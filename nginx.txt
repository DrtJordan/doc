nginx


nginx split_client 可以用来做灰度路由

ngx_stream_core_module模块 模拟反代基于tcp或udp的服务连接，即工作于传输层的反代或调度器； 此模块可以定义非http服务的反代功能
 
nginx-sticky-module 做session stick
 
nginx  性能测试    2111.22 request/s nginx/1.6.2 静态简单html 
apache 性能测试    1723.13 request/s Apache/2.4.6 静态简单html 
tomcat 性能测试    1474.27  request/s tomcat 7.0.50 简单jsp 
tomcat 性能测试    1464.85 request/s tomcat 7.0.50 简单css
tomcat GAF性能测试 617.85 request/s tomcat 7.0.50 gaf简单 service，不涉及数据库
tomcat GAF         691.77  request/s gaf spring mvc转发

配置压缩 添加到 http section
gzip on;
gzip_min_length 1k;
gzip_buffers 4 16k;
gzip_comp_level 5;
gzip_types text/html text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;
gzip_vary off;
gzip_disable "MSIE [1-6]\.";
检测是否打开
curl -I -H "Accept-Encoding: gzip, deflate" "http://192.168.193.176"  
Content-Encoding: gzip
最好把css/js都touch一下修改时间，避免浏览器缓存，看不到效果
压缩比5 567k->90k  压缩比9 567k->85.8k
framework7.min.js 压缩后  209K->53.8K 
framework7.min.css 压缩后 175K->20.5K 
html 文件         5.16k->1.6k



Nginx是一个轻量级高性能的web服务器，它是为快速响应大量静态文件请求和高效利用系统资源而设计的。
与apache使用面向进程或线程的方式处理请求不同，nginx使用异步事件驱动模型在负载下性能更突出。

server指令块，像上面例子中那个一样，是我们nginx用户主要配置自己虚拟主机的地方。
在server块里有许多重要的指令。listen指令告诉nginx在一个特定的hostname，ip或者tcp端口监听连接。默认，http服务运行在80端口。一下这些listen指令都是有效的：

配置文件在
/etc/nginx/nginx.conf 
配置php-fpm
rpm --httpproxy 192.168.8.26   --httpport 8080  -ivh http://ftp.uninett.no/linux/epel/6/i386/epel-release-6-8.noarch.rpm
rpm --httpproxy 192.168.8.26   --httpport 8080  -ivh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm

yum install php55w-fpm.x86_64

修改 
/etc/nginx/conf.d/default.conf 启动php-fastcgi
 location ~ \.php$ {
        root           /ownclound/www;
        fastcgi_pass   127.0.0.1:9000;
        fastcgi_index  index.php;
        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
        include        fastcgi_params;
    }
    

Configure PHP-FPM  /etc/php-fpm.d/www.conf

user = nginx
group = nginx

 service php-fpm restart
 service nginx restart
 
 chkconfig nginx on
 chkconfig php-fpm on
 chkconfig mysqld on 
 
 
 server_name指令可以设置基于域名的虚拟主机，根据请求头部的内容，一个ip的服务器可以配置多个域名。下面这些server_name的参数是有效的:
 

优化
net.core.somaxconn=512
net.core.netdev_max_backlog=1024
一个连接nginx可能消耗两个file descriptior (一个 client,一个 to upstream server)


events {
     worker_connections  1024;
      use   epoll; 
}
/etc/nginx/nginx.conf



location  = / {
  # 只匹配"/".
  [ configuration A ] 
}
location  / {
  # 匹配任何请求，因为所有请求都是以"/"开始
  # 但是更长字符匹配或者正则表达式匹配会优先匹配
  [ configuration B ] 
}
location ^~ /images/ {
  # 匹配任何以 /images/ 开始的请求，并停止匹配 其它location
  [ configuration C ] 
}
location ~* \.(gif|jpg|jpeg)$ {
  # 匹配以 gif, jpg, or jpeg结尾的请求. 
  # 但是所有 /images/ 目录的请求将由 [Configuration C]处理.   
  [ configuration D ] 
}

配置 loadbalancer   支持最少连接( least_conn;)，session stick(ip_hash;) 等等
 http {
    upstream myapp1 {
        server srv1.example.com weight=3;
        server srv2.example.com;
        server srv3.example.com;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://myapp1;
        }
    }
}

  配置 状态 
  location = /status {
    status;
}

配置文件中，http是公共的参数，至少需要配置一个 server作为虚拟机

nginx -s reload  重新读取配置文件

可以限制流量,request rate,ip等等

 location /images/ {
        root /data;    这里面的root是绝对文件路径
    }
    
    context( events, http, server, and location,main) 能够包含其他的 block directive(location )  ,block directive 包含directive
    
    
    location /images/ {
        root /data;
    }
    
    http://localhost/images/example.png =/data/images/example.png
    
    配置缺省字符集
     charset  utf-8;
     
     打开 index 
    location /soft {
    autoindex on;
    root /ownclound/;
    }
    
   设置cache 
   注意 proxy_cache_path 这个指令只能在 http 层指定。它有两个必须的参数：缓存响应存储在文件系统中的路径，以及由参数 keys_zone 指定的共享内存空间的名字和大小。在 proxy_cache 指令中指定的名字要与 proxy_cache_path指定的内存空间名字相同。
   默认情下，Nginx 把所有有GET和HEAD方法的响应缓存起来当这些响应第一次从被代理的服务器接收的时候。Nginx使用请求字符串作为一个请求的身份标识键。任何时候当两个请求有相同的键被认为是一样的并且返回同一个缓存的响应发送给客户端。  proxy_cache_key 指令定义一个请求键的计算方法，这个指令能在location、server 和 http 修改：
   
   http {
    ...
    proxy_cache_path /data/nginx/cache keys_zone=one:10m
                     loader_threshold=300 loader_files=200
                     max_size=200m;

    server {
        listen 8080;
        proxy_cache one;

        location / {
            proxy_pass http://backend1;
        }

        location /some/path {
            proxy_cache_valid any   1m;
            proxy_cache_min_uses 3;
            proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;
            proxy_pass http://backend2;
        }
    }
}
这个例子定义了一个拥有两个使用相同缓存但是做了不同配置的location的虚拟服务。
该例假定从backend1服务器来的响应很少改变，所以第一次请求的响应可以缓存尽可能长的时间。
相比之下，来自backend2服务器的响应则非常易变，所以只有在出现三次相同的请求之后才缓存并且只保存一分钟。此外，
如果一个请求满足 proxy_cache_bapass 指令的条件，Nginx 不会在缓存里查找它的响应而是直接把请求发送给后端。





    
nginx指令中的优化（配置文件）
worker_processes 8;
nginx进程数，建议按照cpu数目来指定
worker_rlimit_nofile 102400; 
use epoll;
worker_connections 102400;
keepalive_timeout 60;
keepalive_request 10240
open_file_cache max=102400 inactive=20s;
打开 cache 可以优化性能

enable keepalive 需要设置  
proxy_http_version 1.1;
proxy_set_header Connection "";

access log 优化  buffer=size parameter to the access_log   flush=time parameter. 
打开 zero copy   sendfile directive  如果同时打开了gzip，则 zero copy 失效
?	limit_conn and limit_conn_zone C Limit the number of client connections NGINX accepts, for example from a single IP address. Setting them can help prevent individual clients from opening too many connections and consuming more than their share of resources.
?	limit_rate C Limits the rate at which responses are transmitted to a client, per connection (so clients that open multiple connections can consume this amount of bandwidth for each connection). Setting a limit can prevent the system from being overloaded by certain clients, ensuring more even quality of service for all clients.
?	limit_req and limit_req_zone C Limit the rate of requests being processed by NGINX, which has the same benefits as setting limit_rate. They can also improve security, especially for login pages, by limiting the request rate to a value reasonable for human users but too slow for programs trying to overwhelm your application with requests (such as bots in a DDoS attack).
?	max_conns parameter to the server directive in an upstream configuration block C Sets the maximum number of simultaneous connections accepted by a server in an upstream group. Imposing a limit can help prevent the upstream servers from being overloaded. Setting the value to 0 (zero, the default) means there is no limit.
?	queue (NGINX Plus) C Creates a queue in which requests are placed when all the available servers in the upstream group have reached their max_conns limit. This directive sets the maximum number of requests in the queue and, optionally, the maximum time they wait (60 seconds by default) before an error is returned. Requests are not queued if you omit this directive.
 
 启用GZip

gzip on;
gzip_disable "msie6";
gzip_vary on;
gzip_proxied any;
gzip_comp_level 6;
gzip_min_length 1100;
gzip_buffers 16 8k;
gzip_http_version 1.1;
gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;

优化 network参数
/etc/sysctl.conf调优

# Recycle Zombie connections
net.inet.tcp.fast_finwait2_recycle=1
net.inet.tcp.maxtcptw=200000

# Increase number of files
kern.maxfiles=65535
kern.maxfilesperproc=16384

# Increase page share factor per process
vm.pmap.pv_entry_max=54272521
vm.pmap.shpgperproc=20000

# Increase number of connections
vfs.vmiodirenable=1
kern.ipc.somaxconn=3240000
net.inet.tcp.rfc1323=1
net.inet.tcp.delayed_ack=0
net.inet.tcp.restrict_rst=1
kern.ipc.maxsockbuf=2097152
kern.ipc.shmmax=268435456

# Host cache
net.inet.tcp.hostcache.hashsize=4096
net.inet.tcp.hostcache.cachelimit=131072
net.inet.tcp.hostcache.bucketlimit=120

# Increase number of ports
net.inet.ip.portrange.first=2000
net.inet.ip.portrange.last=100000
net.inet.ip.portrange.hifirst=2000
net.inet.ip.portrange.hilast=100000
kern.ipc.semvmx=131068

# Disable Ping-flood attacks
net.inet.tcp.msl=2000
net.inet.icmp.bmcastecho=1
net.inet.icmp.icmplim=1
net.inet.tcp.blackhole=2
net.inet.udp.blackhole=1



 client_body_buffer_size指令用来指定处理客户端请求的缓冲区大小, 这个代表了访问请求的body. 
 这是用来处理POST的数据,也就是通过提交表单,文件上传等请求的数据. 如果你需要处理很多大的POST请求的,
 你必须确保缓存区要设置的足够大.

fastcgi_buffers 和 proxy_buffers 指令用来处理上流(upstream)的响应结果, 也就是PHP Apache等.
它的概念其实和上面提到的差不多, 如果缓冲区不足够大数据将在返回给用户使用之前被保存到磁盘上. 
注意Nginx将这个buffer数据同步的传输给客户端之前,有一个缓存上限, 保存到磁盘也同样受限.
 这个上线是通过fastcgi_max_temp_file_size和proxy_max_temp_file_size来设置的. 
 另外对于代理的连接你也可以通过把proxy_buffering设置成off来彻底的关闭缓存.(通常这不是一个好办法).  


同一台机器上多个upstream后端相比单个upstream后端能够带来更高的吞吐量

例如，如果你想支持最大1000个PHP-fpm子进程（children），可以将该数字平均分配到两个upstream后端，各自处理500个PHP-fpm子进程：
配置/etc/php-fpm.d/www.conf
upstream backend {
    server unix:/var/run/php5-fpm.sock1 weight=100 max_fails=5 fail_timeout=5;
    server unix:/var/run/php5-fpm.sock2 weight=100 max_fails=5 fail_timeout=5;
}
