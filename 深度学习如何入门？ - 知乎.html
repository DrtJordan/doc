<!DOCTYPE html>
<!-- saved from url=(0056)https://www.zhihu.com/question/26006703/answer/129209540 -->
<html lang="zh" data-reactroot="" data-reactid="1" data-react-checksum="-291987393" data-focus-method="keyboard"><head data-reactid="2"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title data-reactid="4">深度学习如何入门？ - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1" data-reactid="5"><meta name="renderer" content="webkit" data-reactid="6"><meta name="force-rendering" content="webkit" data-reactid="7"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" data-reactid="8"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg" data-reactid="9"><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico" data-reactid="11"><link rel="dns-prefetch" href="https://static.zhihu.com/" data-reactid="12"><link rel="dns-prefetch" href="https://pic1.zhihu.com/" data-reactid="13"><link rel="dns-prefetch" href="https://pic2.zhihu.com/" data-reactid="14"><link rel="dns-prefetch" href="https://pic3.zhihu.com/" data-reactid="15"><link rel="dns-prefetch" href="https://pic4.zhihu.com/" data-reactid="16"><link href="./深度学习如何入门？ - 知乎_files/main.app.d1f055fc8e563e09f9fd.css" rel="stylesheet" data-reactid="17"><meta name="apple-itunes-app" content="app-id=432274380, app-argument=zhihu://question/26006703" data-react-helmet="true"><script type="text/javascript" charset="utf-8" async="" src="./深度学习如何入门？ - 知乎_files/main.richinput.e0a645095163f916cacb.js.下载"></script><style type="text/css">.CloseIcon-icon-2xww{transition:opacity .3s ease-out}.CloseIcon-icon-2xww:hover{opacity:.8}</style><style type="text/css">.animations-fadeIn-1aFv{animation:animations-fadeIn-1aFv .3s ease-out both}@keyframes animations-fadeIn-1aFv{0%{opacity:0}to{opacity:1}}.animations-fadeOut-3XSQ{animation:animations-fadeOut-3XSQ .3s ease-out both}@keyframes animations-fadeOut-3XSQ{0%{opacity:1}to{opacity:0}}.animations-fadeInUp-3KKK{animation:animations-fadeInUp-3KKK .3s cubic-bezier(.25,.1,.35,1) both}@keyframes animations-fadeInUp-3KKK{0%{opacity:0;transform:translateY(20px)}to{opacity:1;transform:translateY(0)}}.animations-fadeOutDown-r_A_{animation:animations-fadeOutDown-r_A_ .3s cubic-bezier(.25,.1,.35,1) both}@keyframes animations-fadeOutDown-r_A_{0%{transform:translateY(0)}to{opacity:0;transform:translateY(20px)}}</style><style type="text/css">.Modal-backdrop-2ksh{background-color:rgba(0,0,0,.65)}.Modal-backdrop-2ksh,.Modal-modalWrapper-56Mq{position:fixed;top:0;right:0;bottom:0;left:0;z-index:10010}.Modal-modalWrapper-56Mq{display:-ms-flexbox;display:flex;-ms-flex-align:center;align-items:center;-ms-flex-pack:center;justify-content:center}.Modal-modal-wf58{position:relative;z-index:10011;background:#fff;border-radius:2px}.Modal-content-3JxL{width:588px;max-height:calc(100vh - 24px * 2);overflow-x:hidden;overflow-y:auto;-webkit-overflow-scrolling:touch}.Modal-closeButton-3JkR{position:absolute;top:4px;right:-44px;padding:12px;width:40px;height:40px;cursor:pointer;box-sizing:border-box;background:none;outline:none;border:none}</style><style type="text/css">.FeedbackButton-button-3waL{position:fixed;z-index:10000;bottom:40px;right:40px;width:40px;height:40px;cursor:pointer;border-radius:50%;background-color:#fff;border:none;outline:none;box-shadow:0 0 10px rgba(0,0,0,.15);font-weight:700;line-height:normal}.FeedbackButton-icon-1Rgw{display:inline-block;vertical-align:middle;width:18px;height:18px;background-image:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzUiIGhlaWdodD0iMzYiIHZpZXdCb3g9IjAgMCAzNSAzNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R3JvdXAgNjwvdGl0bGU+PGcgZmlsbD0iIzAwOEZFQiIgZmlsbC1ydWxlPSJldmVub2RkIj48cGF0aCBkPSJNMTMgMTguM2MwLS40IDAtLjcuNC0xIC4yLS4yLjUtLjMuOC0uMy40IDAgLjcgMCAxIC40LjIuMi4zLjUuMyAxIDAgLjIgMCAuNS0uNC43IDAgLjQtLjQuNS0uOC41LS4zIDAtLjYgMC0uOC0uNC0uMyAwLS40LS40LS40LS43ek0xMCAxMC43di0xYy40LTEgMS41LTIuNyA0LjItMi43IDIgMCAzLjggMS40IDMuOCAzcy0xLjQgMi43LTIgMy4zYy0uOC42LTEgMS0xLjIgMS43LS4yLjYtLjYgMS0xLjMgMS0uMy0uMi0uNi0uMy0uNy0uNXYtLjhjMC0uMiAwLS43LjMtMS4ybDEuNC0xLjVjMS40LTEuMiAxLjYtMiAuOC0yLjgtLjUtLjQtMS42LS41LTIuMiAwLS44LjQtMSAxLTEuMiAxLjMtLjIuNS0uMyAxLTEuMyAxLS4zLS4yLS40LS40LS41LS44eiIvPjxwYXRoIGQ9Ik0yOS44IDEwLjJ2M2MxLjQgMS44IDIuMyA0IDIuMyA2LjMgMCAzLjgtMi4yIDctNS41IDl2My44bC0zLjctMi41LTMgLjNjLTIuOCAwLTQuMy0uOC02LjQtMi4yaC0zLjFDMTMgMzAuNCAxNS42IDMyIDIwIDMyYy44IDAgMS43IDAgMi42LS4ybDYgNHYtNi40YzMuNS0yLjQgNS43LTYgNS43LTEwIDAtMy42LTEuNy03LTQuNS05LjJ6TTE0LjQgMjUuNmM4IDAgMTMuMi02IDEzLjItMTNTMjEgMCAxNC40IDBDNi40IDAgMCA1LjcgMCAxMi43YzAgNCAxLjUgNy41IDQuNCAxMFYyOWw2LjMtMy42IDMuNy4yek0xNC4yIDJjNi41IDAgMTEuNSA1LjMgMTEuNSAxMUMyNS43IDE5IDIxIDI0IDE0LjQgMjRjLTEgMC0zLjYtLjMtNC41LS41TDYgMjUuN3YtNGMtMi43LTIuMi00LTUtNC04LjZDMiA3IDcgMiAxNCAyeiIvPjwvZz48L3N2Zz4=);background-repeat:no-repeat;background-size:contain}.FeedbackButton-button-3waL:hover .FeedbackButton-icon-1Rgw{background-image:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzUiIGhlaWdodD0iMzYiIHZpZXdCb3g9IjAgMCAzNSAzNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R3JvdXAgMTE8L3RpdGxlPjxnIGZpbGw9Im5vbmUiIGZpbGwtcnVsZT0iZXZlbm9kZCI+PHBhdGggZD0iTTI5LjQgMTNjMCAyLS4zIDguMi01IDExLjQtNC4zIDMtOSAzLjMtMTEuMyAzLjNoLTNjMi44IDIuNyA2LjYgNC44IDEyLjIgNCAxIDAgNi4zIDQgNi4zIDRWMjljMy41LTIuMyA1LjMtNS4yIDUuNi05LjUuMy0zLjctMS42LTctNC41LTkuNXYzem0tMTUgMTIuNmM4IDAgMTMuMi02IDEzLjItMTNTMjEgMCAxNC40IDBDNi40IDAgMCA1LjcgMCAxMi43YzAgNCAxLjUgNy41IDQuNCAxMFYyOWw2LjMtMy42IDMuNy4zeiIgZmlsbD0iIzAwOEZFQiIvPjxwYXRoIGQ9Ik0xMyAxOC4zYzAtLjQgMC0uNy40LTFzLjUtLjMuOC0uM2MuNCAwIC43IDAgMSAuNC4yLjIuMy41LjMgMSAwIC4yIDAgLjUtLjQuNyAwIC40LS40LjUtLjguNS0uMyAwLS42IDAtLjgtLjQtLjMgMC0uNC0uNC0uNC0uN3ptLTMtNy42di0xYy40LTEgMS40LTIuNyA0LjItMi43IDIgMCAzLjggMS40IDMuOCAzcy0xLjQgMi43LTIgMy4zYy0uOC42LTEgMS0xLjIgMS43LS4yLjYtLjYgMS0xLjMgMS0uMy0uMi0uNi0uMy0uNy0uNXYtLjhjMC0uMiAwLS43LjMtMS4ybDEuNC0xLjVjMS40LTEuMiAxLjYtMiAuOC0yLjgtLjUtLjQtMS42LS41LTIuMiAwLS44LjQtMSAxLTEuMiAxLjMtLjIuNS0uMyAxLTEuMyAxLS4zLS4yLS40LS40LS41LS44eiIgZmlsbD0iI0ZGRiIvPjwvZz48L3N2Zz4=)}</style><style type="text/css">.DrawingExample-svg-30WA{position:absolute;top:30px;right:0;left:0;margin:auto;transform:rotate(-44deg)}.DrawingExample-ellipse-26bv{stroke-dasharray:520;transform-origin:center;animation:DrawingExample-drawingExample-3Bm3 .6s linear both}@keyframes DrawingExample-drawingExample-3Bm3{0%{stroke-dashoffset:520}50%{stroke-dashoffset:1000;opacity:1}to{stroke-dashoffset:1000;opacity:0}}</style><style type="text/css">.Spinner-spinner-2PGn{position:absolute;width:30px;height:30px;top:50%;left:50%;margin:-15px 0 0 -15px;animation:Spinner-rotate-RMMJ .8s linear infinite}.Spinner-spinner-2PGn .Spinner-circle-teFy{stroke:#4197ff;stroke-dasharray:187;stroke-dashoffset:46.75;transform-origin:center}@keyframes Spinner-rotate-RMMJ{0%{transform:rotate(0deg)}to{transform:rotate(1turn)}}</style><style type="text/css">.FeedbackForm-form-1uUg{padding:40px 24px 32px;width:100%;font-size:14px;line-height:1.5;font-family:HelveticaNeue-Light,Helvetica,PingFangSC-Light,Hiragino Sans GB,Microsoft YaHei,Arial,sans-serif;color:#404040;box-sizing:border-box}.FeedbackForm-header-3hQI{margin-bottom:26px;text-align:center}.FeedbackForm-title-2uCC{font-size:24px;font-weight:500;line-height:33px;font-family:Helvetica,PingFang SC,Hiragino Sans GB,Microsoft YaHei,Arial,sans-serif}.FeedbackForm-inputBox-15yJ{display:block;padding:12px;width:100%;height:auto;font-size:15px;border:1px solid #e7eaf1;border-radius:3px;box-sizing:border-box;resize:none;outline:none;color:inherit;transition:box-shadow .15s ease-out;overflow:auto}.FeedbackForm-inputBox-15yJ::-webkit-input-placeholder{color:#9aaabf;transition:color .15s ease-out}.FeedbackForm-inputBox-15yJ::-moz-placeholder{color:#9aaabf;transition:color .15s ease-out}.FeedbackForm-inputBox-15yJ:-ms-input-placeholder{color:#9aaabf;transition:color .15s ease-out}.FeedbackForm-inputBox-15yJ::placeholder{color:#9aaabf;transition:color .15s ease-out}.FeedbackForm-inputBox-15yJ:hover::-webkit-input-placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ:hover::-moz-placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ:hover:-ms-input-placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ:hover::placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ:focus{box-shadow:0 0 5px #e7eaf1}.FeedbackForm-inputBox-15yJ:focus::-webkit-input-placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ:focus::-moz-placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ:focus:-ms-input-placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ:focus::placeholder{color:rgba(154,170,191,.8)}.FeedbackForm-inputBox-15yJ.FeedbackForm-isWarning-2ds-{border-color:#f75659}.FeedbackForm-inputBox-15yJ.FeedbackForm-isWarning-2ds-::-webkit-input-placeholder{color:#f75659}.FeedbackForm-inputBox-15yJ.FeedbackForm-isWarning-2ds-::-moz-placeholder{color:#f75659}.FeedbackForm-inputBox-15yJ.FeedbackForm-isWarning-2ds-:-ms-input-placeholder{color:#f75659}.FeedbackForm-inputBox-15yJ.FeedbackForm-isWarning-2ds-::placeholder{color:#f75659}.FeedbackForm-inputBox-15yJ.FeedbackForm-isWarning-2ds-:focus{box-shadow:none}.FeedbackForm-screenShot--Gsn{overflow:hidden;box-sizing:border-box;transition:max-height .3s ease,opacity .3s ease}.FeedbackForm-screenShotLabel-2Sgh{padding-top:22px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.FeedbackForm-canvasContainer-mrde{margin-top:8px;position:relative;background-color:#f6f7f9}.FeedbackForm-canvas-tSGI{display:block;max-width:100%;cursor:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAASCAYAAABWzo5XAAAABGdBTUEAALGPC/xhBQAAARpJREFUOBGdkr1KA0EUhTcxEkSQQIpAihQWPoedD2BnIVsZQiBVEkiR7SwtBDsJqXwBLQwEgoWNjY2FjYUQ38Ei5Oc7sBeGLTKze+Djzsyecxh2N4ryq0zkHpYQQ2H1SW5TNsxukaZzQsewACvTvIBg3eFUaABHMEv3OruBIN3icm8wZl+FZ3iBQ/AqweGW2FrlKlChV0McFsxOvaegm/T2lLzzTC/dqzaO7A1s/8GzE28Dhhj0f1jQnZ+c18CrKxxrcMO2/uK87m3AcAkrsKA7vzlvQJAmuNywrX84bwY1YBrBATyCFWj+QguCJKNCU1DZQ7r/Y55CsK5x2i2eWFcggTPIJd3Eiv5Zd3KlU3OJOQd9lVd4A5Xl1g4YG2GGhwRfegAAAABJRU5ErkJggg==) 0 17,default;cursor:-webkit-image-set(url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAASCAYAAABWzo5XAAAABGdBTUEAALGPC/xhBQAAARpJREFUOBGdkr1KA0EUhTcxEkSQQIpAihQWPoedD2BnIVsZQiBVEkiR7SwtBDsJqXwBLQwEgoWNjY2FjYUQ38Ei5Oc7sBeGLTKze+Djzsyecxh2N4ryq0zkHpYQQ2H1SW5TNsxukaZzQsewACvTvIBg3eFUaABHMEv3OruBIN3icm8wZl+FZ3iBQ/AqweGW2FrlKlChV0McFsxOvaegm/T2lLzzTC/dqzaO7A1s/8GzE28Dhhj0f1jQnZ+c18CrKxxrcMO2/uK87m3AcAkrsKA7vzlvQJAmuNywrX84bwY1YBrBATyCFWj+QguCJKNCU1DZQ7r/Y55CsK5x2i2eWFcggTPIJd3Eiv5Zd3KlU3OJOQd9lVd4A5Xl1g4YG2GGhwRfegAAAABJRU5ErkJggg==) 1x,url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACQAAAAkCAYAAADhAJiYAAAABGdBTUEAALGPC/xhBQAAAn9JREFUWAnFlz1IV2EUxs2+ixCCrCCrIaiGGnLIRdBacqkhtCEbqqVaoqmacpIma6rFHHITh1pKMKFaInATkb4hKChKIwj7rt8D74XDy3tfKM69Hng4zz3nvc9zfH3/93//DQ31xWqsBsEnMAU6wILFSpwnwB+Db/BDoPZYjuMYsMMU/Af1nron2o7hh5KBNNhP0AtqjV24vQPFzsT5F70jVU7UiPhNcNyY7IC/AfEwxfUsvcVmvRtdhNIQkNFvcAoUsQ3yGhRDxLmpWOiZryUMzxqDrfCXiTXjZo0bvZIwKnbhvHHZBH9q1s7Am03fhV42BsUQcb5knDbAp8EzsNHUXWgfKrF52XW/cVwH1265xgXUyszL6gOuExixc/8xjIZ8C9YbHRd6GpWyHcjV33PfTpcJjMgJuJ4xOeNU7yP37DY6LvQoKnrUpwxzNb12tLpMYES64foyzBmnep+5p83ouNCDqHwHKcNc7Qv3tLtMYEQOwPVClTNO9ea5Z7/RcaH7UJFwyjBX0x/Q5TKBEdFWa8tzxqme3gTdX0/3IqrDmDLM1XTodfhdYw9qcyBnnOrpcdDrOglienDpAZYyzNX0oDwJ3GMUxZxxWe+M+yRBcBX53j8OpS9Z9ziM4tKguoJ8B5Tthq1fDPe4p+co3gbLgrLyLWDNY94X1rqnFmN8F64dUiwBIyAeRNd6Za0sjqFsTXWGdJYU+q00DGz/qhpVxg3EraH4Q7AmmDaSB4Hq10Ot0vQimMVDPaLeFJz1A1DvQsqVxmbU40Hs9ST9tZVOYMT1r+gw1zF9ReEx2BI3qrrWp6jTiH+FPwD6pI2BJ6DW0HkYBzNAQ9wH82DB4i/kUnkzGX+skQAAAABJRU5ErkJggg==) 2x) 0 17,default}.FeedbackForm-canvas-tSGI.FeedbackForm-isCapturing-3UFp{display:none}.FeedbackForm-checkLabelWrapper-3B7w{margin-top:12px}.FeedbackForm-checkLabel-2VTb{cursor:pointer;color:#9aaabf;transition:color .15s ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.FeedbackForm-checkLabel-2VTb:hover{color:rgba(154,170,191,.8)}.FeedbackForm-checkLabel-2VTb input{margin-right:.5em;vertical-align:1px}.FeedbackForm-actions-dJ87{margin-top:40px;text-align:center}.FeedbackForm-submitButton-1oKQ{display:inline-block;min-width:220px;padding:8px 1em;background-color:#0f88eb;border:1px solid #0f88eb;border-radius:3px;font:inherit;color:#fff;transition:background-color .15s ease-out,opacity .15s ease-out;cursor:pointer;outline:none}.FeedbackForm-submitButton-1oKQ[disabled]{opacity:.8;cursor:default}.FeedbackForm-submitButton-1oKQ:hover{background-color:#0d79d1}.FeedbackForm-submitButton-1oKQ:active{opacity:.8}.FeedbackForm-successMask-34go{display:-ms-flexbox;display:flex;-ms-flex-pack:center;justify-content:center;-ms-flex-align:center;align-items:center;position:absolute;top:0;left:0;width:100%;height:100%;background-color:#fff}.FeedbackForm-successTitle-1Y6p{font-size:24px;font-weight:500;line-height:33px;font-family:Helvetica,PingFang SC,Hiragino Sans GB,Microsoft YaHei,Arial,sans-serif;text-align:center}.FeedbackForm-successSubtitle-A_aP{margin-top:10px;font-size:18px;line-height:33px;text-align:center}</style></head><body class="Entry-body" data-reactid="18"><div id="root" data-reactid="19"><div data-reactroot=""><!-- react-empty: 2 --><div class="LoadingBar"></div><!-- react-empty: 4 --><div><header role="banner" class="Sticky AppHeader is-fixed" data-za-module="TopNavBar" style="width: 978.909px; top: 0px; left: 0px;"><!-- react-empty: 261 --><div class="AppHeader-inner"><a href="https://www.zhihu.com/" aria-label="知乎"><svg viewBox="0 0 200 91" class="Icon Icon--logo" width="64" height="30" aria-hidden="true" style="fill: rgb(15, 136, 235); height: 30px; width: 64px;"><title></title><g><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></g></svg></a><nav role="navigation" class="AppHeader-nav"><a class="AppHeader-navItem" href="https://www.zhihu.com/">首页</a><a class="AppHeader-navItem" href="https://www.zhihu.com/explore">发现</a><a class="AppHeader-navItem" href="https://www.zhihu.com/topic">话题</a></nav><div class="SearchBar" role="search"><div class="SearchBar-toolWrapper"><form class="SearchBar-tool"><div><div class="Popover"><div class="SearchBar-input Input-wrapper Input-wrapper--grey"><input type="text" maxlength="100" value="" autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplete-69708-30977--1" id="Popover-69709-68727-toggle" aria-haspopup="true" aria-owns="Popover-69709-68727-content" class="Input" placeholder="搜索你感兴趣的内容…"></div><!-- react-empty: 24 --></div></div><button class="Button SearchBar-searchIcon Button--plain" aria-label="搜索" type="button"><svg viewBox="0 0 16 16" class="Icon Icon--search" width="16" height="16" aria-hidden="true" style="height: 16px; width: 16px;"><title></title><g><path d="M12.054 10.864c.887-1.14 1.42-2.57 1.42-4.127C13.474 3.017 10.457 0 6.737 0S0 3.016 0 6.737c0 3.72 3.016 6.737 6.737 6.737 1.556 0 2.985-.533 4.127-1.42l3.103 3.104c.765.46 1.705-.37 1.19-1.19l-3.103-3.104zm-5.317.925c-2.786 0-5.053-2.267-5.053-5.053S3.95 1.684 6.737 1.684 11.79 3.95 11.79 6.737 9.522 11.79 6.736 11.79z"></path></g></svg></button><div class="SearchBar-iconDecorator"></div></form></div><button class="Button SearchBar-askButton Button--primary Button--blue" type="button"><!-- react-text: 31 -->提问<!-- /react-text --><!-- react-empty: 32 --></button><!-- react-empty: 33 --></div><div class="AppHeader-userInfo"><div class="Popover PushNotifications AppHeader-notifications"><button class="Button PushNotifications-icon Button--plain" type="button" id="Popover-69853-80208-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69853-80208-content"><svg viewBox="0 0 20 22" class="Icon Icon--news" width="20" height="20" aria-hidden="true" style="height: 20px; width: 20px;"><title></title><g><path d="M2.502 14.08C3.1 10.64 2 3 8.202 1.62 8.307.697 9.08 0 10 0s1.694.697 1.797 1.62C18 3 16.903 10.64 17.497 14.076c.106 1.102.736 1.855 1.7 2.108.527.142.868.66.793 1.206-.075.546-.542.95-1.09.943H1.1C.55 18.34.084 17.936.01 17.39c-.075-.547.266-1.064.794-1.206.963-.253 1.698-1.137 1.698-2.104zM10 22c-1.417.003-2.602-1.086-2.73-2.51-.004-.062.02-.124.063-.17.043-.045.104-.07.166-.07h5c.063 0 .124.025.167.07.044.046.067.108.063.17-.128 1.424-1.313 2.513-2.73 2.51z"></path></g></svg><span class="PushNotifications-count"><!-- react-text: 268 -->1<!-- /react-text --></span><!-- react-empty: 269 --></button><!-- react-empty: 270 --></div><div><div class="Popover Messages AppHeader-messages"><button class="Button Messages-icon Button--plain" type="button" id="Popover-69855-66168-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69855-66168-content"><svg viewBox="0 0 20 20" class="Icon Icon--message" width="20" height="20" aria-hidden="true" style="height: 20px; width: 20px;"><title></title><g><path d="M9 0C3.394 0 0 4.13 0 8c0 1.654.522 3.763 2.014 5.566.314.292.518.82.454 1.17-.165 1.488-.842 1.905-.842 1.905-.328.332.105.67.588.582 1.112-.2 2.07-.58 3.526-1.122.4-.202.464-.147.78-.078C11.524 17.764 18 14 18 8c0-3.665-3.43-8-9-8z"></path><path d="M19.14 9.628c.758.988.86 2.01.86 3.15 0 1.195-.62 3.11-1.368 3.938-.21.23-.354.467-.308.722.12 1.073.614 1.5.614 1.5.237.24-.188.563-.537.5-.802-.145-1.494-.42-2.545-.81-.29-.146-.336-.106-.563-.057-2.043.712-4.398.476-6.083-.926 5.964-.524 8.726-3.03 9.93-8.016z"></path></g></svg></button><!-- react-empty: 277 --></div><!-- react-empty: 278 --></div><div class="AppHeader-profile"><div class="Popover"><button class="Button AppHeader-profileEntry Button--plain" type="button" id="Popover-69856-17588-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69856-17588-content"><img class="Avatar" src="./深度学习如何入门？ - 知乎_files/da8e974dc_is.jpg" srcset="https://pic1.zhimg.com/da8e974dc_im.jpg 2x" style="width: 30px; height: 30px;"></button><!-- react-empty: 282 --></div></div></div></div><div class="PageHeader"><div data-reactroot="" class="QuestionHeader-content"><div class="QuestionHeader-main"><h1 class="QuestionHeader-title">深度学习如何入门？</h1></div><div class="QuestionHeader-side"><div class="QuestionButtonGroup"><button class="Button Button--primary Button--blue" type="button">关注问题</button><button class="Button" type="button"><svg viewBox="0 0 12 12" class="Icon Button-icon Icon--modify" width="14" height="16" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><path d="M.423 10.32L0 12l1.667-.474 1.55-.44-2.4-2.33-.394 1.564zM10.153.233c-.327-.318-.85-.31-1.17.018l-.793.817 2.49 2.414.792-.814c.318-.328.312-.852-.017-1.17l-1.3-1.263zM3.84 10.536L1.35 8.122l6.265-6.46 2.49 2.414-6.265 6.46z" fill-rule="evenodd"></path></g></svg><!-- react-text: 11 -->写回答<!-- /react-text --></button></div></div></div></div></header><div class="Sticky--holder" style="position: relative; top: 0px; right: 0px; bottom: 0px; left: 0px; display: block; float: none; margin: 0px; height: 60.7273px;"></div></div><main role="main" class="App-main"><div><!-- react-empty: 48 --><div data-za-module="QuestionItem"><div class="QuestionStatus"><!-- react-empty: 51 --><!-- react-empty: 52 --><!-- react-empty: 53 --></div><div class="QuestionHeader"><div class="QuestionHeader-content"><div class="QuestionHeader-main"><div class="QuestionHeader-topics"><div class="Tag QuestionTopic" data-za-module="TopicItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19559450&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19559450"><div class="Popover"><div id="Popover-69732-23090-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69732-23090-content">机器学习</div><!-- react-empty: 63 --></div></a></span></div><div class="Tag QuestionTopic" data-za-module="TopicItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19813032&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19813032"><div class="Popover"><div id="Popover-69733-17619-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69733-17619-content">深度学习（Deep Learning）</div><!-- react-empty: 69 --></div></a></span></div></div><h1 class="QuestionHeader-title"><!-- react-text: 71 -->深度学习如何入门？<!-- /react-text --></h1><div class="QuestionHeader-detail"><div class="QuestionRichText QuestionRichText--expandable QuestionRichText--collapsed"><div><span class="RichText">本人研究生，刚开始研究深度学习，课题组无任何前期基础。数学基础较差，现在发现网上各种资料真是太多了。不知道从何下手。现在在看《Python基础教程》、…</span><button class="Button QuestionRichText-more Button--plain" type="button"><!-- react-text: 77 -->显示全部<!-- /react-text --><svg viewBox="0 0 10 6" class="Icon QuestionRichText-more-icon Icon--arrow" width="10" height="16" aria-hidden="true" style="height: 16px; width: 10px;"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"></path></g></svg></button></div></div></div></div><div class="QuestionHeader-side"><div class="QuestionHeader-follow-status"><div class="QuestionFollowStatus"><div class="NumberBoard QuestionFollowStatus-counts"><button class="Button NumberBoard-item Button--plain" type="button"><div class="NumberBoard-name">关注者</div><div class="NumberBoard-value">20567</div></button><div class="NumberBoard-divider"></div><div class="NumberBoard-item"><div class="NumberBoard-name">被浏览</div><div class="NumberBoard-value">736148</div></div></div><!-- react-empty: 92 --></div></div></div></div><div class="QuestionHeader-footer"><div class="QuestionHeader-footer-inner"><div class="QuestionHeader-main QuestionHeader-footer-main"><div class="QuestionHeader-actions"><button class="Button Button--plain" type="button"><svg viewBox="0 0 18 18" class="Icon Icon--comment Icon--left" width="12" height="16" aria-hidden="true" style="height: 16px; width: 12px;"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"></path></g></svg><!-- react-text: 101 -->9 条评论<!-- /react-text --><!-- react-empty: 102 --></button><div class="Popover ShareMenu"><div id="Popover-69741-84437-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69741-84437-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" class="Icon Icon--share Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"></path></g></svg><!-- react-text: 109 -->分享<!-- /react-text --></button></div><!-- react-empty: 110 --></div><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"></path></g></svg><!-- react-text: 115 -->邀请回答<!-- /react-text --><!-- react-empty: 116 --></button><button class="Button Button--plain" type="button"><svg viewBox="0 0 18 20" class="Icon Icon--report Icon--left" width="11" height="16" aria-hidden="true" style="height: 16px; width: 11px;"><title></title><g><path d="M16.947 1.13c-.633.135-3.927.638-5.697.384-3.133-.45-4.776-2.54-9.95-.888C.305 1.04.025 1.664.025 2.646L0 18.807c0 .3.1.54.304.718.195.202.438.304.73.304.275 0 .52-.102.73-.304.202-.18.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V1.964c0-.6-.42-.972-1.053-.835z"></path></g></svg><!-- react-text: 121 -->举报<!-- /react-text --><!-- react-empty: 122 --></button><div class="Popover"><button class="Button Button--plain" type="button" id="Popover-69745-47507-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69745-47507-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" width="14" height="16" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><g><circle cx="2" cy="2" r="2"></circle><circle cx="9" cy="2" r="2"></circle><circle cx="16" cy="2" r="2"></circle></g></g></svg></button><!-- react-empty: 128 --></div><!-- react-empty: 129 --><!-- react-empty: 130 --><!-- react-empty: 131 --><!-- react-empty: 132 --><!-- react-empty: 133 --></div><div class="QuestionHeader-actions"></div></div><div class="QuestionHeader-side"><div class="QuestionButtonGroup"><button class="Button Button--primary Button--blue" type="button">关注问题</button><button class="Button" type="button"><svg viewBox="0 0 12 12" class="Icon Button-icon Icon--modify" width="14" height="16" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><path d="M.423 10.32L0 12l1.667-.474 1.55-.44-2.4-2.33-.394 1.564zM10.153.233c-.327-.318-.85-.31-1.17.018l-.793.817 2.49 2.414.792-.814c.318-.328.312-.852-.017-1.17l-1.3-1.263zM3.84 10.536L1.35 8.122l6.265-6.46 2.49 2.414-6.265 6.46z" fill-rule="evenodd"></path></g></svg><!-- react-text: 142 -->写回答<!-- /react-text --></button></div></div></div></div></div><div><div><div class="Sticky is-fixed" style="width: 978.909px; top: 60px; left: 0px;"></div><div class="Sticky--holder" style="position: static; top: auto; right: auto; bottom: auto; left: auto; display: block; float: none; margin: 0px; height: 0px;"></div></div><!-- react-empty: 455 --></div></div><div class="Question-main"><!-- react-empty: 147 --><div class="Question-mainColumn"><div class="Card" data-za-module="MessageItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;item_num&quot;:102}}}"><a class="QuestionMainAction" data-za-detail-view-element_name="ViewAll" href="https://www.zhihu.com/question/26006703"><!-- react-text: 151 -->查看全部 <!-- /react-text --><!-- react-text: 152 -->102<!-- /react-text --><!-- react-text: 153 --> 个回答<!-- /react-text --></a></div><div class="Card"><div class="QuestionAnswer-content"><div data-za-module="AnswerItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Answer&quot;,&quot;token&quot;:&quot;129209540&quot;,&quot;upvote_num&quot;:3697,&quot;comment_num&quot;:115,&quot;publish_timestamp&quot;:null,&quot;parent_token&quot;:&quot;26006703&quot;,&quot;author_member_hash_id&quot;:&quot;ceff5c1e402891df07f3216271d2da55&quot;}}}"><div class="ContentItem" data="[object Object]"><div class="ContentItem-meta"><div class="AnswerItem-meta AnswerItem-meta--related"><div class="AuthorInfo"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover-69765-85389-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69765-85389-content"><a class="UserLink-link" href="https://www.zhihu.com/people/jacky-yang-30"><img class="Avatar AuthorInfo-avatar" src="./深度学习如何入门？ - 知乎_files/v2-15e541b81efc194fa83052bd46ceb60d_xs.jpg" srcset="https://pic2.zhimg.com/v2-15e541b81efc194fa83052bd46ceb60d_l.jpg 2x" alt="jacky yang" style="width: 38px; height: 38px;"></a></div><!-- react-empty: 166 --></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-title"><div class="AuthorInfo-name"><span class="UserLink"><div class="Popover"><div id="Popover-69767-39311-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-69767-39311-content"><a class="UserLink-link" href="https://www.zhihu.com/people/jacky-yang-30">jacky yang</a></div><!-- react-empty: 174 --></div></span></div></div><div class="RichText AuthorInfo-badge">深度学习，人脸识别，人工智能</div></div></div><div class="AnswerItem-extraInfo"><!-- react-text: 177 -->收录于 编辑推荐<!-- /react-text --><!-- react-text: 178 --> · <!-- /react-text --><span class="Voters"><button class="Button Button--plain" type="button">3697 人赞同了该回答</button><!-- react-empty: 181 --></span></div></div></div><div class="ContentItem-content ContentItem-content--unescapable"><div><div><span class="RichText CopyrightRichText-richText"><p>关于深度学习，网上的资料很多，不过貌似大部分都不太适合初学者。 <br>这里有几个原因：<br>1.深度学习确实需要一定的数学基础。如果不用深入浅出地方法讲，有些读者就会有畏难的情绪，因而容易过早地放弃。<br>2.中国人或美国人写的书籍或文章，普遍比较难一些。我不太清楚为什么，不过确实是这样子的。</p><p>深度学习，确实需要一定的数学基础，但真的那么难么？这个，还真没有。不信？听我来给你侃侃。看完，你也会觉得没那么难了。</p><p>本文是针对初学者，高手可以无视，有不对的地方，还请多多批评指正。</p><p>这里，先推荐一篇非常不错的文章：<br>《1天搞懂深度学习》，300多页的ppt，台湾李宏毅教授写的，非常棒。<br>不夸张地说，是我看过最系统，也最通俗易懂的，关于深度学习的文章。</p><p>这是slideshare的链接：<br><a href="https://link.zhihu.com/?target=http%3A//www.slideshare.net/tw_dsconf/ss-62245351%3Fqid%3D108adce3-2c3d-4758-a830-95d0a57e46bc%26v%3D%26b%3D%26from_search%3D3" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://www.</span><span class="visible">slideshare.net/tw_dscon</span><span class="invisible">f/ss-62245351?qid=108adce3-2c3d-4758-a830-95d0a57e46bc&amp;v=&amp;b=&amp;from_search=3</span><span class="ellipsis"></span><i class="icon-external"></i></a></p><p>没梯子的同学，可以从我的网盘下：<br>链接：<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1nv54p9R" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">pan.baidu.com/s/1nv54p9</span><span class="invisible">R</span><span class="ellipsis"></span><i class="icon-external"></i></a> 密码：3mty</p><p>要说先准备什么，私以为，其实只需要知道导数和相关的函数概念就可以了。高等数学也没学过？很好，我就是想让文科生也能看懂，您只需要学过初中数学就可以了。</p><p>其实不必有畏难的情绪，个人很推崇李书福的精神，在一次电视采访中，李书福说：谁说中国人不能造汽车？造汽车有啥难的，不就是四个轮子加两排沙发嘛。当然，他这个结论有失偏颇，不过精神可嘉。</p><p>导数是什么，无非就是变化率呗，王小二今年卖了100头猪，去年卖了90头，前年卖了80头。。。变化率或者增长率是什么？每年增长10头猪，多简单。这里需要注意有个时间变量---年。王小二卖猪的增长率是10头/年，也就是说，导数是10.<br>函数y=f(x)=10x+30，这里我们假设王小二第一年卖了30头，以后每年增长10头，x代表时间（年），y代表猪的头数。<br>当然，这是增长率固定的情形，现实生活中，很多时候，变化量也不是固定的，也就是说增长率也不是恒定的。比如，函数可能是这样: y=f(x)=5x²+30，这里x和y依然代表的是时间和头数，不过增长率变了，怎么算这个增长率，我们回头再讲。或者你干脆记住几个求导的公式也可以。</p><p>深度学习还有一个重要的数学概念：偏导数，偏导数的偏怎么理解？偏头疼的偏，还是我不让你导，你偏要导？都不是，我们还以王小二卖猪为例，刚才我们讲到，x变量是时间（年），可是卖出去的猪，不光跟时间有关啊，随着业务的增长，王小二不仅扩大了养猪场，还雇了很多员工一起养猪。所以方程式又变了：y=f(x)=5x₁²+8x₂ + 35x₃ +30<br>这里x₂代表面积，x₃代表员工数，当然x₁还是时间。<br>上面我们讲了，导数其实就是变化率，那么偏导数是什么？偏导数无非就是多个变量的时候，针对某个变量的变化率呗。在上面的公式里，如果针对x₃求偏导数，也就是说，员工对于猪的增长率贡献有多大，或者说，随着（每个）员工的增长，猪增加了多少，这里等于35---每增加一个员工，就多卖出去35头猪. 计算偏导数的时候，其他变量都可以看成常量，这点很重要，常量的变化率为0，所以导数为0，所以就剩对35x₃ 求导数，等于35. 对于x₂求偏导，也是类似的。<br>求偏导我们用一个符号 表示：比如 y/ x₃ 就表示y对 x₃求偏导。</p>废话半天，这些跟深度学习到底有啥关系？有关系，我们知道，深度学习是采用神经网络，用于解决线性不可分的问题。关于这一点，我们回头再讨论，大家也可以网上搜一下相关的文章。我这里主要讲讲数学与深度学习的关系。先给大家看几张图：<br><noscript>&amp;lt;img src="https://pic3.zhimg.com/v2-91704850c698cbe0cdfd0af76d328ebe_b.png" data-rawwidth="631" data-rawheight="488" class="origin_image zh-lightbox-thumb" width="631" data-original="https://pic3.zhimg.com/v2-91704850c698cbe0cdfd0af76d328ebe_r.png"&amp;gt;  图1. 所谓深度学习，就是具有很多个隐层的神经网络。</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-91704850c698cbe0cdfd0af76d328ebe_b.png" data-rawwidth="631" data-rawheight="488" class="origin_image zh-lightbox-thumb lazy" width="631" data-original="https://pic3.zhimg.com/v2-91704850c698cbe0cdfd0af76d328ebe_r.png" data-actualsrc="https://pic3.zhimg.com/v2-91704850c698cbe0cdfd0af76d328ebe_b.png"><p>  图1. 所谓深度学习，就是具有很多个隐层的神经网络。</p><noscript>&amp;lt;img src="https://pic4.zhimg.com/v2-7875411304340d5accd6d800be9f933b_b.jpg" data-rawwidth="432" data-rawheight="576" class="origin_image zh-lightbox-thumb" width="432" data-original="https://pic4.zhimg.com/v2-7875411304340d5accd6d800be9f933b_r.jpg"&amp;gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-7875411304340d5accd6d800be9f933b_b.jpg" data-rawwidth="432" data-rawheight="576" class="origin_image zh-lightbox-thumb lazy" width="432" data-original="https://pic4.zhimg.com/v2-7875411304340d5accd6d800be9f933b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-7875411304340d5accd6d800be9f933b_b.jpg"><br>图2.单输出的时候，怎么求偏导数<br><noscript>&amp;lt;img src="https://pic2.zhimg.com/v2-c52b1fcdd42c3ac413120b56e40a8619_b.jpg" data-rawwidth="432" data-rawheight="576" class="origin_image zh-lightbox-thumb" width="432" data-original="https://pic2.zhimg.com/v2-c52b1fcdd42c3ac413120b56e40a8619_r.jpg"&amp;gt;图3.多输出的时候，怎么求偏导数。后面两张图是日语的，这是日本人写的关于深度学习的书。感觉写的不错，把图盗来用一下。所谓入力层，出力层，中间层，分别对应于中文的：输入层，输出层，和隐层。</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-c52b1fcdd42c3ac413120b56e40a8619_b.jpg" data-rawwidth="432" data-rawheight="576" class="origin_image zh-lightbox-thumb lazy" width="432" data-original="https://pic2.zhimg.com/v2-c52b1fcdd42c3ac413120b56e40a8619_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c52b1fcdd42c3ac413120b56e40a8619_b.jpg"><p>图3.多输出的时候，怎么求偏导数。后面两张图是日语的，这是日本人写的关于深度学习的书。感觉写的不错，把图盗来用一下。所谓入力层，出力层，中间层，分别对应于中文的：输入层，输出层，和隐层。</p><p>大家不要被这几张图吓着，其实很简单的。干脆再举一个例子，就以撩妹为例。男女恋爱我们大致可以分为三个阶段：<br>1.初恋期。相当于深度学习的输入层。别人吸引你，肯定是有很多因素，比如：身高，身材，脸蛋，学历，性格等等，这些都是输入层的参数，对每个人来说权重可能都不一样。<br>2.热恋期。我们就让它对应于隐层吧。这个期间，双方各种磨合，柴米油盐酱醋茶。<br>3.稳定期。对应于输出层，是否合适，就看磨合得咋样了。</p><p>大家都知道，磨合很重要，怎么磨合呢？就是不断学习训练和修正的过程嘛！比如女朋友喜欢草莓蛋糕，你买了蓝莓的，她的反馈是negative，你下次就别买了蓝莓，改草莓了。<br>------------------------------------------------------------------------------------------------<br>看完这个，有些小伙可能要开始对自己女友调参了。有点不放心，所以补充一下。<br>撩妹和深度学习一样，既要防止欠拟合，也要防止过拟合。所谓欠拟合，对深度学习而言，就是训练得不够，数据不足，就好比，你撩妹经验不足，需要多学着点，送花当然是最基本的了，还需要提高其他方面，比如，提高自身说话的幽默感等，因为本文重点并不是撩妹，所以就不展开讲了。这里需要提一点，欠拟合固然不好，但过拟合就更不合适了。过拟合跟欠拟合相反，一方面，如果过拟合，她会觉得你有陈冠希老师的潜质，更重要的是，每个人情况不一样，就像深度学习一样，训练集效果很好，但测试集不行！就撩妹而言，她会觉得你受前任(训练集)影响很大，这是大忌！如果给她这个映象，你以后有的烦了，切记切记！<br>------------------------------------------------------------------------------------------------</p><p>深度学习也是一个不断磨合的过程，刚开始定义一个标准参数（这些是经验值。就好比情人节和生日必须送花一样），然后不断地修正，得出图1每个节点间的权重。为什么要这样磨合？试想一下，我们假设深度学习是一个小孩，我们怎么教他看图识字？肯定得先把图片给他看，并且告诉他正确的答案，需要很多图片，不断地教他，训练他，这个训练的过程，其实就类似于求解神经网络权重的过程。以后测试的时候，你只要给他图片，他就知道图里面有什么了。</p><p>所以训练集，其实就是给小孩看的，带有正确答案的图片，对于深度学习而言，训练集就是用来求解神经网络的权重的，最后形成模型；而测试集，就是用来验证模型的准确度的。</p>对于已经训练好的模型，如下图所示，权重（w1，w2...）都已知。<br><noscript>&amp;lt;img src="https://pic1.zhimg.com/v2-8521e1fa289e08dbbab5aa63b6527bd4_b.png" data-rawwidth="940" data-rawheight="736" class="origin_image zh-lightbox-thumb" width="940" data-original="https://pic1.zhimg.com/v2-8521e1fa289e08dbbab5aa63b6527bd4_r.png"&amp;gt;                                图4</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-8521e1fa289e08dbbab5aa63b6527bd4_b.png" data-rawwidth="940" data-rawheight="736" class="origin_image zh-lightbox-thumb lazy" width="940" data-original="https://pic1.zhimg.com/v2-8521e1fa289e08dbbab5aa63b6527bd4_r.png" data-actualsrc="https://pic1.zhimg.com/v2-8521e1fa289e08dbbab5aa63b6527bd4_b.png">                                图4<br><noscript>&amp;lt;img src="https://pic4.zhimg.com/v2-ef5ad0d06a316f762f0625b2468e2f43_b.png" data-rawwidth="776" data-rawheight="174" class="origin_image zh-lightbox-thumb" width="776" data-original="https://pic4.zhimg.com/v2-ef5ad0d06a316f762f0625b2468e2f43_r.png"&amp;gt;                             图5</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-ef5ad0d06a316f762f0625b2468e2f43_b.png" data-rawwidth="776" data-rawheight="174" class="origin_image zh-lightbox-thumb lazy" width="776" data-original="https://pic4.zhimg.com/v2-ef5ad0d06a316f762f0625b2468e2f43_r.png" data-actualsrc="https://pic4.zhimg.com/v2-ef5ad0d06a316f762f0625b2468e2f43_b.png"><p>                             图5</p><p>我们知道，像上面这样，从左至右容易算出来。但反过来呢，我们上面讲到，测试集有图片，也有预期的正确答案，要反过来求w1，w2......，怎么办？</p>绕了半天，终于该求偏导出场了。目前的情况是：<br>1.我们假定一个神经网络已经定义好，比如有多少层，每层有多少个节点，也有默认的权重和激活函数（后面讲）等。这个没办法，刚开始得有一个初始值。你喜欢一个美女，她也不是刚从娘胎里出来的，也是带有各种默认参数的。至于怎么调教，那就得求偏导。<br>2.我们已知正确答案，比如图2和3里的r，训练的时候，是从左至右计算，得出的结果为y，r与y一般来说是不一样的。那么他们之间的差距，就是图2和3里的E。这个差距怎么算？当然，直接相减是一个办法，尤其是对于只有一个输出的情况，比如图2； 但很多时候，其实像图3里的那样，那么这个差距，一般可以这样算，当然，还可以有其他的评估办法，只是函数不同而已，作用是类似的：<br><noscript>&amp;lt;img src="https://pic4.zhimg.com/v2-e5ddd26d65aa04ed82f2a51fc8212427_b.png" data-rawwidth="484" data-rawheight="102" class="origin_image zh-lightbox-thumb" width="484" data-original="https://pic4.zhimg.com/v2-e5ddd26d65aa04ed82f2a51fc8212427_r.png"&amp;gt;不得不说，理想跟现实还是有差距的，我们当然是希望差距越小越好，怎么才能让差距越来越小呢？得调整参数呗，因为输入（图像）确定的情况下，只有调整参数才能改变输出的值。怎么调整，怎么磨合？刚才我们讲到，每个参数都有一个默认值，我们就对每个参数加上一定的数值∆，然后看看结果如何？如果参数调大，差距也变大，你懂的，那就得减小∆，因为我们的目标是要让差距变小；反之亦然。所以为了把参数调整到最佳，我们需要了解误差对每个参数的变化率，这不就是求误差对于该参数的偏导数嘛。</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-e5ddd26d65aa04ed82f2a51fc8212427_b.png" data-rawwidth="484" data-rawheight="102" class="origin_image zh-lightbox-thumb lazy" width="484" data-original="https://pic4.zhimg.com/v2-e5ddd26d65aa04ed82f2a51fc8212427_r.png" data-actualsrc="https://pic4.zhimg.com/v2-e5ddd26d65aa04ed82f2a51fc8212427_b.png"><p>不得不说，理想跟现实还是有差距的，我们当然是希望差距越小越好，怎么才能让差距越来越小呢？得调整参数呗，因为输入（图像）确定的情况下，只有调整参数才能改变输出的值。怎么调整，怎么磨合？刚才我们讲到，每个参数都有一个默认值，我们就对每个参数加上一定的数值∆，然后看看结果如何？如果参数调大，差距也变大，你懂的，那就得减小∆，因为我们的目标是要让差距变小；反之亦然。所以为了把参数调整到最佳，我们需要了解误差对每个参数的变化率，这不就是求误差对于该参数的偏导数嘛。</p><p>关键是怎么求偏导。图2和图3分别给了推导的方法，其实很简单，从右至左挨个求偏导就可以。相邻层的求偏导其实很简单，因为是线性的，所以偏导数其实就是参数本身嘛，就跟求解x₃的偏导类似。然后把各个偏导相乘就可以了。</p>这里有两个点：<br>一个是激活函数，其实激活函数也没啥，就是为了让每个节点的输出都在0到1的区间，这样好算账嘛，所以在结果上面再做了一层映射，反正都是一对一的。由于激活函数的存在，所以在求偏导的时候，也要把它算进去，激活函数，一般用sigmoid，也可以用Relu等。激活函数的求导其实也非常简单：<br><noscript>&amp;lt;img src="https://pic2.zhimg.com/v2-a9311523c35a3558844d1edc22cee9ed_b.jpg" data-rawwidth="257" data-rawheight="159" class="content_image" width="257"&amp;gt;求导： f'(x)=f(x)*[1-f(x)]</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-a9311523c35a3558844d1edc22cee9ed_b.jpg" data-rawwidth="257" data-rawheight="159" class="content_image lazy" width="257" data-actualsrc="https://pic2.zhimg.com/v2-a9311523c35a3558844d1edc22cee9ed_b.jpg"><p>求导： f'(x)=f(x)*[1-f(x)]<br>这个方面，有时间可以翻看一下高数，没时间，直接记住就行了。<br>至于Relu，那就更简单了，就是f(x) 当x&lt;0的时候y等于0，其他时候，y等于x。<br>当然，你也可以定义你自己的Relu函数，比如x大于等于0的时候，y等于0.01x，也可以。</p><p>另一个是学习系数，为什么叫学习系数？刚才我们上面讲到∆增量，到底每次增加多少合适？是不是等同于偏导数（变化率）？经验告诉我们，需要乘以一个百分比，这个就是学习系数，而且，随着训练的深入，这个系数是可以变的。</p><p>当然，还有一些很重要的基本知识，比如SGD（随机梯度下降），mini batch 和 epoch（用于训练集的选择），限于篇幅，以后再侃吧。其实参考李宏毅的那篇文章就可以了。</p><p>这篇拙文，算是对我另一个回答的补充吧：<br><a href="https://www.zhihu.com/question/31785984/answer/129108774?from=profile_answer_card" class="internal">深度学习入门必看的书和论文？有哪些必备的技能需学习？ - jacky yang 的回答</a></p><p>其实上面描述的，主要是关于怎么调整参数，属于初级阶段。上面其实也提到，在调参之前，都有默认的网络模型和参数，如何定义最初始的模型和参数？就需要进一步深入了解。<br>不过对于一般做工程而言，只需要在默认的网络上调参就可以了，相当于用算法；<br>对于学者和科学家而言，他们会发明算法，难度还是不小的。向他们致敬！</p><p>写得很辛苦，觉得好就给我点个赞吧:）</p>------------------------------------------------------------------------------------------------<br>关于求偏导的推导过程，我尽快抽时间，把数学公式用通俗易懂的语言详细描述一下，前一段时间比较忙，抱歉:)<br>------------------------------------------------------------------------------------------------</span><div class="ContentItem-time"><a href="https://www.zhihu.com/question/26006703/answer/129209540" target="_blank"><span data-tooltip="发布于 2016-10-31"><!-- react-text: 189 -->编辑于 <!-- /react-text --><!-- react-text: 190 -->2017-02-03<!-- /react-text --></span></a></div><!-- react-empty: 191 --></div></div></div><div><div class="ContentItem-actions Sticky is-bottom"><span><button class="VoteButton VoteButton--up" aria-label="赞同"><svg viewBox="0 0 20 18" class="Icon VoteButton-upIcon Icon--triangle" width="9" height="16" aria-hidden="true" style="height: 16px; width: 9px;"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"></path></g></svg><!-- react-text: 625 -->3697<!-- /react-text --></button><button class="VoteButton VoteButton--down" aria-label="反对"><svg viewBox="0 0 20 18" class="Icon VoteButton-downIcon Icon--triangle" width="9" height="16" aria-hidden="true" style="height: 16px; width: 9px;"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"></path></g></svg></button></span><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 18 18" class="Icon Icon--comment Icon--left" width="12" height="16" aria-hidden="true" style="height: 16px; width: 12px;"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"></path></g></svg><!-- react-text: 634 -->115 条评论<!-- /react-text --><!-- react-empty: 635 --></button><div class="Popover ShareMenu ContentItem-action"><div id="Popover-73701-14143-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73701-14143-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" class="Icon Icon--share Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"></path></g></svg><!-- react-text: 642 -->分享<!-- /react-text --></button></div><!-- react-empty: 643 --></div><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"></path></g></svg><!-- react-text: 648 -->收藏<!-- /react-text --><!-- react-empty: 649 --></button><button class="Button ContentItem-action Button--plain" type="button"><svg width="14" height="16" viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--thank Icon--left" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><path d="M0 5.437C0 2.505 2.294.094 5.207 0 7.243 0 9.092 1.19 10 3c.823-1.758 2.65-3 4.65-3C17.546 0 20 2.507 20 5.432 20 13.24 11.842 18 10 18 8.158 18 0 13.24 0 5.437z" fill-rule="evenodd"></path></g></svg><!-- react-text: 654 -->感谢<!-- /react-text --></button><div class="Popover ContentItem-action"><button class="Button Button--plain" type="button" id="Popover-73708-56979-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73708-56979-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" width="14" height="16" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><g><circle cx="2" cy="2" r="2"></circle><circle cx="9" cy="2" r="2"></circle><circle cx="16" cy="2" r="2"></circle></g></g></svg></button><!-- react-empty: 660 --></div><button class="Button ContentItem-action ContentItem-rightButton Button--plain" type="button"><!-- react-text: 662 -->收起<!-- /react-text --><svg viewBox="0 0 10 6" class="Icon ContentItem-arrowIcon is-active Icon--arrow" width="10" height="16" aria-hidden="true" style="height: 16px; width: 10px;"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"></path></g></svg></button></div></div></div><!-- react-empty: 239 --><!-- react-empty: 240 --></div></div></div><div class="Card"><div class="QuestionMainDivider"><span class="QuestionMainDivider-inner">更多回答</span></div><div class="List"><div class="List-item"><div data-za-module="AnswerItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Answer&quot;,&quot;token&quot;:&quot;90969591&quot;,&quot;upvote_num&quot;:3359,&quot;comment_num&quot;:105,&quot;publish_timestamp&quot;:null,&quot;parent_token&quot;:&quot;26006703&quot;,&quot;author_member_hash_id&quot;:&quot;7e6bee8b4c8c826d76230cd6c139fa27&quot;}}}"><div class="ContentItem" data="[object Object]"><div class="ContentItem-meta"><div class="AnswerItem-meta AnswerItem-meta--related"><div class="AuthorInfo"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover-73329-50620-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73329-50620-content"><a class="UserLink-link" href="https://www.zhihu.com/people/heamon7"><img class="Avatar AuthorInfo-avatar" src="./深度学习如何入门？ - 知乎_files/54e051a383587384b68fdf5578e43c37_xs.png" srcset="https://pic4.zhimg.com/54e051a383587384b68fdf5578e43c37_l.png 2x" alt="袁哲" style="width: 38px; height: 38px;"></a></div><!-- react-empty: 471 --></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-title"><div class="AuthorInfo-name"><span class="UserLink"><div class="Popover"><div id="Popover-73330-97579-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73330-97579-content"><a class="UserLink-link" href="https://www.zhihu.com/people/heamon7">袁哲</a></div><!-- react-empty: 479 --></div></span></div></div><div class="RichText AuthorInfo-badge">真实，安静，从容</div></div></div><div class="AnswerItem-extraInfo"><span class="Voters"><button class="Button Button--plain" type="button">3359 人赞同了该回答</button><!-- react-empty: 484 --></span></div></div></div><div class="ContentItem-content is-collapsed ContentItem-content--unescapable"><div><div><span class="RichText CopyrightRichText-richText">Github 上有同学总结了一份 机器学习和深度学习资料列表 ,共两篇，总计接近 1000 条。<br>原文第一篇如下：<br><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/dl.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">Qix/dl.md at master · ty4z2008/Qix · GitHub<i class="icon-external"></i></a><br><blockquote>机器学习(Machine Learning)&amp;深度学习(Deep Learning)资料(Chapter 1)<a class=" wrap external" href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/dl.md%23%25E6%25B3%25A8%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E8%25B5%2584%25E6%2596%2599%25E7%25AF%2587%25E7%259B%25AE%25E4%25B8%2580%25E5%2585%25B1500%25E6%259D%25A1%25E7%25AF%2587%25E7%259B%25AE%25E4%25BA%258C%25E5%25BC%2580%25E5%25A7%258B%25E6%259B%25B4%25E6%2596%25B0" target="_blank" rel="nofollow noreferrer">Qix/dl.md at master · ty4z2008/Qix · GitHub<i class="icon-external"></i></a>注:机器学习资料<a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/dl.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">篇目一<i class="icon-external"></i></a>共500条,<a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/dl2.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">篇目二<i class="icon-external"></i></a>开始更新<a class=" wrap external" href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/dl.md%23%25E5%25B8%258C%25E6%259C%259B%25E8%25BD%25AC%25E8%25BD%25BD%25E7%259A%2584%25E6%259C%258B%25E5%258F%258B%25E4%25BD%25A0%25E5%258F%25AF%25E4%25BB%25A5%25E4%25B8%258D%25E7%2594%25A8%25E8%2581%2594%25E7%25B3%25BB%25E6%2588%2591%25E4%25BD%2586%25E6%2598%25AF%25E4%25B8%2580%25E5%25AE%259A%25E8%25A6%2581%25E4%25BF%259D%25E7%2595%2599%25E5%258E%259F%25E6%2596%2587%25E9%2593%25BE%25E6%258E%25A5%25E5%259B%25A0%25E4%25B8%25BA%25E8%25BF%2599%25E4%25B8%25AA%25E9%25A1%25B9%25E7%259B%25AE%25E8%25BF%2598%25E5%259C%25A8%25E7%25BB%25A7%25E7%25BB%25AD%25E4%25B9%259F%25E5%259C%25A8%25E4%25B8%258D%25E5%25AE%259A%25E6%259C%259F%25E6%259B%25B4%25E6%2596%25B0%25E5%25B8%258C%25E6%259C%259B%25E7%259C%258B%25E5%2588%25B0%25E6%2596%2587%25E7%25AB%25A0%25E7%259A%2584%25E6%259C%258B%25E5%258F%258B%25E8%2583%25BD%25E5%25A4%259F%25E5%25AD%25A6%25E5%2588%25B0%25E6%259B%25B4%25E5%25A4%259A%25E6%25AD%25A4%25E5%25A4%2596%25E6%259F%2590%25E4%25BA%259B%25E8%25B5%2584%25E6%2596%2599%25E5%259C%25A8%25E4%25B8%25AD%25E5%259B%25BD%25E8%25AE%25BF%25E9%2597%25AE%25E9%259C%2580%25E8%25A6%2581%25E6%25A2%25AF%25E5%25AD%2590" target="_blank" rel="nofollow noreferrer">Qix/dl.md at master · ty4z2008/Qix · GitHub<i class="icon-external"></i></a>希望转载的朋友，你可以不用联系我．但是<strong>一定要保留原文链接</strong>，因为这个项目还在继续也在不定期更新．希望看到文章的朋友能够学到更多．此外:某些资料在中国访问需要梯子.<ul><li><a href="https://link.zhihu.com/?target=http%3A//www.erogol.com/brief-history-machine-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Brief History of Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:这是一篇介绍机器学习历史的文章，介绍很全面，从感知机、神经网络、决策树、SVM、Adaboost到随机森林、Deep Learning.<a href="https://link.zhihu.com/?target=http%3A//www.almosthuman.cn/2016/01/23/koarh/" class=" wrap external" target="_blank" rel="nofollow noreferrer">译文part1<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.idsia.ch/%7Ejuergen/DeepLearning15May2014.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning in Neural Networks: An Overview》<i class="icon-external"></i></a></li></ul><p>介绍:这是瑞士人工智能实验室Jurgen Schmidhuber写的最新版本《神经网络与深度学习综述》本综述的特点是以时间排序，从1940年开始讲起，到60-80年代，80-90年代，一直讲到2000年后及最近几年的进展。涵盖了deep learning里各种tricks，引用非常全面.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Gentle Introduction to Scikit-Learn: A Python Machine Learning Library》<i class="icon-external"></i></a></li></ul><p>介绍:这是一份python机器学习库,如果您是一位python工程师而且想深入的学习机器学习.那么这篇文章或许能够帮助到你.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearningmastery.com/how-to-layout-and-manage-your-machine-learning-project/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《How to Layout and Manage Your Machine Learning Project》<i class="icon-external"></i></a></li></ul><p>介绍:这一篇介绍如果设计和管理属于你自己的机器学习项目的文章，里面提供了管理模版、数据管理与实践方法.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//medium.com/code-poet/80ea3ec3c471" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning is Fun!》<i class="icon-external"></i></a></li></ul><p>介绍:如果你还不知道什么是机器学习，或则是刚刚学习感觉到很枯燥乏味。那么推荐一读。这篇文章已经被翻译成中文,如果有兴趣可以移步<a href="https://link.zhihu.com/?target=http%3A//blog.jobbole.com/67616/" class=" wrap external" target="_blank" rel="nofollow noreferrer">有趣的机器学习：最简明入门指南<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cran.r-project.org/doc/contrib/Liu-R-refcard.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《R语言参考卡片》<i class="icon-external"></i></a></li></ul><p>介绍:R语言是机器学习的主要语言,有很多的朋友想学习R语言，但是总是忘记一些函数与关键字的含义。那么这篇文章或许能够帮助到你</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Choosing a Machine Learning Classifier》<i class="icon-external"></i></a></li></ul><p>介绍:我该如何选择机器学习算法，这篇文章比较直观的比较了Naive Bayes，Logistic Regression，SVM，决策树等方法的优劣，另外讨论了样本大小、Feature与Model权衡等问题。此外还有已经翻译了的版本:<a href="https://link.zhihu.com/?target=http%3A//www.52ml.net/15063.html" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://www.</span><span class="visible">52ml.net/15063.html</span><span class="invisible"></span><i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Introduction to Deep Learning: From Perceptrons to Deep Networks》<i class="icon-external"></i></a></li></ul><p>介绍：深度学习概述：从感知机到深度网络，作者对于例子的选择、理论的介绍都很到位，由浅入深。翻译版本：<a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/xiaowanyer/p/3701944.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">深度学习概述：从感知机到深度网络<i class="icon-external"></i></a></p><ul><li><p><a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/s/ayG13we2vxyKl" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The LION Way: Machine Learning plus Intelligent Optimization》<i class="icon-external"></i></a></p><p>介绍:&lt;机器学习与优化&gt;这是一本机器学习的小册子, 短短300多页道尽机器学习的方方面面. 图文并茂, 生动易懂, 没有一坨坨公式的烦恼. 适合新手入门打基础, 也适合老手温故而知新. 比起MLAPP/PRML等大部头, 也许这本你更需要!具体内容推荐阅读:<a href="https://link.zhihu.com/?target=http%3A//intelligent-optimization.org/LIONbook/" class=" wrap external" target="_blank" rel="nofollow noreferrer">LIONbook - intelligent-optimization.org for prescriptive analytics<i class="icon-external"></i></a></p></li><li><p><a href="https://link.zhihu.com/?target=http%3A//1.guzili.sinaapp.com/%3Fp%3D174" class=" wrap external" target="_blank" rel="nofollow noreferrer">《深度学习与统计学习理论》<i class="icon-external"></i></a></p></li></ul><p>介绍:作者是来自百度，不过他本人已经在2014年4月份申请离职了。但是这篇文章很不错如果你不知道深度学习与支持向量机/统计学习理论有什么联系？那么应该立即看看这篇文章.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/readings/MIT6_042JF10_notes.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《计算机科学中的数学》<i class="icon-external"></i></a></li></ul><p>介绍:这本书是由谷歌公司和MIT共同出品的计算机科学中的数学：<a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/Mathematics%2520for%2520Computer%2520Science" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mathematics for Computer Science<i class="icon-external"></i></a>，Eric Lehman et al 2013 。分为5大部分：1）证明，归纳。2）结构，数论，图。3）计数，求和，生成函数。4）概率，随机行走。5）递归。等等</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/en-US/people/kannan/book-no-solutions-aug-21-2014.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《信息时代的计算机科学理论(Foundations of Data Science)》<i class="icon-external"></i></a></li></ul><p>介绍：信息时代的计算机科学理论,目前国内有纸质书购买，<a href="https://link.zhihu.com/?target=https%3A//itunes.apple.com/us/book/introduction-to-data-science/id529088127" class=" wrap external" target="_blank" rel="nofollow noreferrer">iTunes购买<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/s/ayG13we2vx5qg" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Data Science with R》<i class="icon-external"></i></a></li></ul><p>介绍:这是一本由雪城大学新编的第二版《数据科学入门》教材：偏实用型，浅显易懂，适合想学习R语言的同学选读。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.informit.com/articles/article.aspx%3Fp%3D2213858" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Twenty Questions for Donald Knuth》<i class="icon-external"></i></a></li></ul><p>介绍:这并不是一篇文档或书籍。这是篇向图灵奖得主Donald Knuth提问记录稿： 近日， Charles Leiserson, Al Aho, Jon Bentley等大神向Knuth提出了20个问题，内容包括TAOCP，P/NP问题，图灵机，逻辑，以及为什么大神不用电邮等等。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1402.4304v2.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Automatic Construction and Natural-Language Description of Nonparametric Regression Models》<i class="icon-external"></i></a></li></ul><p>介绍：不会统计怎么办？不知道如何选择合适的统计模型怎么办？那这篇文章你的好好读一读了麻省理工Joshua B. Tenenbaum和剑桥Zoubin Ghahramani合作，写了一篇关于automatic statistician的文章。可以自动选择回归模型类别，还能自动写报告...</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//openreview.net/venue/iclr2014" class=" wrap external" target="_blank" rel="nofollow noreferrer">《ICLR 2014论文集》<i class="icon-external"></i></a></li></ul><p>介绍:对深度学习和representation learning最新进展有兴趣的同学可以了解一下</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www-nlp.stanford.edu/IR-book/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Information Retrieval》<i class="icon-external"></i></a></li></ul><p>介绍：这是一本信息检索相关的书籍，是由斯坦福Manning与谷歌副总裁Raghavan等合著的Introduction to Information Retrieval一直是北美最受欢迎的信息检索教材之一。最近作者增加了该课程的幻灯片和作业。IR相关资源：<a href="https://link.zhihu.com/?target=http%3A//www-nlp.stanford.edu/IR-book/information-retrieval.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Information Retrieval Resources<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.denizyuret.com/2014/02/machine-learning-in-5-pictures.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine learning in 10 pictures》<i class="icon-external"></i></a></li></ul><p>介绍:Deniz Yuret用10张漂亮的图来解释机器学习重要概念：1. Bias/Variance Tradeoff 2. Overfitting 3. Bayesian / Occam's razor 4. Feature combination 5. Irrelevant feature 6. Basis function 7. Discriminative / Generative 8. Loss function 9. Least squares 10. Sparsity.很清晰</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//webscope.sandbox.yahoo.com/catalog.php%3Fdatatype%3Dl" class=" wrap external" target="_blank" rel="nofollow noreferrer">《雅虎研究院的数据集汇总》<i class="icon-external"></i></a></li></ul><p>介绍：雅虎研究院的数据集汇总： 包括语言类数据，图与社交类数据，评分与分类数据，计算广告学数据，图像数据，竞赛数据，以及系统类的数据。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www-bcf.usc.edu/%7Egareth/ISL/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Introduction to Statistical Learning with Applications in R》<i class="icon-external"></i></a></li></ul><p>介绍：这是一本斯坦福统计学著名教授Trevor Hastie和Robert Tibshirani的新书，并且在2014年一月已经开课：<a href="https://link.zhihu.com/?target=https%3A//class.stanford.edu/courses/HumanitiesScience/StatLearning/Winter2014/about" class=" wrap external" target="_blank" rel="nofollow noreferrer">Statistical Learning<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearningmastery.com/best-machine-learning-resources-for-getting-started/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Best Machine Learning Resources for Getting Started<i class="icon-external"></i></a></li></ul><p>介绍：机器学习最佳入门学习资料汇总是专为机器学习初学者推荐的优质学习资源，帮助初学者快速入门。而且这篇文章的介绍已经被翻译成<a href="https://link.zhihu.com/?target=http%3A//article.yeeyan.org/view/22139/410514" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>。如果你不怎么熟悉，那么我建议你先看一看中文的介绍。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_bda0d2f10101fpp4.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">My deep learning reading list<i class="icon-external"></i></a></li></ul><p>介绍:主要是顺着Bengio的PAMI review的文章找出来的。包括几本综述文章，将近100篇论文，各位山头们的Presentation。全部都可以在google上找到。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.morganclaypool.com/doi/abs/10.2200/S00266ED1V01Y201005HLT008%3FjournalCode%3Dhlt" class=" wrap external" target="_blank" rel="nofollow noreferrer">Cross-Language Information Retrieval<i class="icon-external"></i></a></li></ul><p>介绍：这是一本书籍，主要介绍的是跨语言信息检索方面的知识。理论很多</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html%3Fca%3Ddrs-" class=" wrap external" target="_blank" rel="nofollow noreferrer">探索推荐引擎内部的秘密，第 1 部分: 推荐引擎初探<i class="icon-external"></i></a></li></ul><p>介绍:本文共有三个系列，作者是来自IBM的工程师。它主要介绍了推荐引擎相关算法，并帮助读者高效的实现这些算法。 <a href="https://link.zhihu.com/?target=http%3A//www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy2/index.html%3Fca%3Ddrs-" class=" wrap external" target="_blank" rel="nofollow noreferrer">探索推荐引擎内部的秘密，第 2 部分: 深度推荐引擎相关算法 - 协同过滤<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy3/index.html%3Fca%3Ddrs-" class=" wrap external" target="_blank" rel="nofollow noreferrer">探索推荐引擎内部的秘密，第 3 部分: 深度推荐引擎相关算法 - 聚类<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//mimno.infosci.cornell.edu/b/articles/ml-learn/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Advice for students of machine learning》<i class="icon-external"></i></a></li></ul><p>介绍：康奈尔大学信息科学系助理教授David Mimno写的《对机器学习初学者的一点建议》， 写的挺实际，强调实践与理论结合，最后还引用了冯 • 诺依曼的名言: "Young man, in mathematics you don't understand things. You just get used to them."</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//web.stanford.edu/group/pdplab/pdphandbook/" class=" wrap external" target="_blank" rel="nofollow noreferrer">分布式并行处理的数据<i class="icon-external"></i></a></li></ul><p>介绍：这是一本关于分布式并行处理的数据《Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises》,作者是斯坦福的James L. McClelland。着重介绍了各种神级网络算法的分布式实现,做Distributed Deep Learning 的童鞋可以参考下</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blogs.technet.com/b/machinelearning/archive/2014/07/01/what-is-machine-learning.aspx" class=" wrap external" target="_blank" rel="nofollow noreferrer">《“机器学习”是什么？》<i class="icon-external"></i></a></li></ul><p>介绍:【“机器学习”是什么？】John Platt是微软研究院杰出科学家，17年来他一直在机器学习领域耕耘。近年来机器学习变得炙手可热，Platt和同事们遂决定开设<a href="https://link.zhihu.com/?target=http%3A//blogs.technet.com/b/machinelearning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客<i class="icon-external"></i></a>，向公众介绍机器学习的研究进展。机器学习是什么，被应用在哪里？来看Platt的这篇<a href="https://link.zhihu.com/?target=http%3A//blogs.technet.com/b/machinelearning/archive/2014/07/01/what-is-machine-learning.aspx" class=" wrap external" target="_blank" rel="nofollow noreferrer">博文<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//icml.cc/2014/index/article/15.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">《2014年国际机器学习大会ICML 2014 论文》<i class="icon-external"></i></a></li></ul><p>介绍：2014年国际机器学习大会（ICML）已经于6月21-26日在国家会议中心隆重举办。本次大会由微软亚洲研究院和清华大学联手主办，是这个有着30多年历史并享誉世界的机器学习领域的盛会首次来到中国，已成功吸引海内外1200多位学者的报名参与。干货很多，值得深入学习下</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blogs.technet.com/b/machinelearning/archive/2014/07/11/machine-learning-for-industry-a-case-study.aspx" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning for Industry: A Case Study》<i class="icon-external"></i></a></li></ul><p>介绍：这篇文章主要是以Learning to Rank为例说明企业界机器学习的具体应用，RankNet对NDCG之类不敏感，加入NDCG因素后变成了LambdaRank，同样的思想从神经网络改为应用到Boosted Tree模型就成就了LambdaMART。<a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/en-us/people/cburges/%3FWT.mc_id%3DBlog_MachLearn_General_DI" class=" wrap external" target="_blank" rel="nofollow noreferrer">Chirs Burges<i class="icon-external"></i></a>，微软的机器学习大神，Yahoo 2010 Learning to Rank Challenge第一名得主，排序模型方面有RankNet，LambdaRank，LambdaMART，尤其以LambdaMART最为突出，代表论文为： <a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/en-us/um/people/cburges/tech_reports/msr-tr-2010-82.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">From RankNet to LambdaRank to LambdaMART: An Overview<i class="icon-external"></i></a> 此外，Burges还有很多有名的代表作，比如：<a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/pubs/67119/svmtutorial.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">A Tutorial on Support Vector Machines for Pattern Recognition<i class="icon-external"></i></a><br><a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/en-us/um/people/cburges/tech_reports/tr-2004-56.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Some Notes on Applied Mathematics for Machine Learning<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//meta-guide.com/software-meta-guide/100-best-github-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">100 Best GitHub: Deep Learning<i class="icon-external"></i></a></li></ul><p>介绍:100 Best GitHub: Deep Learning</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.52ml.net/12019.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《UFLDL-斯坦福大学Andrew Ng教授“Deep Learning”教程》<i class="icon-external"></i></a></li></ul><p>介绍:本教程将阐述无监督特征学习和深度学习的主要观点。通过学习，你也将实现多个功能学习/深度学习算法，能看到它们为你工作，并学习如何应用/适应这些想法到新问题上。本教程假定机器学习的基本知识（特别是熟悉的监督学习，逻辑回归，梯度下降的想法），如果你不熟悉这些想法，我们建议你去这里<a href="https://link.zhihu.com/?target=http%3A//openclassroom.stanford.edu/MainFolder/CoursePage.php%3Fcourse%3DMachineLearning" class=" wrap external" target="_blank" rel="nofollow noreferrer">机器学习课程<i class="icon-external"></i></a>，并先完成第II，III，IV章（到逻辑回归）。此外这关于这套教程的源代码在github上面已经有python版本了<a href="https://link.zhihu.com/?target=https%3A//github.com/jatinshah/ufldl_tutorial" class=" wrap external" target="_blank" rel="nofollow noreferrer"> UFLDL Tutorial Code<i class="icon-external"></i></a></p><p>*<a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/pubs/217165/ICASSP_DeepTextLearning_v07.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning for Natural Language Processing and Related Applications》<i class="icon-external"></i></a></p><p>介绍:这份文档来自微软研究院,精髓很多。如果需要完全理解，需要一定的机器学习基础。不过有些地方会让人眼前一亮,毛塞顿开。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//colah.github.io/posts/2014-07-Understanding-Convolutions/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Understanding Convolutions<i class="icon-external"></i></a></li></ul><p>介绍:这是一篇介绍图像卷积运算的文章，讲的已经算比较详细的了</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//mlss2014.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Summer School》<i class="icon-external"></i></a></li></ul><p>介绍：每天请一个大牛来讲座，主要涉及机器学习，大数据分析，并行计算以及人脑研究。<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/user/smolix" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">youtube.com/user/smolix</span><span class="invisible"></span><i class="icon-external"></i></a> （需翻墙）</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/josephmisiti/awesome-machine-learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Awesome Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍：一个超级完整的机器学习开源库总结，如果你认为这个碉堡了，那后面这个列表会更让你惊讶：【Awesome Awesomeness】,国内已经有热心的朋友进行了翻译<a href="https://link.zhihu.com/?target=http%3A//blog.jobbole.com/73806/" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文介绍<i class="icon-external"></i></a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/josephmisiti/awesome-machine-learning/blob/master/books.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">机器学习数据挖掘免费电子书<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//see.stanford.edu/see/lecturelist.aspx%3Fcoll%3D63480b48-8819-4efd-8412-263f1a472f5a" class=" wrap external" target="_blank" rel="nofollow noreferrer">斯坦福《自然语言处理》课程视频<i class="icon-external"></i></a></li></ul><p>介绍:ACL候任主席、斯坦福大学计算机系Chris Manning教授的《自然语言处理》课程所有视频已经可以在斯坦福公开课网站上观看了（如Chrome不行，可用IE观看） 作业与测验也可以下载。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//freemind.pluskid.org/machine-learning/deep-learning-and-shallow-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning and Shallow Learning》<i class="icon-external"></i></a></li></ul><p>介绍:对比 Deep Learning 和 Shallow Learning 的好文，来着浙大毕业、MIT 读博的 Chiyuan Zhang 的博客。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//benanne.github.io/2014/08/05/spotify-cnns.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Recommending music on Spotify with deep learning》<i class="icon-external"></i></a></li></ul><p>介绍:利用卷积神经网络做音乐推荐。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//neuralnetworksanddeeplearning.com/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Neural Networks and Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍：神经网络的免费在线书，已经写了三章了，还有对应的开源代码：<a href="https://link.zhihu.com/?target=https%3A//github.com/mnielsen/neural-networks-and-deep-learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">GitHub - mnielsen/neural-networks-and-deep-learning: Code samples for my book "Neural Networks and Deep Learning"<i class="icon-external"></i></a> 爱好者的福音。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearningmastery.com/java-machine-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Java Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍：Java机器学习相关平台和开源的机器学习库，按照大数据、NLP、计算机视觉和Deep Learning分类进行了整理。看起来挺全的，Java爱好者值得收藏。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.oschina.net/translate/6-tips-for-writing-better-code" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Theory: An Introductory Primer》<i class="icon-external"></i></a></li></ul><p>介绍：机器学习最基本的入门文章，适合零基础者</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ctocio.com/hotnews/15919.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习常见算法分类汇总》<i class="icon-external"></i></a></li></ul><p>介绍：机器学习的算法很多。很多时候困惑人们都是，很多算法是一类算法，而有些算法又是从其他算法中延伸出来的。这里，我们从两个方面来给大家介绍，第一个方面是学习的方式，第二个方面是算法的类似性。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//suanfazu.com/discussion/68/%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E7%25BB%258F%25E5%2585%25B8%25E8%25AE%25BA%25E6%2596%2587survey%25E5%2590%2588%25E9%259B%2586" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习经典论文/survey合集》<i class="icon-external"></i></a></li></ul><p>介绍：看题目你已经知道了是什么内容,没错。里面有很多经典的机器学习论文值得仔细与反复的阅读。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//work.caltech.edu/library/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习视频库》<i class="icon-external"></i></a></li></ul><p>介绍：视频由加州理工学院（Caltech）出品。需要英语底子。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//suanfazu.com/discussion/109/%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E7%25BB%258F%25E5%2585%25B8%25E4%25B9%25A6%25E7%25B1%258D" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习经典书籍》<i class="icon-external"></i></a></li></ul><p>介绍：总结了机器学习的经典书籍，包括数学基础和算法理论的书籍，可做为入门参考书单。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//efytimes.com/e1/fullnews.asp%3Fedid%3D121516" class=" wrap external" target="_blank" rel="nofollow noreferrer">《16 Free eBooks On Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:16本机器学习的电子书，可以下载下来在pad，手机上面任意时刻去阅读。不多我建议你看完一本再下载一本。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.erogol.com/large-set-machine-learning-resources-beginners-mavens/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Large set of Machine Learning Resources for Beginners to Mavens》<i class="icon-external"></i></a></li></ul><p>介绍:标题很大，从新手到专家。不过看完上面所有资料。肯定是专家了</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//article.yeeyan.org/view/22139/410514" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习最佳入门学习资料汇总》<i class="icon-external"></i></a></li></ul><p>介绍：入门的书真的很多，而且我已经帮你找齐了。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//users.soe.ucsc.edu/%7Eniejiazhong/slides/chandra.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Sibyl》<i class="icon-external"></i></a></li></ul><p>介绍：Sibyl 是一个监督式机器学习系统，用来解决预测方面的问题，比如 YouTube 的视频推荐。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.iro.umontreal.ca/%7Ebengioy/dlbook/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍：Yoshua Bengio, Ian Goodfellow, Aaron Courville著</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.slideshare.net/ssuser9cc1bd/piji-li-dltm" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Neural Network &amp; Text Mining》<i class="icon-external"></i></a></li></ul><p>介绍:关于(Deep) Neural Networks在 NLP 和 Text Mining 方面一些paper的总结</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/lxy2017/p/3927226.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《前景目标检测1（总结）》<i class="icon-external"></i></a></li></ul><p>介绍:计算机视觉入门之前景目标检测1（总结）</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.52ml.net/17004.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《行人检测》<i class="icon-external"></i></a></li></ul><p>介绍:计算机视觉入门之行人检测</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.kdnuggets.com/2014/08/deep-learning-important-resources-learning-understanding.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning – important resources for learning and understanding》<i class="icon-external"></i></a></li></ul><p>介绍:Important resources for learning and understanding . Is awesome</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Theory: An Introductory Primer》<i class="icon-external"></i></a></li></ul><p>介绍:这又是一篇机器学习初学者的入门文章。值得一读</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//neuralnetworksanddeeplearning.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Neural Networks and Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍:在线Neural Networks and Deep Learning电子书</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/python-%25E7%25BD%2591%25E9%25A1%25B5%25E7%2588%25AC%25E8%2599%25AB-%25E6%2596%2587%25E6%259C%25AC%25E5%25A4%2584%25E7%2590%2586-%25E7%25A7%2591%25E5%25AD%25A6%25E8%25AE%25A1%25E7%25AE%2597-%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0-%25E6%2595%25B0%25E6%258D%25AE%25E6%258C%2596%25E6%258E%2598" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Python 网页爬虫 &amp; 文本处理 &amp; 科学计算 &amp; 机器学习 &amp; 数据挖掘兵器谱》<i class="icon-external"></i></a></li></ul><p>介绍:python的17个关于机器学习的工具</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.flickering.cn/%25E6%25A6%2582%25E7%258E%2587%25E7%25BB%259F%25E8%25AE%25A1/2014/06/%25E7%25A5%259E%25E5%25A5%2587%25E7%259A%2584%25E4%25BC%25BD%25E7%258E%259B%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258A/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《神奇的伽玛函数(上)》<i class="icon-external"></i></a></li></ul><p>介绍:下集在这里<a href="https://link.zhihu.com/?target=http%3A//www.flickering.cn/%25E6%25A6%2582%25E7%258E%2587%25E7%25BB%259F%25E8%25AE%25A1/2014/06/%25E7%25A5%259E%25E5%25A5%2587%25E7%259A%2584%25E4%25BC%25BD%25E7%258E%259B%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258A/" class=" wrap external" target="_blank" rel="nofollow noreferrer">神奇的伽玛函数(下)<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cxwangyi.github.io/notes/2014-01-20-distributed-machine-learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《分布式机器学习的故事》<i class="icon-external"></i></a></li></ul><p>介绍:作者王益目前是腾讯广告算法总监，王益博士毕业后在google任研究。这篇文章王益博士7年来从谷歌到腾讯对于分布机器学习的所见所闻。值得细读</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//metacademy.org/roadmaps/cjrd/level-up-your-ml" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习提升之道（Level-Up Your Machine Learning）》<i class="icon-external"></i></a></li></ul><p>介绍:把机器学习提升的级别分为0~4级，每级需要学习的教材和掌握的知识。这样，给机器学习者提供一个上进的路线图，以免走弯路。另外，整个网站都是关于机器学习的，资源很丰富。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.mlsurveys.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Surveys》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习各个方向综述的网站</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning.net/reading-list/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning Reading list》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习阅资源列表</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/pubs/219984/DeepLearningBook_RefsByLastFirstNames.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning: Methods and Applications》<i class="icon-external"></i></a></li></ul><p>介绍：这是一本来自微的研究员 li Peng和Dong Yu所著的关于深度学习的方法和应用的电子书</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1pJ0ok7T" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Summer School 2014》<i class="icon-external"></i></a></li></ul><p>介绍:2014年七月CMU举办的机器学习夏季课刚刚结束 有近50小时的视频、十多个PDF版幻灯片，覆盖 深度学习，贝叶斯，分布式机器学习，伸缩性 等热点话题。所有13名讲师都是牛人：包括大牛Tom Mitchell （他的［机器学习］是名校的常用教材），还有CMU李沐 .（1080P高清哟）</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//users.soe.ucsc.edu/%7Eniejiazhong/slides/chandra.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Sibyl: 来自Google的大规模机器学习系统》<i class="icon-external"></i></a></li></ul><p>介绍:在今年的IEEE/IFIP可靠系统和网络（DSN）国际会议上，Google软件工程师Tushar Chandra做了一个关于Sibyl系统的主题演讲。 Sibyl是一个监督式机器学习系统，用来解决预测方面的问题，比如YouTube的视频推荐。详情请阅读<a href="https://link.zhihu.com/?target=http%3A//www.infoq.com/cn/news/2014/07/google-sibyl" class=" wrap external" target="_blank" rel="nofollow noreferrer">google sibyl<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//googleresearch.blogspot.com/2014/09/building-deeper-understanding-of-images.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Building a deeper understanding of images》<i class="icon-external"></i></a></li></ul><p>介绍:谷歌研究院的Christian Szegedy在谷歌研究院的博客上简要地介绍了他们今年参加ImageNet取得好成绩的GoogLeNet系统.是关于图像处理的。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/memect/hao/blob/master/awesome/bayesian-network-python.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Bayesian network 与python概率编程实战入门》<i class="icon-external"></i></a></li></ul><p>介绍:贝叶斯学习。如果不是很清可看看<a href="https://link.zhihu.com/?target=http%3A//www.infoq.com/cn/news/2014/07/programming-language-bayes" class=" wrap external" target="_blank" rel="nofollow noreferrer">概率编程语言与贝叶斯方法实践<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《AMA: Michael I Jordan》<i class="icon-external"></i></a></li></ul><p>介绍:网友问伯克利机器学习大牛、美国双料院士Michael I. Jordan："如果你有10亿美金，你怎么花？Jordan: "我会用这10亿美金建造一个NASA级别的自然语言处理研究项目。"</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/tornadomeet/p/3395593.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习&amp;数据挖掘笔记_16（常见面试之机器学习算法思想简单梳理）》<i class="icon-external"></i></a></li></ul><p>介绍:常见面试之机器学习算法思想简单梳理,此外作者还有一些其他的<a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/tornadomeet/tag/%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0/" class=" wrap external" target="_blank" rel="nofollow noreferrer">机器学习与数据挖掘文章<i class="icon-external"></i></a>和<a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/tornadomeet/tag/Deep%25E3%2580%2580Learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">深度学习文章<i class="icon-external"></i></a>,不仅是理论还有源码。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.kdnuggets.com/2014/09/most-viewed-web-mining-lectures-videolectures.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《文本与数据挖掘视频汇总》<i class="icon-external"></i></a></li></ul><p>介绍：Videolectures上最受欢迎的25个文本与数据挖掘视频汇总</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《怎么选择深度学习的GPUs》<i class="icon-external"></i></a></li></ul><p>介绍:在Kaggle上经常取得不错成绩的Tim Dettmers介绍了他自己是怎么选择深度学习的GPUs, 以及个人如何构建深度学习的GPU集群: <a href="https://link.zhihu.com/?target=http%3A//t.cn/RhpuD1G" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">t.cn/RhpuD1G</span><span class="invisible"></span><i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.infoq.com/cn/news/2014/09/depth-model" class=" wrap external" target="_blank" rel="nofollow noreferrer">《对话机器学习大神Michael Jordan：深度模型》<i class="icon-external"></i></a></li></ul><p>介绍:对话机器学习大神Michael Jordan</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_46d0a3930101fswl.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning 和 Knowledge Graph 引爆大数据革命》<i class="icon-external"></i></a></li></ul><p>介绍:还有２，３部分。<a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_46d0a3930101gs5h.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning 【2,3】<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_46d0a3930101h6nf.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning 教程翻译》<i class="icon-external"></i></a></li></ul><p>介绍:是Stanford 教授 Andrew Ng 的 Deep Learning 教程，国内的机器学习爱好者很热心的把这个教程翻译成了中文。如果你英语不好，可以看看这个</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//markus.com/deep-learning-101/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning 101》<i class="icon-external"></i></a></li></ul><p>介绍:因为近两年来，深度学习在媒体界被炒作很厉害（就像大数据）。其实很多人都还不知道什么是深度学习。这篇文章由浅入深。告诉你深度学究竟是什么！</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial" class=" wrap external" target="_blank" rel="nofollow noreferrer">《UFLDL Tutorial》<i class="icon-external"></i></a></li></ul><p>介绍:这是斯坦福大学做的一免费课程（很勉强），这个可以给你在深度学习的路上给你一个学习的思路。里面提到了一些基本的算法。而且告诉你如何去应用到实际环境中。<a href="https://link.zhihu.com/?target=http%3A//ufldl.stanford.edu/wiki/index.php/UFLDL%25E6%2595%2599%25E7%25A8%258B" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning.cs.toronto.edu/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Toronto Deep Learning Demos》<i class="icon-external"></i></a></li></ul><p>介绍:这是多伦多大学做的一个深度学习用来识别图片标签／图转文字的demo。是一个实际应用案例。有源码</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//metacademy.org/roadmaps/rgrosse/deep_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep learning from the bottom up》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习模型，阅读这个内容需要有一定的基础。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cran.r-project.org/web/views/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《R工具包的分类汇总》<i class="icon-external"></i></a></li></ul><p>介绍: (CRAN Task Views, 34种常见任务,每个任务又各自分类列举若干常用相关工具包) 例如: 机器学习，自然语言处理，时间序列分析，空间信息分析，多重变量分析，计量经济学，心理统计学，社会学统计，化学计量学，环境科学，药物代谢动力学 等</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ctocio.com/hotnews/15919.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习常见算法分类汇总》<i class="icon-external"></i></a></li></ul><p>介绍: 机器学习无疑是当前数据分析领域的一个热点内容。很多人在平时的工作中都或多或少会用到机器学习的算法。本文为您总结一下常见的机器学习算法，以供您在工作和学习中参考.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8775360" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning（深度学习）学习笔记整理系列》<i class="icon-external"></i></a></li></ul><p>介绍: 很多干货，而且作者还总结了好几个系列。另外还作者还了一个<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/14222605" class=" wrap external" target="_blank" rel="nofollow noreferrer">文章导航<i class="icon-external"></i></a>.非常的感谢作者总结。</p><p><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8775488" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning（深度学习）学习笔记整理系列之（二）<i class="icon-external"></i></a></p><p><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8775518" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning（深度学习）学习笔记整理系列之（三）<i class="icon-external"></i></a></p><p><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8775524" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning（深度学习）学习笔记整理系列之（四）<i class="icon-external"></i></a></p><p><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8777094" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning（深度学习）学习笔记整理系列之（五）<i class="icon-external"></i></a></p><p><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8781396" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning（深度学习）学习笔记整理系列之（六）<i class="icon-external"></i></a></p><p><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8781543" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning（深度学习）学习笔记整理系列之（七）<i class="icon-external"></i></a></p><p><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8782018" class=" wrap external" target="_blank" rel="nofollow noreferrer">DeepLearning（深度学习）学习笔记整理系列之（八）<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/apps/video/default.aspx%3Fid%3D206976%26l%3Di" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Tutorials Session A - Deep Learning for Computer Vision》<i class="icon-external"></i></a></li></ul><p>介绍:传送理由：Rob Fergus的用深度学习做计算机是觉的NIPS 2013教程。有mp4, mp3, pdf各种<a href="https://link.zhihu.com/?target=http%3A//msrvideo.vo.msecnd.net/rmcvideos/206976/dl/206976.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">下载<i class="icon-external"></i></a> 他是纽约大学教授，目前也在Facebook工作，他2014年的8篇<a href="https://link.zhihu.com/?target=http%3A//cs.nyu.edu/%7Efergus/pmwiki/pmwiki.php%3Fn%3DPmWiki.Publications" class=" wrap external" target="_blank" rel="nofollow noreferrer">论文<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/xpqiu/fnlp/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《FudanNLP》<i class="icon-external"></i></a></li></ul><p>介绍:FudanNLP，这是一个复旦大学计算机学院开发的开源中文自然语言处理（NLP）工具包 Fudan NLP里包含中文分词、关键词抽取、命名实体识别、词性标注、时间词抽取、语法分析等功能，对搜索引擎 文本分析等极为有价值。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//engineering.linkedin.com/large-scale-machine-learning/open-sourcing-ml-ease" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Open Sourcing ml-ease》<i class="icon-external"></i></a></li></ul><p>介绍:LinkedIn 开源的机器学习工具包,支持单机, Hadoop cluster，和 Spark cluster 重点是 logistic regression 算法</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ztl2004.github.io/MachineLearningWeekly/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习周刊》<i class="icon-external"></i></a></li></ul><p>介绍:对于英语不好，但又很想学习机器学习的朋友。是一个大的福利。机器学习周刊目前主要提供中文版，还是面向广大国内爱好者，内容涉及机器学习、数据挖掘、并行系统、图像识别、人工智能、机器人等等。谢谢作者</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//v.163.com/special/opencourse/daishu.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《线性代数》<i class="icon-external"></i></a></li></ul><p>介绍：《线性代数》是《机器学习》的重要数学先导课程。其实《线代》这门课讲得浅显易懂特别不容易，如果一上来就讲逆序数及罗列行列式性质，很容易让学生失去学习的兴趣。我个人推荐的最佳《线性代数》课程是麻省理工Gilbert Strang教授的课程。 <a href="https://link.zhihu.com/?target=http%3A//ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/" class=" wrap external" target="_blank" rel="nofollow noreferrer">课程主页<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.andreamostosi.name/big-data/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Big-data》<i class="icon-external"></i></a></li></ul><p>介绍:大数据数据处理资源、工具不完备列表，从框架、分布式编程、分布式文件系统、键值数据模型、图数据模型、数据可视化、列存储、机器学习等。很赞的资源汇总。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//yahoolabs.tumblr.com/post/97839313996/machine-learning-for-smart-dummies" class=" wrap external" target="_blank" rel="nofollow noreferrer">《machine learning for smart dummies》<i class="icon-external"></i></a></li></ul><p>介绍:雅虎邀请了一名来自本古里安大学的访问学者，制作了一套关于机器学习的系列视频课程。本课程共分为7期，详细讲解了有关SVM, boosting, nearest neighbors, decision trees 等常规机器学习算法的理论基础知识。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.7770" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Entanglement-Based Quantum Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:应对大数据时代，量子机器学习的第一个实验 <a href="https://link.zhihu.com/?target=http%3A//arxiv-web3.library.cornell.edu/pdf/1409.7770.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">paper 下载<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.wired.com/2014/01/how-to-hack-okcupid/all/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《How a Math Genius Hacked OkCupid to Find True Love》<i class="icon-external"></i></a></li></ul><p>介绍:Wired杂志报道了UCLA数学博士Chris McKinlay （图1）通过大数据手段+机器学习方法破解婚恋网站配对算法找到真爱的故事,通过Python脚本控制着12个账号，下载了婚恋网站2万女用户的600万问题答案，对他们进行了统计抽样及聚类分析（图2，3），最后终于收获了真爱。科技改变命运！</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.edx.org/course/mitx/mitx-6-832x-underactuated-robotics-3511" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Underactuated Robotics》<i class="icon-external"></i></a></li></ul><p>介绍:MIT的Underactuated Robotics于 2014年10月1日开课，该课属于MIT研究生级别的课程，对机器人和非线性动力系统感兴趣的朋友不妨可以挑战一下这门课程！</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//yanbohappy.sinaapp.com/%3Fp%3D498" class=" wrap external" target="_blank" rel="nofollow noreferrer">《mllib实践经验(1)》<i class="icon-external"></i></a></li></ul><p>介绍:mllib实践经验分享</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.seobythesea.com/2014/09/google-turns-deep-learning-classification-fight-web-spam/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Google Turns To Deep Learning Classification To Fight Web Spam》<i class="icon-external"></i></a></li></ul><p>介绍:Google用Deep Learning做的antispam(反垃圾邮件)</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/memect/hao/blob/master/awesome/nlp.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NLP常用信息资源》<i class="icon-external"></i></a></li></ul><p>介绍:NLP常用信息资源* <a href="https://link.zhihu.com/?target=https%3A//github.com/memect/hao/blob/master/awesome/nlp.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NLP常用信息资源》<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/soulmachine/machine-learning-cheat-sheet" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习速查表》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习速查表</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arnetminer.org/conferencebestpapers" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Best Papers vs. Top Cited Papers in Computer Science》<i class="icon-external"></i></a></li></ul><p>介绍：从1996年开始在计算机科学的论文中被引用次数最多的论文</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//mmcheng.net/zh/itam/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《InfiniTAM: 基于深度图像的体数据集成框架》<i class="icon-external"></i></a></li></ul><p>介绍：把今年的一个ACM Trans. on Graphics (TOG)论文中的代码整理为一个开源的算法框架，共享出来了。欢迎大家使用。可以实时的采集3D数据、重建出三维模型。Online learning，GPU Random forest，GPU CRF也会后续公开。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//karpathy.github.io/neuralnets/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Hacker's guide to Neural Networks》<i class="icon-external"></i></a></li></ul><p>介绍：【神经网络黑客指南】现在，最火莫过于深度学习（Deep Learning），怎样更好学习它？可以让你在浏览器中，跑起深度学习效果的超酷开源项目<a href="https://link.zhihu.com/?target=https%3A//github.com/karpathy/convnetjs" class=" wrap external" target="_blank" rel="nofollow noreferrer">ConvNetJS<i class="icon-external"></i></a>作者karpathy告诉你，最佳技巧是，当你开始写代码，一切将变得清晰。他刚发布了一本图书，不断在线更新</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearningmastery.com/building-a-production-machine-learning-infrastructure/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Building a Production Machine Learning Infrastructure》<i class="icon-external"></i></a></li></ul><p>介绍：前Google广告系统工程师Josh Wills 讲述工业界和学术界机器学习的异同,大实话</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//neo4j.com/blog/deep-learning-sentiment-analysis-movie-reviews-using-neo4j/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》<i class="icon-external"></i></a></li></ul><p>介绍：使用<a href="https://link.zhihu.com/?target=http%3A//www.neo4j.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Neo4j<i class="icon-external"></i></a> 做电影评论的情感分析。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//memkite.com/deep-learning-bibliography/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《DeepLearning.University – An Annotated Deep Learning Bibliography》<i class="icon-external"></i></a></li></ul><p>介绍：不仅是资料，而且还对有些资料做了注释。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.datarobot.com/blog/a-primer-on-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A primer on deeping learning》<i class="icon-external"></i></a></li></ul><p>介绍：深度学习入门的初级读本</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//news.ycombinator.com/item%3Fid%3D8379571" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine learning is teaching us the secret to teaching 》<i class="icon-external"></i></a></li></ul><p>介绍：机器学习教会了我们什么？</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/documentation.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《scikit-learn：用于机器学习的Python模块》<i class="icon-external"></i></a></li></ul><p>介绍：scikit-learn是在SciPy基础上构建的用于机器学习的Python模块。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.infoq.com/cn/news/2014/10/interview-michael-jordan" class=" wrap external" target="_blank" rel="nofollow noreferrer">《对话机器学习大神Michael Jordan：解析领域中各类模型》<i class="icon-external"></i></a></li></ul><p>介绍：乔丹教授（Michael I. Jordan）教授是机器学习领域神经网络的大牛，他对深度学习、神经网络有着很浓厚的兴趣。因此，很多提问的问题中包含了机器学习领域的各类模型，乔丹教授对此一一做了解释和展望。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.redblobgames.com/pathfinding/a-star/introduction.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A*搜索算法的可视化短教程》<i class="icon-external"></i></a></li></ul><p>介绍：A*搜索是人工智能基本算法，用于高效地搜索图中两点的最佳路径, 核心是 g(n)+h(n): g(n)是从起点到顶点n的实际代价，h(n)是顶点n到目标顶点的估算代价。<a href="https://link.zhihu.com/?target=https%3A//github.com/memect/hao/issues/256" class=" wrap external" target="_blank" rel="nofollow noreferrer">合集<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//code.csdn.net/news/2822123" class=" wrap external" target="_blank" rel="nofollow noreferrer">《基于云的自然语言处理开源项目FudanNLP》<i class="icon-external"></i></a></li></ul><p>介绍：本项目利用了Microsoft Azure，可以在几分种内完成NLP on Azure Website的部署，立即开始对FNLP各种特性的试用，或者以REST API的形式调用FNLP的语言分析功能</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.youku.com/playlist_show/id_22935176.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《吴立德《概率主题模型&amp;数据科学基础》<i class="icon-external"></i></a></li></ul><p>介绍：现任复旦大学首席教授、计算机软件博士生导师。计算机科学研究所副所长.内部课程</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ml.memect.com/article/machine-learning-guide.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习入门资源不完全汇总》<i class="icon-external"></i></a></li></ul><p>介绍：好东西的干货真的很多</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//memkite.com/deep-learning-bibliography/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《收集从2014年开始深度学习文献》<i class="icon-external"></i></a></li></ul><p>介绍：从硬件、图像到健康、生物、大数据、生物信息再到量子计算等，Amund Tveit等维护了一个DeepLearning.University小项目：收集从2014年开始深度学习文献，相信可以作为深度学习的起点,<a href="https://link.zhihu.com/?target=https%3A//github.com/memkite/DeepLearningBibliography" class=" wrap external" target="_blank" rel="nofollow noreferrer">github<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//emnlp2014.org/papers/pdf/EMNLP2014148.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《EMNLP上两篇关于股票趋势的应用论文 》<i class="icon-external"></i></a></li></ul><p>介绍：EMNLP上两篇关于<a href="https://link.zhihu.com/?target=http%3A//emnlp2014.org/papers/pdf/EMNLP2014148.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">stock trend<i class="icon-external"></i></a> 用到了deep model组织特征；<a href="https://link.zhihu.com/?target=http%3A//emnlp2014.org/papers/pdf/EMNLP2014120.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer"> Exploiting Social Relations and Sentiment for Stock Prediction<i class="icon-external"></i></a>用到了stock network。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning.net/tutorial/deeplearning.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Bengio组（蒙特利尔大学LISA组）深度学习教程 》<i class="icon-external"></i></a></li></ul><p>介绍：作者是深度学习一线大牛Bengio组写的教程，算法深入显出，还有实现代码，一步步展开。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1410.5401v1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《学习算法的Neural Turing Machine 》<i class="icon-external"></i></a></li></ul><p>介绍：许多传统的机器学习任务都是在学习function，不过谷歌目前有开始学习算法的趋势。谷歌另外的这篇学习Python程序的<a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1410.4615v1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Learning to Execute<i class="icon-external"></i></a>也有相似之处</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.morganclaypool.com/doi/abs/10.2200/S00607ED2V01Y201410HLT026" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning to Rank for Information Retrieval and Natural Language Processing》<i class="icon-external"></i></a></li></ul><p>介绍：作者是华为技术有限公司，诺亚方舟实验室，首席科学家的李航博士写的关于信息检索与自然语言处理的文章</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.aclweb.org/anthology/D11-1147" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Rumor has it: Identifying Misinformation in Microblogs》<i class="icon-external"></i></a></li></ul><p>介绍：利用机用器学习在谣言的判别上的应用,此外还有两个。一个是识别垃圾与虚假信息的<a href="https://link.zhihu.com/?target=http%3A//digital.cs.usu.edu/%7Ekyumin/tutorial/www-tutorial.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">paper<i class="icon-external"></i></a>.还有一个是<a href="https://link.zhihu.com/?target=http%3A//www.datatang.com/news/details_1319.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">网络舆情及其分析技术<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//study.163.com/course/introduction/854064.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">《R机器学习实践》<i class="icon-external"></i></a></li></ul><p>介绍：该课程是网易公开课的收费课程，不贵，超级便宜。主要适合于对利用R语言进行机器学习，数据挖掘感兴趣的人。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ifeve.com/bigdataanalyticsbeyondhadoop_evolutionofmlrealizaton/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《大数据分析：机器学习算法实现的演化》<i class="icon-external"></i></a></li></ul><p>介绍：本章中作者总结了三代机器学习算法实现的演化：第一代非分布式的， 第二代工具如Mahout和Rapidminer实现基于Hadoop的扩展，第三代如Spark和Storm实现了实时和迭代数据处理。<a href="https://link.zhihu.com/?target=http%3A//ifeve.com/wp-content/uploads/2014/05/big-data-analytics-beyond-hadoop.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">BIG DATA ANALYTICS BEYOND HADOOP<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//book.douban.com/subject/5921462/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《图像处理，分析与机器视觉》<i class="icon-external"></i></a></li></ul><p>介绍：讲计算机视觉的四部奇书（应该叫经典吧）之一，另外三本是Hartley的《多图几何》、Gonzalez的《数字图像处理》、Rafael C.Gonzalez / Richard E.Woods 的<a href="https://link.zhihu.com/?target=http%3A//book.douban.com/subject/1106342/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《数字图像处理》<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1sjFeLTN" class=" wrap external" target="_blank" rel="nofollow noreferrer">《LinkedIn最新的推荐系统文章Browsemaps》<i class="icon-external"></i></a></li></ul><p>介绍：里面基本没涉及到具体算法，但作者介绍了CF在LinkedIn的很多应用，以及他们在做推荐过程中获得的一些经验。最后一条经验是应该监控log数据的质量，因为推荐的质量很依赖数据的质量！</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_574a437f01019poo.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《初学者如何查阅自然语言处理（NLP）领域学术资料》<i class="icon-external"></i></a></li></ul><p>介绍：初学者如何查阅自然语言处理（NLP）领域学术资料</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.open-electronics.org/raspberry-pi-and-the-camera-pi-module-face-recognition-tutorial/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《树莓派的人脸识别教程》<i class="icon-external"></i></a></li></ul><p>介绍：用树莓派和相机模块进行人脸识别</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.hangli-hl.com/uploads/3/1/6/8/3168008/short_text_conversation_mla.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《利用深度学习与大数据构建对话系统 》<i class="icon-external"></i></a></li></ul><p>介绍：如何利用深度学习与大数据构建对话系统</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//lear.inrialpes.fr/people/mairal/resources/pdf/review_sparse_arxiv.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《经典论文Leo Breiman：Statistical Modeling: The Two Cultures 》<i class="icon-external"></i></a></li></ul><p>介绍：Francis Bach合作的有关稀疏建模的新综述(书)：Sparse Modeling for Image and Vision Processing，内容涉及Sparsity, Dictionary Learning, PCA, Matrix Factorization等理论，以及在图像和视觉上的应用，而且第一部分关于Why does the l1-norm induce sparsity的解释也很不错。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.umiacs.umd.edu/%7Ehal/docs/daume04rkhs.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Reproducing Kernel Hilbert Space》<i class="icon-external"></i></a></li></ul><p>介绍：RKHS是机器学习中重要的概念，其在large margin分类器上的应用也是广为熟知的。如果没有较好的数学基础，直接理解RKHS可能会不易。本文从基本运算空间讲到Banach和Hilbert空间，深入浅出，一共才12页。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//karpathy.github.io/neuralnets/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Hacker's guide to Neural Networks》<i class="icon-external"></i></a></li></ul><p>介绍：许多同学对于机器学习及深度学习的困惑在于，数学方面已经大致理解了，但是动起手来却不知道如何下手写代码。斯坦福深度学习博士Andrej Karpathy写了一篇实战版本的深度学习及机器学习教程，手把手教你用Javascript写神经网络和SVM.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/pandalibaba/article/details/17409395" class=" wrap external" target="_blank" rel="nofollow noreferrer">《【语料库】语料库资源汇总》<i class="icon-external"></i></a></li></ul><p>介绍：【语料库】语料库资源汇总</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.jobbole.com/60809/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习算法之旅》<i class="icon-external"></i></a></li></ul><p>介绍：本文会过一遍最流行的机器学习算法，大致了解哪些方法可用，很有帮助。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.csee.wvu.edu/%7Exinl/source.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Reproducible Research in Computational Science》<i class="icon-external"></i></a></li></ul><p>介绍：这个里面有很多关于机器学习、信号处理、计算机视觉、深入学习、神经网络等领域的大量源代码（或可执行代码）及相关论文。科研写论文的好资源</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cilvr.nyu.edu/doku.php%3Fid%3Ddeeplearning%3Aslides%3Astart" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NYU 2014年的深度学习课程资料》<i class="icon-external"></i></a></li></ul><p>介绍：NYU 2014年的深度学习课程资料，有视频</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/memect/hao/blob/master/awesome/computer-vision-dataset.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">《计算机视觉数据集不完全汇总》<i class="icon-external"></i></a></li></ul><p>介绍：计算机视觉数据集不完全汇总</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//mloss.org/software/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Open Source Software》<i class="icon-external"></i></a></li></ul><p>介绍：机器学习开源软件</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.csie.ntu.edu.tw/%7Ecjlin/libsvm/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《LIBSVM》<i class="icon-external"></i></a></li></ul><p>介绍：A Library for Support Vector Machines</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.support-vector-machines.org/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Support Vector Machines》<i class="icon-external"></i></a></li></ul><p>介绍：<a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/files.cnblogs.com/tekson/%25E6%2595%25B0%25E6%258D%25AE%25E6%258C%2596%25E6%258E%2598%25E4%25B9%258B%25E7%25BB%258F%25E5%2585%25B8%25E7%25AE%2597%25E6%25B3%2595.doc" class=" wrap external" target="_blank" rel="nofollow noreferrer">数据挖掘十大经典算法<i class="icon-external"></i></a>之一</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//meta-guide.com/software-meta-guide/100-best-github-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《100 Best GitHub: Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍：github上面100个非常棒的项目</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//archive.ics.uci.edu/ml" class=" wrap external" target="_blank" rel="nofollow noreferrer">《加州大学欧文分校(UCI)机器学习数据集仓库》<i class="icon-external"></i></a></li></ul><p>介绍：当前加州大学欧文分校为机器学习社区维护着306个数据集。<a href="https://link.zhihu.com/?target=http%3A//archive.ics.uci.edu/ml/datasets.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">查询数据集<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Andrej Karpathy个人主页》<i class="icon-external"></i></a></li></ul><p>介绍：Andrej Karpathy 是斯坦福大学Li Fei-Fei的博士生，使用机器学习在图像、视频语义分析领域取得了科研和工程上的突破，发的文章不多，但每个都很扎实，在每一个问题上都做到了state-of-art.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Andrej Karpathy的深度强化学习演示》<i class="icon-external"></i></a></li></ul><p>介绍：Andrej Karpathy的深度强化学习演示，<a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1312.5602v1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">论文在这里<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/cikm-competition-topdata" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CIKM数据挖掘竞赛夺冠算法-陈运文》<i class="icon-external"></i></a></li></ul><p>介绍：CIKM Cup(或者称为CIKM Competition)是ACM CIKM举办的国际数据挖掘竞赛的名称。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/%7Ehinton/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Geoffrey E. Hinton》<i class="icon-external"></i></a></li></ul><p>介绍：杰弗里·埃弗里斯特·辛顿 FRS是一位英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。辛顿是反向传播算法和对比散度算法的发明人之一，也是深度学习的积极推动者.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cikm2014.fudan.edu.cn/cikm2014/Tpl/Public/slides/CIKM14_tutorial_slides_6.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《自然语言处理的深度学习理论与实际》<i class="icon-external"></i></a></li></ul><p>介绍：微软研究院深度学习技术中心在CIKM2014 上关于《自然语言处理的深度学习理论与实际》教学讲座的幻灯片</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//eugenezhulenev.com/blog/2014/11/14/stock-price-prediction-with-big-data-and-machine-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《用大数据和机器学习做股票价格预测》<i class="icon-external"></i></a></li></ul><p>介绍： 本文基于&lt;支持向量机的高频限价订单的动态建模&gt;采用了 Apache Spark和Spark MLLib从纽约股票交易所的订单日志数据构建价格运动预测模型。(股票有风险，投资谨慎)GitHub源代码托管<a href="https://link.zhihu.com/?target=https%3A//github.com/ezhulenev/orderbook-dynamics" class=" wrap external" target="_blank" rel="nofollow noreferrer">地址<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//dataunion.org/%3Fp%3D2011" class=" wrap external" target="_blank" rel="nofollow noreferrer">《关于机器学习的若干理论问题》<i class="icon-external"></i></a></li></ul><p>介绍：徐宗本 院士将于热爱机器学习的小伙伴一起探讨有关于机器学习的几个理论性问题，并给出一些有意义的结论。最后通过一些实例来说明这些理论问题的物理意义和实际应用价值。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/s/D2szyg_bBVM0" class=" wrap external" target="_blank" rel="nofollow noreferrer">《深度学习在自然语言处理的应用》<i class="icon-external"></i></a></li></ul><p>介绍：作者还著有《这就是搜索引擎：核心技术详解》一书，主要是介绍应用层的东西</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.ubc.ca/%7Enando/340-2012/index.php" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Undergraduate machine learning at UBC》<i class="icon-external"></i></a></li></ul><p>介绍：机器学习课程</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_6ae183910101h4jr.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《人脸识别必读的N篇文章》<i class="icon-external"></i></a></li></ul><p>介绍：人脸识别必读文章推荐</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//semocean.com/%25E6%258E%25A8%25E8%258D%2590%25E7%25B3%25BB%25E7%25BB%259F%25E7%25BB%258F%25E5%2585%25B8%25E8%25AE%25BA%25E6%2596%2587%25E6%2596%2587%25E7%258C%25AE%25E5%258F%258A%25E8%25B5%2584%25E6%2596%2599/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《推荐系统经典论文文献及业界应用》<i class="icon-external"></i></a></li></ul><p>介绍：推荐系统经典论文文献</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_6ae183910101h4jr.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《人脸识别必读的N篇文章》<i class="icon-external"></i></a></li></ul><p>介绍：人脸识别必读文章推荐</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//see.xidian.edu.cn/vipsl/MLA2014/program.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">《第十二届中国"机器学习及其应用"研讨会PPT》<i class="icon-external"></i></a></li></ul><p>介绍：第十二届中国"机器学习及其应用"研讨会PPT</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm%3FId%3D398" class=" wrap external" target="_blank" rel="nofollow noreferrer">《统计机器学习》<i class="icon-external"></i></a></li></ul><p>介绍：统计学习是关于计算机基于数据构建的概率统计模型并运用模型对数据进行预测和分析的一门科学，统计学习也成为统计机器学习。课程来自上海交通大学</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm%3FId%3D397" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习导论》<i class="icon-external"></i></a></li></ul><p>介绍：机器学习的目标是对计算机编程，以便使用样本数据或以往的经验来解决给定的问题.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cikm2014.fudan.edu.cn/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CIKM 2014主题报告的幻灯片》<i class="icon-external"></i></a></li></ul><p>介绍：CIKM 2014 Jeff Dean、Qi Lu、Gerhard Weikum的主题报告的幻灯片， Alex Smola、Limsoon Wong、Tong Zhang、Chih-Jen Lin的Industry Track报告的幻灯片</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning.net/software_links/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《人工智能和机器学习领域有趣的开源项目》<i class="icon-external"></i></a></li></ul><p>介绍：部分中文<a href="https://link.zhihu.com/?target=http%3A//code.csdn.net/news/2822818" class=" wrap external" target="_blank" rel="nofollow noreferrer">列表<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/suipingsp/article/details/41645779" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习经典算法详解及Python实现--基于SMO的SVM分类器》<i class="icon-external"></i></a></li></ul><p>介绍:此外作者还有一篇<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/suipingsp/article/details/41722435" class=" wrap external" target="_blank" rel="nofollow noreferrer">元算法、AdaBoost　python实现文章<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//aria42.com/blog/2014/12/understanding-lbfgs/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Numerical Optimization: Understanding L-BFGS》<i class="icon-external"></i></a></li></ul><p>介绍:加州伯克利大学博士Aria Haghighi写了一篇超赞的数值优化博文，从牛顿法讲到拟牛顿法，再讲到BFGS以及L-BFGS, 图文并茂，还有伪代码。强烈推荐。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.goldencui.org/2014/12/02/%25E7%25AE%2580%25E6%2598%258E%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0%25E6%2596%25B9%25E6%25B3%2595%25E6%25A6%2582%25E8%25BF%25B0%25EF%25BC%2588%25E4%25B8%2580%25EF%25BC%2589/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《简明深度学习方法概述（一）》<i class="icon-external"></i></a></li></ul><p>介绍:还有续集<a href="https://link.zhihu.com/?target=http%3A//www.goldencui.org/2014/12/06/%25E7%25AE%2580%25E6%2598%258E%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0%25E6%2596%25B9%25E6%25B3%2595%25E6%25A6%2582%25E8%25BF%25B0%25EF%25BC%2588%25E4%25BA%258C%25EF%25BC%2589/" class=" wrap external" target="_blank" rel="nofollow noreferrer">简明深度学习方法概述（二）<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.johndcook.com/blog/r_language_for_programmers/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《R language for programmers》<i class="icon-external"></i></a></li></ul><p>介绍:Ｒ语言程序员私人定制版</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cheyun.com/content/news/4051" class=" wrap external" target="_blank" rel="nofollow noreferrer">《谷歌地图解密：大数据与机器学习的结合》<i class="icon-external"></i></a></li></ul><p>介绍:谷歌地图解密</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/u012690204/article/details/41853731" class=" wrap external" target="_blank" rel="nofollow noreferrer">《空间数据挖掘常用方法》<i class="icon-external"></i></a></li></ul><p>介绍:空间数据挖掘常用方法</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.kaggle.com/c/word2vec-nlp-tutorial" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Use Google's Word2Vec for movie reviews》<i class="icon-external"></i></a></li></ul><p>介绍:Kaggle新比赛 ”When bag of words meets bags of popcorn“ aka ”边学边用word2vec和deep learning做NLP“ 里面全套教程教一步一步用python和gensim包的word2vec模型，并在实际比赛里面比调参数和清数据。 如果已装过gensim不要忘升级</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pynlpir.readthedocs.org/en/latest/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《PyNLPIR》<i class="icon-external"></i></a></li></ul><p>介绍:PyNLPIR提供了NLPIR/ICTCLAS汉语分词的Python接口,此外<a href="https://link.zhihu.com/?target=http%3A//zhon.readthedocs.org/en/latest/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Zhon<i class="icon-external"></i></a>提供了常用汉字常量，如CJK字符和偏旁，中文标点，拼音，和汉字正则表达式（如找到文本中的繁体字）</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.technologyreview.com/view/533496/why-neural-networks-look-set-to-thrash-the-best-human-go-players-for-the-first-time/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《深度卷积神经网络下围棋》<i class="icon-external"></i></a></li></ul><p>介绍:这文章说把最近模型识别上的突破应用到围棋软件上，打16万张职业棋谱训练模型识别功能。想法不错。训练后目前能做到不用计算，只看棋盘就给出下一步，大约10级棋力。但这篇文章太过乐观，说什么人类的最后一块堡垒马上就要跨掉了。话说得太早。不过，如果与别的软件结合应该还有潜力可挖。@万精油墨绿</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//mrtz.org/blog/the-nips-experiment/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NIPS审稿实验》<i class="icon-external"></i></a></li></ul><p>介绍:UT Austin教授Eric Price关于今年NIPS审稿实验的详细分析,他表示，根据这次实验的结果，如果今年NIPS重新审稿的话，会有一半的论文被拒。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.kdnuggets.com/2014/12/top-kdnuggets-2014-analytics-big-data-science-stories.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《2014年最佳的大数据，数据科学文章》<i class="icon-external"></i></a></li></ul><p>介绍:KDNuggets分别总结了2014年14个阅读最多以及分享最多的文章。我们从中可以看到多个主题——深度学习，数据科学家职业，教育和薪酬，学习数据科学的工具比如R和Python以及大众投票的最受欢迎的数据科学和数据挖掘语言</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/suipingsp/article/details/42101139" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习经典算法详解及Python实现--线性回归（Linear Regression）算法》<i class="icon-external"></i></a></li></ul><p>介绍:Python实现线性回归,作者还有其他很棒的文章推荐可以看看</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//download.csdn.net/album/detail/1367/1/1" class=" wrap external" target="_blank" rel="nofollow noreferrer">《2014中国大数据技术大会33位核心专家演讲PDF》<i class="icon-external"></i></a></li></ul><p>介绍：2014中国大数据技术大会33位核心专家演讲PDF下载</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.5335" class=" wrap external" target="_blank" rel="nofollow noreferrer">《使用RNN和Paragraph Vector做情感分析》<i class="icon-external"></i></a></li></ul><p>介绍：这是T. Mikolov &amp; Y. Bengio最新论文Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews ，使用RNN和PV在情感分析效果不错，［项目代码］(<a href="https://link.zhihu.com/?target=https%3A//github.com/mesnilgr/iclr15%29%25E5%2585%25AC%25E5%25B8%2583%25E5%259C%25A8github%28%25E7%259B%25AE%25E5%2589%258D%25E6%2598%25AF%25E7%25A9%25BA%25E7%259A%2584%29%25E3%2580%2582%25E8%25BF%2599%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580Paragraph" class=" wrap external" target="_blank" rel="nofollow noreferrer">https://github.com/mesnilgr/iclr15)公布在github(目前是空的)。这意味着Paragraph<i class="icon-external"></i></a> Vector终于揭开面纱了嘛。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1o6I9S18" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NLPIR/ICTCLAS2015分词系统大会上的技术演讲 》<i class="icon-external"></i></a></li></ul><p>介绍:NLPIR/ICTCLAS2015分词系统发布与用户交流大会上的演讲，请更多朋友检阅新版分词吧。 我们实验室同学的演讲包括：<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1hqotVVm" class=" wrap external" target="_blank" rel="nofollow noreferrer">孙梦姝-基于评论观点挖掘的商品搜索技术研究<i class="icon-external"></i></a><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1pJ9KuZh" class=" wrap external" target="_blank" rel="nofollow noreferrer">李然-主题模型<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//medium.com/code-poet/80ea3ec3c471" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning is Fun!》<i class="icon-external"></i></a></li></ul><p>介绍:Convex Neural Networks 解决维数灾难</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//dataunion.org/%3Fp%3D5395" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CNN的反向求导及练习》<i class="icon-external"></i></a></li></ul><p>介绍:介绍CNN参数在使用bp算法时该怎么训练，毕竟CNN中有卷积层和下采样层，虽然和MLP的bp算法本质上相同，但形式上还是有些区别的，很显然在完成CNN反向传播前了解bp算法是必须的。此外作者也做了一个<a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/tornadomeet/archive/2012/05/24/2515980.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">资源集:机器学习，深度学习，视觉，数学等<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/cloudflare/ahocorasick" class=" wrap external" target="_blank" rel="nofollow noreferrer">《正则表达式优化成Trie树 》<i class="icon-external"></i></a></li></ul><p>介绍:如果要在一篇文章中匹配十万个关键词怎么办？<a href="https://link.zhihu.com/?target=https%3A//github.com/cloudflare/ahocorasick" class=" wrap external" target="_blank" rel="nofollow noreferrer">Aho-Corasick<i class="icon-external"></i></a> 算法利用添加了返回边的Trie树，能够在线性时间内完成匹配。 但如果匹配十万个正则表达式呢 ？ 这时候可以用到把多个正则优化成Trie树的方法，如日本人写的 <a href="https://link.zhihu.com/?target=http%3A//search.cpan.org/%7Edankogai/Regexp-Trie-0.02/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Regexp::Trie<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//jmozah.github.io/links/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep learning Reading List》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习阅读清单</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//caffe.berkeleyvision.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Caffe》<i class="icon-external"></i></a></li></ul><p>介绍:Caffe是一个开源的深度学习框架，作者目前在google工作，作者主页<a href="https://link.zhihu.com/?target=http%3A//daggerfs.com/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Yangqing Jia (贾扬清)<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/readme.md" class=" wrap external" target="_blank" rel="nofollow noreferrer">《GoogLeNet深度学习模型的Caffe复现 》<i class="icon-external"></i></a></li></ul><p>介绍:2014 ImageNet冠军GoogLeNet深度学习模型的Caffe复现模型,<a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.4842" class=" wrap external" target="_blank" rel="nofollow noreferrer">GoogleNet论文<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/jbarrow/LambdaNet" class=" wrap external" target="_blank" rel="nofollow noreferrer">《LambdaNet，Haskell实现的开源人工神经网络库 》<i class="icon-external"></i></a></li></ul><p>介绍:LambdaNetLambdaNet是由Haskell实现的一个开源的人工神经网络库，它抽象了网络创建、训练并使用了高阶函数。该库还提供了一组预定义函数，用户可以采取多种方式组合这些函数来操作现实世界数据。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//wenku.baidu.com/course/view/49e8b8f67c1cfad6195fa705" class=" wrap external" target="_blank" rel="nofollow noreferrer">《百度余凯&amp;张潼机器学习视频》<i class="icon-external"></i></a></li></ul><p>介绍:如果你从事互联网搜索，在线广告，用户行为分析，图像识别，自然语言理解，或者生物信息学，智能机器人，金融预测，那么这门核心课程你必须深入了解。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//v.youku.com/v_show/id_XODQzNDM4MDg0.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《杨强在TEDxNanjing谈智能的起源》<i class="icon-external"></i></a></li></ul><p>介绍:"人工智能研究分许多流派。其中之一以IBM为代表，认为只要有高性能计算就可得到智能，他们的‘深蓝’击败了世界象棋冠军；另一流派认为智能来自动物本能；还有个很强的流派认为只要找来专家，把他们的思维用逻辑一条条写下，放到计算机里就行……" 杨强在TEDxNanjing谈智能的起源</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《深度RNN/LSTM用于结构化学习 0)序列标注Connectionist Temporal ClassificationICML06》<i class="icon-external"></i></a></li></ul><p>介绍:1)机器翻译<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Sequence to Sequence NIPS14<i class="icon-external"></i></a> 2)成分句法<a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1412.7449v1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">GRAMMAR AS FOREIGN LANGUAGE<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//techblog.youdao.com/%3Fp%3D915" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning实战之word2vec》<i class="icon-external"></i></a></li></ul><p>介绍:网易有道的三位工程师写的word2vec的解析文档，从基本的词向量/统计语言模型-&gt;NNLM-&gt;Log-Linear/Log-Bilinear-&gt;层次化Log-Bilinear，到CBOW和Skip-gram模型，再到word2vec的各种tricks，公式推导与代码，基本上是网上关于word2vec资料的大合集，对word2vec感兴趣的朋友可以看看</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//mloss.org/software/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine learning open source software》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习开源软件,收录了各种机器学习的各种编程语言学术与商业的开源软件．与此类似的还有很多例如:<a href="https://link.zhihu.com/?target=http%3A//www.dmoz.org/Computers/Artificial_Intelligence/Machine_Learning/Software/" class=" wrap external" target="_blank" rel="nofollow noreferrer">DMOZ - Computers: Artificial Intelligence: Machine Learning: Software<i class="icon-external"></i></a>,　<a href="https://link.zhihu.com/?target=http%3A//www.csie.ntu.edu.tw/%7Ecjlin/libsvm/" class=" wrap external" target="_blank" rel="nofollow noreferrer">LIBSVM -- A Library for Support Vector Machines<i class="icon-external"></i></a>,　<a href="https://link.zhihu.com/?target=http%3A//www.cs.waikato.ac.nz/ml/weka/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Weka 3: Data Mining Software in Java<i class="icon-external"></i></a>,　<a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/" class=" wrap external" target="_blank" rel="nofollow noreferrer">scikit-learn:Machine Learning in Python<i class="icon-external"></i></a>,　<a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.nltk.org" class=" wrap external" target="_blank" rel="nofollow noreferrer">Natural Language Toolkit:NLTK<i class="icon-external"></i></a>,　<a href="https://link.zhihu.com/?target=http%3A//mallet.cs.umass.edu/" class=" wrap external" target="_blank" rel="nofollow noreferrer">MAchine Learning for LanguagE Toolkit<i class="icon-external"></i></a>,　<a href="https://link.zhihu.com/?target=http%3A//orange.biolab.si/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Data Mining - Fruitful and Fun<i class="icon-external"></i></a>,　<a href="https://link.zhihu.com/?target=http%3A//opencv.willowgarage.com/wiki/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Open Source Computer Vision Library<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.guokr.com/post/512037/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习入门者学习指南》<i class="icon-external"></i></a></li></ul><p>介绍:作者是计算机研二(写文章的时候，现在是2015年了应该快要毕业了)，专业方向自然语言处理．这是一点他的经验之谈．对于入门的朋友或许会有帮助</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearningmastery.com/a-tour-of-machine-learning-algorithms/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Tour of Machine Learning Algorithms》<i class="icon-external"></i></a></li></ul><p>介绍:这是一篇关于机器学习算法分类的文章，非常好</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ml.memect.com/download/2014.zip" class=" wrap external" target="_blank" rel="nofollow noreferrer">《2014年的《机器学习日报》大合集》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习日报里面推荐很多内容，在这里有一部分的优秀内容就是来自机器学习日报．</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/abcjennifer/article/details/42493493" class=" wrap external" target="_blank" rel="nofollow noreferrer">《 Image classification with deep learning常用模型》<i class="icon-external"></i></a></li></ul><p>介绍:这是一篇关于图像分类在深度学习中的文章</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/en-us/people/deng/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《自动语音识别：深度学习方法》<i class="icon-external"></i></a></li></ul><p>介绍:作者与Bengio的兄弟Samy 09年合编《自动语音识别：核方法》 3）李开复1989年《自动语音识别》专著，其博导、94年图灵奖得主Raj Reddy作序</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/heiyeshuwu/article/details/42554903" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NLP中的中文分词技术》<i class="icon-external"></i></a></li></ul><p>介绍: 作者是360电商技术组成员,这是一篇NLP在中文分词中的应用</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Using convolutional neural nets to detect facial keypoints tutorial》<i class="icon-external"></i></a></li></ul><p>介绍: 使用deep learning的人脸关键点检测，此外还有一篇<a href="https://link.zhihu.com/?target=https%3A//www.kaggle.com/c/facial-keypoints-detection/details/deep-learning-tutorial" class=" wrap external" target="_blank" rel="nofollow noreferrer">AWS部署教程<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.amazon.cn/Advanced-Structured-Prediction-Nowozin-Sebastian/dp/0262028379" class=" wrap external" target="_blank" rel="nofollow noreferrer">《书籍推荐:Advanced Structured Prediction》<i class="icon-external"></i></a></li></ul><p>介绍: 由Sebastian Nowozin等人编纂MIT出版的新书《Advanced Structured Prediction》<a href="https://link.zhihu.com/?target=http%3A//t.cn/RZxipKG" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">t.cn/RZxipKG</span><span class="invisible"></span><i class="icon-external"></i></a> ，汇集了结构化预测领域诸多牛文，涉及CV、NLP等领域，值得一读。网上公开的几章草稿:<a href="https://link.zhihu.com/?target=http%3A//www2.informatik.hu-berlin.de/%7Ekloftmar/publications/strucBook.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">一<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//mlg.eng.cam.ac.uk/yutian/Publications/ChenGelfandWelling14-HerdingBookChapter.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">二<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//web.engr.oregonstate.edu/%7Esinisa/research/publications/StructPredictionChapter14.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">三<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//ttic.uchicago.edu/%7Emeshi/papers/smoothCD_chapter.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">四<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//www.cs.ox.ac.uk/Stanislav.Zivny/homepage/publications/zwp14mit-draft.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">五<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1501.01571v1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Introduction to Matrix Concentration Inequalities》<i class="icon-external"></i></a></li></ul><p>介绍: Tropp把数学家用高深装逼的数学语言写的矩阵概率不等式用初等的方法写出来，是非常好的手册，领域内的paper各种证明都在用里面的结果。虽说是初等的，但还是非常的难</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//agenda.weforum.org/2014/12/the-free-big-data-sources-you-should-know/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The free big data sources you should know》<i class="icon-external"></i></a></li></ul><p>介绍: 不容错过的免费大数据集，有些已经是耳熟能详，有些可能还是第一次听说，内容跨越文本、数据、多媒体等，让他们伴你开始数据科学之旅吧，具体包括：<a href="https://link.zhihu.com/?target=http%3A//Data.gov" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">Data.gov</span><span class="invisible"></span><i class="icon-external"></i></a>、US Census Bureau、European Union Open Data Portal、<a href="https://link.zhihu.com/?target=http%3A//Data.gov.uk" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">Data.gov.uk</span><span class="invisible"></span><i class="icon-external"></i></a>等</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//yyue.blogspot.com/2015/01/a-brief-overview-of-deep-learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Brief Overview of Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍: 谷歌科学家、Hinton亲传弟子Ilya Sutskever的深度学习综述及实际建议</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//nikhilbuduma.com/2015/01/11/a-deep-dive-into-recurrent-neural-networks/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Deep Dive into Recurrent Neural Nets》<i class="icon-external"></i></a></li></ul><p>介绍: 非常好的讨论递归神经网络的文章，覆盖了RNN的概念、原理、训练及优化等各个方面内容，强烈推荐！本文作者Nikhil Buduma还有一篇<a href="https://link.zhihu.com/?target=http%3A//nikhilbuduma.com/2014/12/29/deep-learning-in-a-nutshell/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning in a Nutshell<i class="icon-external"></i></a>值得推荐</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//qianjiye.de/2014/11/machine-learning-resources/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习：学习资源》<i class="icon-external"></i></a></li></ul><p>介绍:里面融合了很多的资源，例如竞赛，在线课程，demo，数据整合等。有分类</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.otexts.org/book/sfml" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Statistical foundations of machine learning》<i class="icon-external"></i></a></li></ul><p>介绍:《机器学习的统计基础》在线版，该手册希望在理论与实践之间找到平衡点，各主要内容都伴有实际例子及数据，书中的例子程序都是用R语言编写的。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Deep Learning Tutorial: From Perceptrons to Deep Networks》<i class="icon-external"></i></a></li></ul><p>介绍:IVAN VASILEV写的深度学习导引：从浅层感知机到深度网络。高可读</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//futureoflife.org/static/data/documents/research_priorities.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Research priorities for robust and beneficial artificial intelligence》<i class="icon-external"></i></a></li></ul><p>介绍:鲁棒及有益的人工智能优先研究计划：一封公开信,目前已经有Stuart Russell, Tom Dietterich, Eric Horvitz, Yann LeCun, Peter Norvig, Tom Mitchell, Geoffrey Hinton, Elon Musk等人签署<a href="https://link.zhihu.com/?target=http%3A//futureoflife.org/misc/open_letter" class=" wrap external" target="_blank" rel="nofollow noreferrer">The Future of Life Institute (FLI)<i class="icon-external"></i></a>.这封信的背景是最近霍金和Elon Musk提醒人们注意AI的潜在威胁。公开信的内容是AI科学家们站在造福社会的角度，展望人工智能的未来发展方向，提出开发AI系统的Verification，Validity, Security, Control四点要求，以及需要注意的社会问题。毕竟当前AI在经济领域，法律，以及道德领域相关研究较少。其实还有一部美剧<a href="https://link.zhihu.com/?target=http%3A//tv.sohu.com/20120925/n353925789.shtml" class=" wrap external" target="_blank" rel="nofollow noreferrer">《疑犯追踪》<i class="icon-external"></i></a>,介绍了AI的演进从一开始的自我学习，过滤，图像识别，语音识别等判断危险，到第四季的时候出现了机器通过学习成长之后想控制世界的状态。说到这里推荐收看。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//metacademy.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《metacademy》<i class="icon-external"></i></a></li></ul><p>介绍:里面根据词条提供了许多资源，还有相关知识结构，路线图，用时长短等。号称是”机器学习“搜索引擎</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//research.facebook.com/blog/879898285375829/fair-open-sources-deep-learning-modules-for-torch/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《FAIR open sources deep-learning modules for Torch》<i class="icon-external"></i></a></li></ul><p>介绍:Facebook人工智能研究院（FAIR）开源了一系列软件库，以帮助开发者建立更大、更快的深度学习模型。开放的软件库在 Facebook 被称作模块。用它们替代机器学习领域常用的开发环境 Torch 中的默认模块，可以在更短的时间内训练更大规模的神经网络模型。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/ello/archive/2012/04/28/2475419.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《浅析人脸检测之Haar分类器方法》<i class="icon-external"></i></a></li></ul><p>介绍:本文虽然是写于2012年，但是这篇文章完全是作者的经验之作。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ituring.com.cn/article/55994" class=" wrap external" target="_blank" rel="nofollow noreferrer">《如何成为一位数据科学家》<i class="icon-external"></i></a></li></ul><p>介绍:本文是对《机器学习实战》作者Peter Harrington做的一个访谈。包含了书中部分的疑问解答和一点个人学习建议</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.metacademy.org/roadmaps/rgrosse/deep_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep learning from the bottom up》<i class="icon-external"></i></a></li></ul><p>介绍:非常好的深度学习概述，对几种流行的深度学习模型都进行了介绍和讨论</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//onepager.togaware.com/TextMiningO.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Hands-On Data Science with R Text Mining》<i class="icon-external"></i></a></li></ul><p>介绍:主要是讲述了利用R语言进行数据挖掘</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//colah.github.io/posts/2014-07-Understanding-Convolutions/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Understanding Convolutions》<i class="icon-external"></i></a></li></ul><p>介绍:帮你理解卷积神经网络，讲解很清晰，此外还有两篇<a href="https://link.zhihu.com/?target=http%3A//colah.github.io/posts/2014-07-Conv-Nets-Modular/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Conv Nets: A Modular Perspective<i class="icon-external"></i></a>，<a href="https://link.zhihu.com/?target=http%3A//colah.github.io/posts/2014-12-Groups-Convolution/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Groups &amp; Group Convolutions<i class="icon-external"></i></a>. 作者的其他的关于神经网络文章也很棒</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.iro.umontreal.ca/%7Epift6266/H10/notes/deepintro.html%23introduction-to-deep-learning-algorithms" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Deep Learning Algorithms》<i class="icon-external"></i></a></li></ul><p>介绍:Deep Learning算法介绍，里面介绍了06年3篇让deep learning崛起的论文</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.iro.umontreal.ca/%7Ebengioy/papers/ftml_book.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning Deep Architectures for AI》<i class="icon-external"></i></a></li></ul><p>介绍:一本学习人工智能的书籍，作者是Yoshua Bengio，相关<a href="https://link.zhihu.com/?target=http%3A//www.infoq.com/cn/articles/ask-yoshua-bengio" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内报道<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/%7Ehinton/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Geoffrey E. Hinton个人主页》<i class="icon-external"></i></a></li></ul><p>介绍:Geoffrey Hinton是Deep Learning的大牛，他的主页放了一些介绍性文章和课件值得学习</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//omega.albany.edu%3A8008/JaynesBook.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《PROBABILITY THEORY: THE LOGIC OF SCIENCE》<i class="icon-external"></i></a></li></ul><p>介绍:概率论：数理逻辑书籍</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/h2oai/h2o" class=" wrap external" target="_blank" rel="nofollow noreferrer">《H2O》<i class="icon-external"></i></a></li></ul><p>介绍:一个用来快速的统计，机器学习并且对于数据量大的数学库</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.iclr.cc/doku.php%3Fid%3Diclr2015%3Amain" class=" wrap external" target="_blank" rel="nofollow noreferrer">《ICLR 2015会议的arXiv稿件合集》<i class="icon-external"></i></a></li></ul><p>介绍:在这里你可以看到最近深度学习有什么新动向。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www-nlp.stanford.edu/IR-book/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Information Retrieval》<i class="icon-external"></i></a></li></ul><p>介绍:此书在信息检索领域家喻户晓， 除提供该书的免费电子版外，还提供一个<a href="https://link.zhihu.com/?target=http%3A//www-nlp.stanford.edu/IR-book/information-retrieval.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">IR资源列表<i class="icon-external"></i></a> ，收录了信息检索、网络信息检索、搜索引擎实现等方面相关的图书、研究中心、相关课程、子领域、会议、期刊等等，堪称全集，值得收藏</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//yosinski.com/mlss12/MLSS-2012-Amari-Information-Geometry/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Information Geometry and its Applications to Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:信息几何学及其在机器学习中的应用</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//computationallegalstudies.com/2015/01/legal-analytics-introduction-course-professors-daniel-martin-katz-michael-j-bommarito/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Legal Analytics – Introduction to the Course》<i class="icon-external"></i></a></li></ul><p>介绍:课程《法律分析》介绍幻灯片。用机器学习解决法律相关分析和预测问题，相关的法律应用包括预测编码、早期案例评估、案件整体情况的预测，定价和工作人员预测，司法行为预测等。法律领域大家可能都比较陌生，不妨了解下。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/yanxionglu/text_pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《文本上的算法》<i class="icon-external"></i></a></li></ul><p>介绍: 文中提到了最优，模型，最大熵等等理论，此外还有应用篇。推荐系统可以说是一本不错的阅读稿，关于模型还推荐一篇<a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_6742eecd0100iqcv.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Generative Model 与 Discriminative Model<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/karpathy/neuraltalk" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NeuralTalk》<i class="icon-external"></i></a></li></ul><p>介绍: NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.NeuralTalk是一个Python的从图像生成自然语言描述的工具。它实现了Google (Vinyals等，卷积神经网络CNN + 长短期记忆LSTM) 和斯坦福 (Karpathy and Fei-Fei， CNN + 递归神经网络RNN)的算法。NeuralTalk自带了一个训练好的动物模型，你可以拿狮子大象的照片来试试看</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.paypal-engineering.com/2015/01/12/deep-learning-on-hadoop-2-0-2/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning on Hadoop 2.0》<i class="icon-external"></i></a></li></ul><p>介绍:本文主要介绍了在Hadoop2.0上使用深度学习,文章来自paypal</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1206.5533" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Practical recommendations for gradient-based training of deep architectures》<i class="icon-external"></i></a></li></ul><p>介绍:用基于梯度下降的方法训练深度框架的实践推荐指导,作者是<a href="https://link.zhihu.com/?target=http%3A//www.iro.umontreal.ca/%7Ebengioy/yoshua_en/research.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Yoshua Bengio<i class="icon-external"></i></a> .感谢@xuewei4d 推荐</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearningmastery.com/machine-learning-statistical-causal-methods/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning With Statistical And Causal Methods》<i class="icon-external"></i></a></li></ul><p>介绍: 用统计和因果方法做机器学习（视频报告）</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPLD0F06AA0D2E8FFBA" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Course 180’》<i class="icon-external"></i></a></li></ul><p>介绍: 一个讲机器学习的Youtube视频教程。160集。系统程度跟书可比拟。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《回归(regression)、梯度下降(gradient descent)》<i class="icon-external"></i></a></li></ul><p>介绍: 机器学习中的数学，作者的研究方向是机器学习，并行计算如果你还想了解一点其他的可以看看他<a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/LeftNotEasy/archive/2011/05/02/recommended-blogspots.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客<i class="icon-external"></i></a>的其他文章</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//tech.meituan.com/mt-recommend-practice.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《美团推荐算法实践》<i class="icon-external"></i></a></li></ul><p>介绍: 美团推荐算法实践，从框架，应用，策略，查询等分析</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.1632" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning for Answer Sentence Selection》<i class="icon-external"></i></a></li></ul><p>介绍: 深度学习用于问答系统答案句的选取</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.iro.umontreal.ca/%7Elisa/pointeurs/WWW2014.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning Semantic Representations Using Convolutional Neural Networks for Web Search 》<i class="icon-external"></i></a></li></ul><p>介绍: CNN用于WEB搜索，深度学习在文本计算中的应用</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/caesar0301/awesome-public-datasets" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Awesome Public Datasets》<i class="icon-external"></i></a></li></ul><p>介绍: Awesome系列中的公开数据集</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.academics.io/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Search Engine &amp; Community》<i class="icon-external"></i></a></li></ul><p>介绍: 一个学术搜索引擎</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//honnibal.github.io/spaCy/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《spaCy》<i class="icon-external"></i></a></li></ul><p>介绍: 用Python和Cython写的工业级自然语言处理库，号称是速度最快的NLP库，快的原因一是用Cython写的，二是用了个很巧妙的hash技术，加速系统的瓶颈，NLP中稀松特征的存取</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//fr.slideshare.net/MrChrisJohnson/collaborative-filtering-with-spark" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Collaborative Filtering with Spark》<i class="icon-external"></i></a></li></ul><p>介绍: <a href="https://link.zhihu.com/?target=http%3A//www.fields.utoronto.ca/video-archive/event/323/2014" class=" wrap external" target="_blank" rel="nofollow noreferrer">Fields<i class="icon-external"></i></a>是个数学研究中心,上面的这份ppt是来自Fields举办的活动中Russ Salakhutdinov带来的《大规模机器学习》分享</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.7300days.com/index.php/stds/topic/list/id/27/name/Topic%2520modeling" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Topic modeling 的经典论文》<i class="icon-external"></i></a></li></ul><p>介绍: Topic modeling 的经典论文,标注了关键点</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.6564" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Move Evaluation in Go Using Deep Convolutional Neural Networks》<i class="icon-external"></i></a></li></ul><p>介绍: 多伦多大学与Google合作的新论文，深度学习也可以用来下围棋，据说能达到六段水平</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ztl2004.github.io/MachineLearningWeekly/issue2.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习周刊第二期》<i class="icon-external"></i></a></li></ul><p>介绍: 新闻，paper,课程，book，system,CES,Roboot，此外还推荐一个<a href="https://link.zhihu.com/?target=http%3A//blog.newitfarmer.com/ai/deep-learning/15302/repost-%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0%25E5%2585%25A5%25E9%2597%25A8%25E4%25B8%258E%25E7%25BB%25BC%25E8%25BF%25B0%25E8%25B5%2584%25E6%2596%2599" class=" wrap external" target="_blank" rel="nofollow noreferrer">深度学习入门与综述资料<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.bigdata-madesimple.com/learning-more-like-a-human-18-free-ebooks-on-machine-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning more like a human: 18 free eBooks on Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍: 18 free eBooks on Machine Learning</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.hangli-hl.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Recommend :Hang Li Home》<i class="icon-external"></i></a></li></ul><p>介绍:Chief scientist of Noah's Ark Lab of Huawei Technologies.He worked at the Research Laboratories of NEC Corporation during 1990 and 2001 and Microsoft Research Asia during 2001 and 2012.<a href="https://link.zhihu.com/?target=http%3A//www.hangli-hl.com/recent-publications.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Paper<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//memkite.com/deep-learning-bibliography/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《DEEPLEARNING.UNIVERSITY – AN ANNOTATED DEEP LEARNING BIBLIOGRAPHY》<i class="icon-external"></i></a></li></ul><p>介绍: DEEPLEARNING.UNIVERSITY的论文库已经收录了963篇经过分类的深度学习论文了，很多经典论文都已经收录</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DwTp3P2UnTfQ%26hd%3D1" class=" wrap external" target="_blank" rel="nofollow noreferrer">《MLMU.cz - Radim Řehůřek - Word2vec &amp; friends (7.1.2015)》<i class="icon-external"></i></a></li></ul><p>介绍: Radim Řehůřek(Gensim开发者)在一次机器学习聚会上的报告，关于word2vec及其优化、应用和扩展，很实用.<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1c03wd24" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内网盘<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//databricks.com/blog/2015/01/28/introducing-streaming-k-means-in-spark-1-2.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introducing streaming k-means in Spark 1.2》<i class="icon-external"></i></a></li></ul><p>介绍:很多公司都用机器学习来解决问题，提高用户体验。那么怎么可以让机器学习更实时和有效呢？Spark MLlib 1.2里面的Streaming K-means，由斑马鱼脑神经研究的Jeremy Freeman脑神经科学家编写，最初是为了实时处理他们每半小时1TB的研究数据，现在发布给大家用了。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.hankcs.com/nlp/lda-java-introduction-and-implementation.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《LDA入门与Java实现》<i class="icon-external"></i></a></li></ul><p>介绍: 这是一篇面向工程师的LDA入门笔记，并且提供一份开箱即用Java实现。本文只记录基本概念与原理，并不涉及公式推导。文中的LDA实现核心部分采用了arbylon的LdaGibbsSampler并力所能及地注解了，在搜狗分类语料库上测试良好，开源在<a href="https://link.zhihu.com/?target=https%3A//github.com/hankcs/LDA4j" class=" wrap external" target="_blank" rel="nofollow noreferrer">GitHub<i class="icon-external"></i></a>上。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//aminer.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《AMiner - Open Science Platform》<i class="icon-external"></i></a></li></ul><p>介绍: AMiner是一个学术搜索引擎，从学术网络中挖掘深度知识、面向科技大数据的挖掘。收集近4000万作者信息、8000万论文信息、1亿多引用关系、链接近8百万知识点；支持专家搜索、机构排名、科研成果评价、会议排名。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.quora.com/What-are-some-interesting-Word2Vec-results" class=" wrap external" target="_blank" rel="nofollow noreferrer">《What are some interesting Word2Vec results?》<i class="icon-external"></i></a></li></ul><p>介绍: Quora上的主题，讨论Word2Vec的有趣应用，Omer Levy提到了他在CoNLL2014最佳论文里的分析结果和新方法，Daniel Hammack给出了找特异词的小应用并提供了<a href="https://link.zhihu.com/?target=https%3A//github.com/dhammack/Word2VecExample" class=" wrap external" target="_blank" rel="nofollow noreferrer">(Python)代码<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.coursegraph.com/%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E5%2585%25AC%25E5%25BC%2580%25E8%25AF%25BE%25E6%25B1%2587%25E6%2580%25BB" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习公开课汇总》<i class="icon-external"></i></a></li></ul><p>介绍: 机器学习公开课汇总,虽然里面的有些课程已经归档过了，但是还有个别的信息没有。感谢课程图谱的小编</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//linear.ups.edu/download.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A First Course in Linear Algebra》<i class="icon-external"></i></a></li></ul><p>介绍: 【A First Course in Linear Algebra】Robert Beezer 有答案 有移动版、打印版 使用GNU自由文档协议 引用了杰弗逊1813年的信</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ShiqiYu/libfacedetection" class=" wrap external" target="_blank" rel="nofollow noreferrer">《libfacedetection》<i class="icon-external"></i></a></li></ul><p>介绍:libfacedetection是深圳大学开源的一个人脸图像识别库。包含正面和多视角人脸检测两个算法.优点:速度快(OpenCV haar+adaboost的2-3倍), 准确度高 (FDDB非公开类评测排名第二），能估计人脸角度。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//dl.acm.org/citation.cfm%3Fdoid%3D2684822.2685310" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Inverting a Steady-State》<i class="icon-external"></i></a></li></ul><p>介绍:WSDM2015最佳论文 把马尔可夫链理论用在了图分析上面，比一般的propagation model更加深刻一些。通过全局的平稳分布去求解每个节点影响系数模型。假设合理（转移受到相邻的影响系数影响）。可以用来反求每个节点的影响系数</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1pJogO7x" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习入门书单》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习入门书籍，<a href="https://link.zhihu.com/?target=http%3A//www.hankcs.com/ml/machine-learning-entry-list.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">具体介绍<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//v1v3kn.tumblr.com/post/47193952400/the-trouble-with-svms" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The Trouble with SVMs》<i class="icon-external"></i></a></li></ul><p>介绍: 非常棒的强调特征选择对分类器重要性的文章。情感分类中，根据互信息对复杂高维特征降维再使用朴素贝叶斯分类器，取得了比SVM更理想的效果，训练和分类时间也大大降低——更重要的是，不必花大量时间在学习和优化SVM上——特征也一样no free lunch</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.stat.cmu.edu/%7Elarry/Wasserman.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Rise of the Machines》<i class="icon-external"></i></a></li></ul><p>介绍:CMU的统计系和计算机系知名教授Larry Wasserman 在《机器崛起》,对比了统计和机器学习的差异</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//tech.meituan.com/mt-mlinaction-how-to-ml.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《实例详解机器学习如何解决问题》<i class="icon-external"></i></a></li></ul><p>介绍:随着大数据时代的到来，机器学习成为解决问题的一种重要且关键的工具。不管是工业界还是学术界，机器学习都是一个炙手可热的方向，但是学术界和工业界对机器学习的研究各有侧重，学术界侧重于对机器学习理论的研究，工业界侧重于如何用机器学习来解决实际问题。这篇文章是美团的实际环境中的实战篇</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.gaussianprocess.org/gpml/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Gaussian Processes for Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:面向机器学习的高斯过程，章节概要：回归、分类、协方差函数、模型选择与超参优化、高斯模型与其他模型关系、大数据集的逼近方法等,<a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/s/ayG13we2vfWuT" class=" wrap external" target="_blank" rel="nofollow noreferrer">微盘下载<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《FuzzyWuzzy: Fuzzy String Matching in Python》<i class="icon-external"></i></a></li></ul><p>介绍:Python下的文本模糊匹配库，老库新推，可计算串间ratio(简单相似系数)、partial_ratio(局部相似系数)、token_sort_ratio(词排序相似系数)、token_set_ratio(词集合相似系数)等 <a href="https://link.zhihu.com/?target=https%3A//github.com/seatgeek/fuzzywuzzy" class=" wrap external" target="_blank" rel="nofollow noreferrer">github<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blocks.readthedocs.org/en/latest/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Blocks》<i class="icon-external"></i></a></li></ul><p>介绍:Blocks是基于Theano的神经网络搭建框架，集成相关函数、管道和算法，帮你更快地创建和管理NN模块.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//alex.smola.org/teaching/10-701-15/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习大神Alex Smola在CMU新一期的机器学习入门课程”Introduction to Machine Learning“近期刚刚开课，课程4K高清视频同步到Youtube上，目前刚刚更新到 2.4 Exponential Families,课程视频<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPLZSO_6-bSqHTTV7w9u7grTXBHMH-mw3qn" class=" wrap external" target="_blank" rel="nofollow noreferrer">playlist<i class="icon-external"></i></a>, 感兴趣的同学可以关注，非常适合入门.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.01423" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Collaborative Feature Learning from Social Media》<i class="icon-external"></i></a></li></ul><p>介绍:用社交用户行为学习图片的协同特征，可更好地表达图片内容相似性。由于不依赖于人工标签(标注)，可用于大规模图片处理，难在用户行为数据的获取和清洗；利用社会化特征的思路值得借鉴.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//blog.twitter.com/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introducing practical and robust anomaly detection in a time series》<i class="icon-external"></i></a></li></ul><p>介绍:Twitter技术团队对前段时间开源的时间序列异常检测算法(S-H-ESD)R包的介绍，其中对异常的定义和分析很值得参考，文中也提到——异常是强针对性的，某个领域开发的异常检测在其他领域直接用可不行.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.destinationcrm.com/Articles/Web-Exclusives/Viewpoints/Empower-Your-Team-to-Deal-with-Data-Quality-Issues-101308.aspx" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Empower Your Team to Deal with Data-Quality Issues》<i class="icon-external"></i></a></li></ul><p>介绍:聚焦数据质量问题的应对，数据质量对各种规模企业的性能和效率都至关重要，文中总结出(不限于)22种典型数据质量问题显现的信号，以及典型的数据质量解决方案(清洗、去重、统一、匹配、权限清理等)</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/%25E4%25B8%25AD%25E6%2596%2587%25E5%2588%2586%25E8%25AF%258D%25E5%2585%25A5%25E9%2597%25A8%25E4%25B9%258B%25E8%25B5%2584%25E6%25BA%2590" class=" wrap external" target="_blank" rel="nofollow noreferrer">《中文分词入门之资源》<i class="icon-external"></i></a></li></ul><p>介绍:中文分词入门之资源.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPLnDbcXCpYZ8lCKExMs8k4PtIbani9ESX3" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning Summit, San Francisco, 2015》<i class="icon-external"></i></a></li></ul><p>介绍:15年旧金山深度学习峰会视频集萃,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1ntiLMcT" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内云盘<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Conditional Random Fields》<i class="icon-external"></i></a></li></ul><p>介绍:很好的条件随机场(CRF)介绍文章,作者的学习笔记</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/%7Edanqi/papers/emnlp2014.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Fast and Accurate Dependency Parser using Neural Networks》<i class="icon-external"></i></a></li></ul><p>介绍: 来自Stanford，用神经网络实现快速准确的依存关系解析器</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍:做深度学习如何选择GPU的建议</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//new.livestream.com/accounts/10932136/events/3779068" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Sparse Linear Models》<i class="icon-external"></i></a></li></ul><p>介绍: Stanford的Trevor Hastie教授在H2O.ai Meet-Up上的报告，讲稀疏线性模型——面向“宽数据”(特征维数超过样本数)的线性模型,13年同<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1jimPw" class=" wrap external" target="_blank" rel="nofollow noreferrer">主题报告<i class="icon-external"></i></a> 、<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1o6wqW6u" class=" wrap external" target="_blank" rel="nofollow noreferrer">讲义<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/jbhuang0604/awesome-computer-vision" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Awesome Computer Vision》<i class="icon-external"></i></a></li></ul><p>介绍: 分类整理的机器视觉相关资源列表，秉承Awesome系列风格，有质有量!作者的更新频率也很频繁</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.personal.ceu.hu/staff/Adam_Szeidl/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Adam Szeidl》<i class="icon-external"></i></a></li></ul><p>介绍: social networks course</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//radar.oreilly.com/2015/01/building-and-deploying-large-scale-machine-learning-pipelines.html/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Building and deploying large-scale machine learning pipelines》<i class="icon-external"></i></a></li></ul><p>介绍: 大规模机器学习流程的构建与部署.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//download.csdn.net/detail/lswtzw/8469997" class=" wrap external" target="_blank" rel="nofollow noreferrer">《人脸识别开发包》<i class="icon-external"></i></a></li></ul><p>介绍: 人脸识别二次开发包，免费，可商用，有演示、范例、说明书.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Understanding Natural Language with Deep Neural Networks Using Torch》<i class="icon-external"></i></a></li></ul><p>介绍: 采用Torch用深度学习网络理解NLP，来自Facebook 人工智能的文章.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1503.00168.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The NLP Engine: A Universal Turing Machine for NLP》<i class="icon-external"></i></a></li></ul><p>介绍: 来自CMU的Ed Hovy和Stanford的Jiwei Li一篇有意思的Arxiv文章,作者用Shannon Entropy来刻画NLP中各项任务的难度.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//staff.city.ac.uk/%7Esb317/papers/foundations_bm25_review.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《TThe Probabilistic Relevance Framework: BM25 and Beyond》<i class="icon-external"></i></a></li></ul><p>介绍: 信息检索排序模型BM25(Besting Matching)。1）从经典概率模型演变而来 2）捕捉了向量空间模型中三个影响索引项权重的因子：IDF逆文档频率；TF索引项频率；文档长度归一化。3）并且含有集成学习的思想：组合了BM11和BM15两个模型。4）作者是BM25的提出者和Okapi实现者Robertson.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.analyticsvidhya.com/blog/2015/03/introduction-auto-regression-moving-average-time-series/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to ARMA Time Series Models – simplified》<i class="icon-external"></i></a></li></ul><p>介绍: 自回归滑动平均(ARMA)时间序列的简单介绍，ARMA是研究时间序列的重要方法，由自回归模型（AR模型）与滑动平均模型（MA模型）为基础“混合”构成.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1503.01838v1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Encoding Source Language with Convolutional Neural Network for Machine Translation》<i class="icon-external"></i></a></li></ul><p>介绍: 把来自target的attention signal加入source encoding CNN的输入，得到了比BBN的模型好的多neural network joint model</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.03815" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Spices form the basis of food pairing in Indian cuisine》<i class="icon-external"></i></a></li></ul><p>介绍: 揭开印度菜的美味秘诀——通过对大量食谱原料关系的挖掘，发现印度菜美味的原因之一是其中的味道互相冲突，很有趣的文本挖掘研究</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/hmm%25E7%259B%25B8%25E5%2585%25B3%25E6%2596%2587%25E7%25AB%25A0%25E7%25B4%25A2%25E5%25BC%2595" class=" wrap external" target="_blank" rel="nofollow noreferrer">《HMM相关文章索引》<i class="icon-external"></i></a></li></ul><p>介绍: HMM相关文章,此外推荐<a href="https://link.zhihu.com/?target=http%3A//yanyiwu.com/work/2014/04/07/hmm-segment-xiangjie.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文分词之HMM模型详解<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ccs.neu.edu/home/ekanou/ISU535.09X2/Handouts/Review_Material/zipfslaw.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Zipf's and Heap's law》<i class="icon-external"></i></a></li></ul><p>介绍: 1)词频与其降序排序的关系,最著名的是语言学家齐夫(Zipf,1902-1950)1949年提出的Zipf‘s law,即二者成反比关系. 曼德勃罗(Mandelbrot,1924- 2010)引入参数修正了对甚高频和甚低频词的刻画 2)Heaps' law: 词汇表与语料规模的平方根(这是一个参数,英语0.4-0.6)成正比</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%25C3%25BCrgen_schmidhuber_ama/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《I am Jürgen Schmidhuber, AMA》<i class="icon-external"></i></a></li></ul><p>介绍: Jürgen Schmidhuber在Reddit上的AMA(Ask Me Anything)主题，有不少RNN和AI、ML的干货内容，关于开源&amp;思想&amp;方法&amp;建议……耐心阅读，相信你也会受益匪浅.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//academictorrents.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《学术种子网站：AcademicTorrents》<i class="icon-external"></i></a></li></ul><p>介绍: 成G上T的学术数据，HN近期热议话题,主题涉及机器学习、NLP、SNA等。下载最简单的方法，通过BT软件，RSS订阅各集合即可</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/tutorial/machine_learning_map/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器学习交互速查表》<i class="icon-external"></i></a></li></ul><p>介绍: Scikit-Learn官网提供，在原有的Cheat Sheet基础上加上了Scikit-Learn相关文档的链接，方便浏览</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//timdettmers.wordpress.com/2015/03/09/deep-learning-hardware-guide/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Full Hardware Guide to Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍: 深度学习的全面硬件指南，从GPU到RAM、CPU、SSD、PCIe</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//hi.baidu.com/susongzhi/item/085983081b006311eafe38e7" class=" wrap external" target="_blank" rel="nofollow noreferrer">《行人检测(Pedestrian Detection)资源》<i class="icon-external"></i></a></li></ul><p>介绍:Pedestrian Detection paper &amp; data</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.01241" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A specialized face-processing network consistent with the representational geometry of monkey face patches》<i class="icon-external"></i></a></li></ul><p>介绍: 【神经科学碰撞人工智能】在脸部识别上你我都是专家，即使细微的差别也能辨认。研究已证明人类和灵长类动物在面部加工上不同于其他物种，人类使用梭状回面孔区（FFA）。Khaligh-Razavi等通过计算机模拟出人脸识别的FFA活动，堪称神经科学与人工智能的完美结合。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//vimeo.com/19569529" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Neural Net in C++ Tutorial》<i class="icon-external"></i></a></li></ul><p>介绍: 神经网络C++教程,本文介绍了用可调节梯度下降和可调节动量法设计和编码经典BP神经网络，网络经过训练可以做出惊人和美妙的东西出来。此外作者博客的其他文章也很不错。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning4j.org/neuralnetworktable.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《How to Choose a Neural Network》<i class="icon-external"></i></a></li></ul><p>介绍:deeplearning4j官网提供的实际应用场景NN选择参考表，列举了一些典型问题建议使用的神经网络</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/yusugomori/DeepLearning" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning (Python, C/C++, Java, Scala, Go)》<i class="icon-external"></i></a></li></ul><p>介绍:一个深度学习项目,提供了Python, C/C++, Java, Scala, Go多个版本的代码</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning.net/tutorial/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning Tutorials》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习教程,<a href="https://link.zhihu.com/?target=https%3A//github.com/lisa-lab/DeepLearningTutorials" class=" wrap external" target="_blank" rel="nofollow noreferrer">github<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ccf.org.cn/resources/1190201776262/2015/03/12/15.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《自然语言处理的发展趋势——访卡内基梅隆大学爱德华·霍威教授》<i class="icon-external"></i></a></li></ul><p>介绍:自然语言处理的发展趋势——访卡内基梅隆大学爱德华·霍威教授.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1503.03832" class=" wrap external" target="_blank" rel="nofollow noreferrer">《FaceNet: A Unified Embedding for Face Recognition and Clustering》<i class="icon-external"></i></a></li></ul><p>介绍:Google对Facebook DeepFace的有力回击—— FaceNet，在LFW(Labeled Faces in the Wild)上达到99.63%准确率(新纪录)，FaceNet embeddings可用于人脸识别、鉴别和聚类.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//databricks.com/blog/2015/01/21/random-forests-and-boosting-in-mllib.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《MLlib中的Random Forests和Boosting》<i class="icon-external"></i></a></li></ul><p>介绍:本文来自Databricks公司网站的一篇博客文章，由Joseph Bradley和Manish Amde撰写，文章主要介绍了Random Forests和Gradient-Boosted Trees（GBTs）算法和他们在MLlib中的分布式实现，以及展示一些简单的例子并建议该从何处上手.<a href="https://link.zhihu.com/?target=http%3A//www.csdn.net/article/2015-03-11/2824178" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//spn.cs.washington.edu/index.shtml" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Sum-Product Networks(SPN) 》<i class="icon-external"></i></a></li></ul><p>介绍:华盛顿大学Pedro Domingos团队的DNN，提供论文和实现代码.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//nlp.stanford.edu/software/nndep.shtml" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Neural Network Dependency Parser》<i class="icon-external"></i></a></li></ul><p>介绍:基于神经网络的自然语言依存关系解析器(已集成至Stanford CoreNLP)，特点是超快、准确，目前可处理中英文语料，基于<a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/%7Edanqi/papers/emnlp2014.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Fast and Accurate Dependency Parser Using Neural Networks》<i class="icon-external"></i></a> 思路实现.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.flickering.cn/nlp/2015/03/%25E6%2588%2591%25E4%25BB%25AC%25E6%2598%25AF%25E8%25BF%2599%25E6%25A0%25B7%25E7%2590%2586%25E8%25A7%25A3%25E8%25AF%25AD%25E8%25A8%2580%25E7%259A%2584-3%25E7%25A5%259E%25E7%25BB%258F%25E7%25BD%2591%25E7%25BB%259C%25E8%25AF%25AD%25E8%25A8%2580%25E6%25A8%25A1%25E5%259E%258B/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《神经网络语言模型》<i class="icon-external"></i></a></li></ul><p>介绍:本文根据神经网络的发展历程，详细讲解神经网络语言模型在各个阶段的形式，其中的模型包含NNLM[Bengio,2003]、Hierarchical NNLM[Bengio, 2005], Log-Bilinear[Hinton, 2007],SENNA等重要变形，总结的特别好.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.elg.uottawa.ca/%7Enat/Courses/csi5387_Winter2014/paper13.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Classifying Spam Emails using Text and Readability Features》<i class="icon-external"></i></a></li></ul><p>介绍:经典问题的新研究：利用文本和可读性特征分类垃圾邮件。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/alexandrebarachant/bci-challenge-ner-2015" class=" wrap external" target="_blank" rel="nofollow noreferrer">《BCI Challenge @ NER 2015》<i class="icon-external"></i></a></li></ul><p>介绍:<a href="https://link.zhihu.com/?target=https%3A//www.kaggle.com/c/inria-bci-challenge" class=" wrap external" target="_blank" rel="nofollow noreferrer">Kaggle脑控计算机交互(BCI)竞赛<i class="icon-external"></i></a>优胜方案源码及文档，包括完整的数据处理流程，是学习Python数据处理和Kaggle经典参赛框架的绝佳实例</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ipol.im/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《IPOL Journal · Image Processing On Line》<i class="icon-external"></i></a></li></ul><p>介绍:IPOL（在线图像处理）是图像处理和图像分析的研究期刊，每篇文章都包含一个算法及相应的代码、Demo和实验文档。文本和源码是经过了同行评审的。IPOL是开放的科学和可重复的研究期刊。我一直想做点类似的工作，拉近产品和技术之间的距离.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//eprint.iacr.org/2014/331" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine learning classification over encrypted data》<i class="icon-external"></i></a></li></ul><p>介绍:出自MIT，研究加密数据高效分类问题.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/purine/purine2" class=" wrap external" target="_blank" rel="nofollow noreferrer">《purine2》<i class="icon-external"></i></a></li></ul><p>介绍:新加坡LV实验室的神经网络并行框架<a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.6249" class=" wrap external" target="_blank" rel="nofollow noreferrer">Purine: A bi-graph based deep learning framework<i class="icon-external"></i></a>,支持构建各种并行的架构，在多机多卡，同步更新参数的情况下基本达到线性加速。12块Titan 20小时可以完成Googlenet的训练。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//michal.io/machine-learning-resources/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Resources》<i class="icon-external"></i></a></li></ul><p>介绍:这是一个机器学习资源库,虽然比较少.但蚊子再小也是肉.有突出部分.此外还有一个由<a href="https://link.zhihu.com/?target=http%3A//zhengrui.github.io/zerryland/ML-CV-Resource.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">zheng Rui整理的机器学习资源<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/cjdd3b/nicar2015/tree/master/machine-learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Hands-on with machine learning》<i class="icon-external"></i></a></li></ul><p>介绍:Chase Davis在NICAR15上的主题报告材料，用Scikit-Learn做监督学习的入门例子.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cse.unsw.edu.au/%7Ebillw/nlpdict.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The Natural Language Processing Dictionary》<i class="icon-external"></i></a></li></ul><p>介绍:这是一本自然语言处理的词典,从1998年开始到目前积累了成千上万的专业词语解释,如果你是一位刚入门的朋友.可以借这本词典让自己成长更快.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1503.01331" class=" wrap external" target="_blank" rel="nofollow noreferrer">《PageRank Approach to Ranking National Football Teams》<i class="icon-external"></i></a></li></ul><p>介绍:通过分析1930年至今的比赛数据，用PageRank计算世界杯参赛球队排行榜.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cyclismo.org/tutorial/R/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《R Tutorial》<i class="icon-external"></i></a></li></ul><p>介绍:R语言教程,此外还推荐一个R语言教程<a href="https://link.zhihu.com/?target=http%3A//cran.r-project.org/doc/manuals/R-intro.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">An Introduction to R<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/0803.0476" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Fast unfolding of communities in large networks》<i class="icon-external"></i></a></li></ul><p>介绍:经典老文，复杂网络社区发现的高效算法，Gephi中的<a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/The%2520Louvain%2520method%2520for%2520community%2520detection%2520in%2520large%2520networks" class=" wrap external" target="_blank" rel="nofollow noreferrer">Community detection<i class="icon-external"></i></a>即基于此.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//numl.net/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NUML》<i class="icon-external"></i></a></li></ul><p>介绍: 一个面向 .net 的开源机器学习库,<a href="https://link.zhihu.com/?target=https%3A//github.com/sethjuarez/numl" class=" wrap external" target="_blank" rel="nofollow noreferrer">github地址<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//synaptic.juancazala.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《synaptic.Js》<i class="icon-external"></i></a></li></ul><p>介绍: 支持node.js的JS神经网络库，可在客户端浏览器中运行，支持LSTM等 <a href="https://link.zhihu.com/?target=https%3A//github.com/cazala/synaptic" class=" wrap external" target="_blank" rel="nofollow noreferrer">github地址<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//tjo-en.hatenablog.com/entry/2015/03/20/191614" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine learning for package users with R (1): Decision Tree》<i class="icon-external"></i></a></li></ul><p>介绍: 决策树</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning, The Curse of Dimensionality, and Autoencoders》<i class="icon-external"></i></a></li></ul><p>介绍: 讨论深度学习自动编码器如何有效应对维数灾难,<a href="https://link.zhihu.com/?target=http%3A//www.36dsj.com/archives/26223" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内翻译<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.cmu.edu/%7Esuvrit/teach/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Advanced Optimization and Randomized Methods》<i class="icon-external"></i></a></li></ul><p>介绍: CMU的优化与随机方法课程，由A. Smola和S. Sra主讲，优化理论是机器学习的基石，值得深入学习 <a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1c0cZtQC" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内云(视频)<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs231n.stanford.edu/reports.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CS231n: Convolutional Neural Networks for Visual Recognition》<i class="icon-external"></i></a></li></ul><p>介绍: "面向视觉识别的CNN"课程设计报告集锦.近百篇，内容涉及图像识别应用的各个方面</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//databricks.com/blog/2015/03/25/topic-modeling-with-lda-mllib-meets-graphx.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Topic modeling with LDA: MLlib meets GraphX》<i class="icon-external"></i></a></li></ul><p>介绍:用Spark的MLlib+GraphX做大规模LDA主题抽取.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.05988" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning for Multi-label Classification》<i class="icon-external"></i></a></li></ul><p>介绍: 基于深度学习的多标签分类,用基于RBM的DBN解决多标签分类(特征)问题</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deepmind.com/publications.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Google DeepMind publications》<i class="icon-external"></i></a></li></ul><p>介绍: DeepMind论文集锦</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//kaldi-asr.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《kaldi》<i class="icon-external"></i></a></li></ul><p>介绍: 一个开源语音识别工具包,它目前托管在<a href="https://link.zhihu.com/?target=http%3A//sourceforge.net/projects/kaldi/" class=" wrap external" target="_blank" rel="nofollow noreferrer">sourceforge<i class="icon-external"></i></a>上面</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//datajournalismhandbook.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Data Journalism Handbook》<i class="icon-external"></i></a></li></ul><p>介绍: 免费电子书《数据新闻手册》, 国内有热心的朋友翻译了<a href="https://link.zhihu.com/?target=http%3A//datajournalismhandbook.org/chinese/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>,大家也可以<a href="https://link.zhihu.com/?target=http%3A//datajournalismhandbook.org/1.0/en/" class=" wrap external" target="_blank" rel="nofollow noreferrer">在线阅读<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//highlyscalable.wordpress.com/2015/03/10/data-mining-problems-in-retail/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Data Mining Problems in Retail》<i class="icon-external"></i></a></li></ul><p>介绍: 零售领域的数据挖掘文章.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//timdettmers.wordpress.com/2015/03/26/convolution-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Understanding Convolution in Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍: 深度学习卷积概念详解,深入浅出.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pandas.pydata.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《pandas: powerful Python data analysis toolkit》<i class="icon-external"></i></a></li></ul><p>介绍: 非常强大的Python的数据分析工具包.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//breakthroughanalysis.com/2015/03/23/text-analytics-2015/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Text Analytics 2015》<i class="icon-external"></i></a></li></ul><p>介绍: 2015文本分析(商业)应用综述.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.slideshare.net/VincenzoLomonaco/deep-learning-libraries-and-rst-experiments-with-theano" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning libraries and ﬁrst experiments with Theano》<i class="icon-external"></i></a></li></ul><p>介绍: 深度学习框架、库调研及Theano的初步测试体会报告.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.iro.umontreal.ca/%7Ebengioy/dlbook/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《DEEP learning》<i class="icon-external"></i></a></li></ul><p>介绍: MIT的Yoshua Bengio等人讲深度学习的新书，还未定稿，线上提供Draft chapters收集反馈，超赞！强烈推荐.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/hickeroar/simplebayes" class=" wrap external" target="_blank" rel="nofollow noreferrer">《simplebayes》<i class="icon-external"></i></a></li></ul><p>介绍: Python下开源可持久化朴素贝叶斯分类库.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//paracel.io/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Paracel》<i class="icon-external"></i></a></li></ul><p>介绍:Paracel is a distributed computational framework designed for machine learning problems, graph algorithms and scientific computing in C++.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//hanlp.linrunsoft.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《HanLP:Han Language processing》<i class="icon-external"></i></a></li></ul><p>介绍: 开源汉语言处理包.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.rubylab.io/2015/03/18/simple-neural-network-implenentation-in-ruby/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Simple Neural Network implementation in Ruby》<i class="icon-external"></i></a></li></ul><p>介绍: 使用Ruby实现简单的神经网络例子.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//karpathy.github.io/neuralnets/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Hacker's guide to Neural Networks》<i class="icon-external"></i></a></li></ul><p>介绍:神经网络黑客入门.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//datasciencemasters.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The Open-Source Data Science Masters》<i class="icon-external"></i></a></li></ul><p>介绍:好多数据科学家名人推荐,还有资料.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.01710" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Text Understanding from Scratch》<i class="icon-external"></i></a></li></ul><p>介绍:实现项目已经开源在github上面<a href="https://link.zhihu.com/?target=https%3A//github.com/zhangxiangxiao/Crepe" class=" wrap external" target="_blank" rel="nofollow noreferrer">Crepe<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=https%3A//levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《 Improving Distributional Similarity with Lessons Learned from Word Embeddings》<i class="icon-external"></i></a></li></ul><p>介绍:作者发现，经过调参，传统的方法也能和word2vec取得差不多的效果。另外，无论作者怎么试，GloVe都比不过word2vec.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs224d.stanford.edu/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CS224d: Deep Learning for Natural Language Processing》<i class="icon-external"></i></a></li></ul><p>介绍:Stanford深度学习与自然语言处理课程,Richard Socher主讲.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//courses.washington.edu/css490/2012.Winter/lecture_slides/02_math_essentials.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Math Essentials in Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习中的重要数学概念.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1503.00007" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks》<i class="icon-external"></i></a></li></ul><p>介绍:用于改进语义表示的树型LSTM递归神经网络,句子级相关性判断和情感分类效果很好.<a href="https://link.zhihu.com/?target=https%3A//github.com/stanfordnlp/treelstm" class=" wrap external" target="_blank" rel="nofollow noreferrer">实现代码<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.stat.cmu.edu/%7Elarry/%3Dsml/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Statistical Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:卡耐基梅隆Ryan Tibshirani和Larry Wasserman开设的机器学习课程，先修课程为机器学习(10-715)和中级统计学(36-705)，聚焦统计理论和方法在机器学习领域应用.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//am207.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《AM207: Monte Carlo Methods, Stochastic Optimization》<i class="icon-external"></i></a></li></ul><p>介绍:《哈佛大学蒙特卡洛方法与随机优化课程》是哈佛应用数学研究生课程，由V Kaynig-Fittkau、P Protopapas主讲，Python程序示例，对贝叶斯推理感兴趣的朋友一定要看看，提供授<a href="https://link.zhihu.com/?target=http%3A//nbviewer.ipython.org/github/AM207/2015/tree/master/Lectures/" class=" wrap external" target="_blank" rel="nofollow noreferrer">课视频及课上IPN讲义<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//spark-summit.org/wp-content/uploads/2015/03/SSE15-40-Danford.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《生物医学的SPARK大数据应用》<i class="icon-external"></i></a></li></ul><p>介绍:生物医学的SPARK大数据应用.并且伯克利开源了他们的big data genomics系统<a href="https://link.zhihu.com/?target=https%3A//github.com/bigdatagenomics/adam" class=" wrap external" target="_blank" rel="nofollow noreferrer">ADAM<i class="icon-external"></i></a>，其他的内容可以关注一下<a href="https://link.zhihu.com/?target=http%3A//spark-summit.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">官方主页<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//aclanthology.info/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《ACL Anthology》<i class="icon-external"></i></a></li></ul><p>介绍:对自然语言处理技术或者机器翻译技术感兴趣的亲们，请在提出自己牛逼到无以伦比的idea（自动归纳翻译规律、自动理解语境、自动识别语义等等）之前，请通过谷歌学术简单搜一下，如果谷歌不可用，这个网址有这个领域几大顶会的论文列表,切不可断章取义,胡乱假设.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.uni-weimar.de/medien/webis/publications/papers/stein_2015b.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Twitter Sentiment Detection via Ensemble Classification Using Averaged Confidence Scores》<i class="icon-external"></i></a></li></ul><p>介绍:论文+代码:基于集成方法的Twitter情感分类,<a href="https://link.zhihu.com/?target=https%3A//github.com/webis-de/ECIR-2015-and-SEMEVAL-2015" class=" wrap external" target="_blank" rel="nofollow noreferrer">实现代码<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ciml.chalearn.org/schedule" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NIPS 2014 CIML workshop》<i class="icon-external"></i></a></li></ul><p>介绍:NIPS CiML 2014的PPT,NIPS是神经信息处理系统进展大会的英文简称.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs231n.stanford.edu/reports.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CS231n: Convolutional Neural Networks for Visual Recognition》<i class="icon-external"></i></a></li></ul><p>介绍:斯坦福的深度学习课程的Projects 每个人都要写一个论文级别的报告 里面有一些很有意思的应用 大家可以看看 .</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.sumsar.net/blog/2015/03/a-speed-comparison-between-flexible-linear-regression-alternatives-in-r/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Speed Comparison Between Flexible Linear Regression Alternatives in R》<i class="icon-external"></i></a></li></ul><p>介绍:R语言线性回归多方案速度比较具体方案包括lm()、nls()、glm()、bayesglm()、nls()、mle2()、optim()和Stan’s optimizing()等.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.allthingsdistributed.com/2015/04/machine-learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Back-to-Basics Weekend Reading - Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:文中提到的三篇论文（机器学习那些事、无监督聚类综述、监督分类综述）都很经典，Domnigos的机器学习课也很精彩</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1504.00641" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Probabilistic Theory of Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍:莱斯大学（Rice University）的深度学习的概率理论.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.gregreda.com/2015/03/30/beer-review-markov-chains/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Nonsensical beer reviews via Markov chains》<i class="icon-external"></i></a></li></ul><p>介绍:基于马尔可夫链自动生成啤酒评论的开源Twitter机器人,<a href="https://link.zhihu.com/?target=https%3A//github.com/gjreda/beer-snob-says" class=" wrap external" target="_blank" rel="nofollow noreferrer">github地址<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//nlp.stanford.edu/courses/NAACL2013/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning for Natural Language Processing (without Magic)》<i class="icon-external"></i></a></li></ul><p>介绍:视频+讲义:深度学习用于自然语言处理教程(NAACL13).</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DU4IYsLgNgoY%26hd%3D1" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Data Analysis using Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:用机器学习做数据分析,David Taylor最近在McGill University研讨会上的报告，还提供了一系列讲机器学习方法的ipn，很有价值 <a href="https://link.zhihu.com/?target=https%3A//github.com/Prooffreader/intro_machine_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">GitHub<i class="icon-external"></i></a>.<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1mgtE9te" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1503.08909" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Beyond Short Snippets: Deep Networks for Video Classification》<i class="icon-external"></i></a></li></ul><p>介绍:基于CNN+LSTM的视频分类,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1c0cZS9E" class=" wrap external" target="_blank" rel="nofollow noreferrer">google演示<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.quora.com/How-does-Quora-use-machine-learning-in-2015/answer/Xavier-Amatriain" class=" wrap external" target="_blank" rel="nofollow noreferrer">《How does Quora use machine learning in 2015?》<i class="icon-external"></i></a></li></ul><p>介绍:Quora怎么用机器学习.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//aws.amazon.com/cn/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Amazon Machine Learning – Make Data-Driven Decisions at Scale》<i class="icon-external"></i></a></li></ul><p>介绍:亚马逊在机器学习上面的一些应用,<a href="https://link.zhihu.com/?target=https%3A//github.com/awslabs/machine-learning-samples" class=" wrap external" target="_blank" rel="nofollow noreferrer">代码示例<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ogrisel/parallel_ml_tutorial" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Parallel Machine Learning with scikit-learn and IPython》<i class="icon-external"></i></a></li></ul><p>介绍:并行机器学习指南(基于scikit-learn和IPython).<a href="https://link.zhihu.com/?target=http%3A//nbviewer.ipython.org/github/ogrisel/parallel_ml_tutorial/tree/master/notebooks/" class=" wrap external" target="_blank" rel="nofollow noreferrer">notebook<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.kaggle.com/2015/04/08/new-video-series-introduction-to-machine-learning-with-scikit-learn/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Intro to machine learning with scikit-learn》<i class="icon-external"></i></a></li></ul><p>介绍:DataSchool的机器学习基本概念教学.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/hughperkins/DeepCL" class=" wrap external" target="_blank" rel="nofollow noreferrer">《DeepCLn》<i class="icon-external"></i></a></li></ul><p>介绍:一个基于OpenGL实现的卷积神经网络，支持Linux及Windows系.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.mapr.com/blog/inside-look-at-components-of-recommendation-engine" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Inside Look at the Components of a Recommendation Engine》<i class="icon-external"></i></a></li></ul><p>介绍:基于Mahout和Elasticsearch的推荐系统.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ssc.upenn.edu/%7Efdiebold/Teaching221/econ221.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Forecasting in Economics, Business, Finance and Beyond》<i class="icon-external"></i></a></li></ul><p>介绍:Francis X. Diebold的《(经济|商业|金融等领域)预测方法.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.ssc.upenn.edu/%7Efdiebold/Teaching706/econ706Penn.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Time Series Econometrics - A Concise Course》<i class="icon-external"></i></a></li></ul><p>介绍:Francis X. Diebold的《时序计量经济学》.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//fotiad.is/blog/sentiment-analysis-comparison/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A comparison of open source tools for sentiment analysis》<i class="icon-external"></i></a></li></ul><p>介绍:基于Yelp数据集的开源<a href="https://link.zhihu.com/?target=https%3A//github.com/sfotiadis/yenlp" class=" wrap external" target="_blank" rel="nofollow noreferrer">情感分析工具<i class="icon-external"></i></a>比较,评测覆盖Naive Bayes、SentiWordNet、CoreNLP等 .</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/s/ayG13we2u_sAZ" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Pattern Recognition And Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:国内Pattern Recognition And Machine Learning读书会资源汇总,<a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/u/1841149974" class=" wrap external" target="_blank" rel="nofollow noreferrer">各章pdf讲稿<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/Nietzsche/" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Probabilistic Data Structures for Web Analytics and Data Mining 》<i class="icon-external"></i></a></li></ul><p>介绍:用于Web分析和数据挖掘的概率数据结构.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//blindmotion.github.io/2015/04/11/ml-in-navigation/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine learning in navigation devices: detect maneuvers using accelerometer and gyroscope》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习在导航上面的应用.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/user/Taylorns34/videos" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Neural Networks Demystified 》<i class="icon-external"></i></a></li></ul><p>介绍:Neural Networks Demystified系列视频，Stephen Welch制作，纯手绘风格，浅显易懂,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1i3AFURj" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内云<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.datacamp.com/swirl-r-tutorial" class=" wrap external" target="_blank" rel="nofollow noreferrer">《swirl + DataCamp 》<i class="icon-external"></i></a></li></ul><p>介绍:{swirl}数据训练营:R&amp;数据科学在线交互教程.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.terminal.com/recurrent-neural-networks-deep-net-optimization-lstm/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning to Read with Recurrent Neural Networks 》<i class="icon-external"></i></a></li></ul><p>介绍:关于深度学习和RNN的讨论 <a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.3215" class=" wrap external" target="_blank" rel="nofollow noreferrer">Sequence to Sequence Learning with Neural Networks<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//wanghaitao8118.blog.163.com/blog/static/13986977220153811210319/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《深度强化学习（Deep Reinforcement Learning）的资源》<i class="icon-external"></i></a></li></ul><p>介绍:Deep Reinforcement Learning.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/jakevdp/sklearn_pycon2015" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning with Scikit-Learn》<i class="icon-external"></i></a></li></ul><p>介绍:(PyCon2015)Scikit-Learn机器学习教程,<a href="https://link.zhihu.com/?target=https%3A//github.com/ogrisel/parallel_ml_tutorial" class=" wrap external" target="_blank" rel="nofollow noreferrer">Parallel Machine Learning with scikit-learn and IPython<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.cmu.edu/%7Eymiao/pdnntk.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《PDNN》<i class="icon-external"></i></a></li></ul><p>介绍:PDNN: A Python Toolkit for Deep Learning.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//alex.smola.org/teaching/10-701-15/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:15年春季学期CMU的机器学习课程，由Alex Smola主讲，提供讲义及授课视频，很不错.<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1pJxBePX" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内镜像<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.st.ewi.tudelft.nl/%7Ehauff/TI2736-B.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Big Data Processing》<i class="icon-external"></i></a></li></ul><p>介绍:大数据处理课.内容覆盖流处理、MapReduce、图算法等.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.hakkalabs.co/articles/spark-mllib-making-practical-machine-learning-easy-and-scalable" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Spark MLlib: Making Practical Machine Learning Easy and Scalable》<i class="icon-external"></i></a></li></ul><p>介绍:用Spark MLlib实现易用可扩展的机器学习,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1gdxSOZh" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内镜像<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//mrkulk.github.io/www_cvpr15/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Picture: A Probabilistic Programming Language for Scene Perception》<i class="icon-external"></i></a></li></ul><p>介绍:以往上千行代码概率编程(语言)实现只需50行.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Beautiful plotting in R: A ggplot2 cheatsheet》<i class="icon-external"></i></a></li></ul><p>介绍:ggplot2速查小册子,<a href="https://link.zhihu.com/?target=http%3A//www.ling.upenn.edu/%7Ejoseff/avml2012/" class=" wrap external" target="_blank" rel="nofollow noreferrer">另外一个<i class="icon-external"></i></a>,此外还推荐<a href="https://link.zhihu.com/?target=http%3A//zevross.com/blog/2015/01/13/a-new-data-processing-workflow-for-r-dplyr-magrittr-tidyr-ggplot2/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A new data processing workflow for R: dplyr, magrittr, tidyr, ggplot2》<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//emnlp2014.org/papers/pdf/EMNLP2014148.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Using Structured Events to Predict Stock Price Movement: An Empirical Investigation》<i class="icon-external"></i></a></li></ul><p>介绍:用结构化模型来预测实时股票行情.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ijcai-15.org/index.php/accepted-papers" class=" wrap external" target="_blank" rel="nofollow noreferrer">《International Joint Conference on Artificial Intelligence Accepted paper》<i class="icon-external"></i></a></li></ul><p>介绍:<a href="https://link.zhihu.com/?target=http%3A//ijcai.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">国际人工智能联合会议<i class="icon-external"></i></a>录取论文列表,大部分论文可使用Google找到.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Why GEMM is at the heart of deep learning》<i class="icon-external"></i></a></li></ul><p>介绍:一般矩阵乘法(GEMM)对深度学习的重要性.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/dmlc" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Distributed (Deep) Machine Learning Common》<i class="icon-external"></i></a></li></ul><p>介绍:A Community of awesome Distributed Machine Learning C++ projects.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//webdocs.cs.ualberta.ca/%7Esutton/book/the-book.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Reinforcement Learning: An Introduction》<i class="icon-external"></i></a></li></ul><p>介绍:免费电子书&lt;强化学习介绍&gt;,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1jkaMq" class=" wrap external" target="_blank" rel="nofollow noreferrer">第一版(1998)<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1dDnNEnR" class=" wrap external" target="_blank" rel="nofollow noreferrer">第二版(2015草稿)<i class="icon-external"></i></a>,相关课程<a href="https://link.zhihu.com/?target=http%3A//incompleteideas.net/rlai.cs.ualberta.ca/RLAI/RLAIcourse/2010.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">资料<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//www.inf.ed.ac.uk/teaching/courses/rl/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Reinforcement Learning<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blogs.msdn.com/b/microsoft_press/archive/2015/04/15/free-ebook-microsoft-azure-essentials-azure-machine-learning.aspx" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Free ebook: Microsoft Azure Essentials: Azure Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:免费书:Azure ML使用精要.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Deep Learning Tutorial: From Perceptrons to Deep Networks》<i class="icon-external"></i></a></li></ul><p>介绍:A Deep Learning Tutorial: From Perceptrons to Deep Networks.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//medium.com/%40ageitgey/machine-learning-is-fun-80ea3ec3c471" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning is Fun! - The world’s easiest introduction to Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:有趣的机器学习：最简明入门指南,<a href="https://link.zhihu.com/?target=http%3A//blog.jobbole.com/67616/" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/yyue.blogspot.com/2015/01/a-brief-overview-of-deep-learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Brief Overview of Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习简明介绍,<a href="https://link.zhihu.com/?target=http%3A//xhrwang.me/2015/01/16/a-brief-overview-of-deep-learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/dmlc/wormhole" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Wormhole》<i class="icon-external"></i></a></li></ul><p>介绍:Portable, scalable and reliable distributed machine learning.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/soumith/convnet-benchmarks" class=" wrap external" target="_blank" rel="nofollow noreferrer">《convnet-benchmarks》<i class="icon-external"></i></a></li></ul><p>介绍:CNN开源实现横向评测,参评框架包括Caffe 、Torch-7、CuDNN 、cudaconvnet2 、fbfft、Nervana Systems等，NervanaSys表现突出.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//islpc21.is.cs.cmu.edu%3A3000/lti_catalogue" class=" wrap external" target="_blank" rel="nofollow noreferrer">《This catalogue lists resources developed by faculty and students of the Language Technologies Institute.》<i class="icon-external"></i></a></li></ul><p>介绍:卡耐基梅隆大学计算机学院语言技术系的资源大全,包括大量的NLP开源软件工具包，基础数据集，论文集，数据挖掘教程，机器学习资源.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/mayank93/Twitter-Sentiment-Analysis" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Sentiment Analysis on Twitter》<i class="icon-external"></i></a></li></ul><p>介绍:Twitter情感分析工具SentiTweet,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1i3kXPlj" class=" wrap external" target="_blank" rel="nofollow noreferrer">视频+讲义<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//machinelearning.wustl.edu/mlpapers/venues" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine Learning Repository @ Wash U》<i class="icon-external"></i></a></li></ul><p>介绍:华盛顿大学的Machine Learning Paper Repository.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/soulmachine/machine-learning-cheat-sheet" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Machine learning cheat sheet》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习速查表.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//spark-summit.org/east" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Spark summit east 2015 agenda》<i class="icon-external"></i></a></li></ul><p>介绍:最新的Spark summit会议资料.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//spark-summit.org/east" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Spark summit east 2015 agenda》<i class="icon-external"></i></a></li></ul><p>介绍:最新的Spark summit会议资料.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1eQkybJG" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning Spark》<i class="icon-external"></i></a></li></ul><p>介绍:Ebook Learning Spark.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1jGot9qe" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Advanced Analytics with Spark, Early Release Edition》<i class="icon-external"></i></a></li></ul><p>介绍:Ebook Advanced Analytics with Spark, Early Release Edition.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//keg.cs.tsinghua.edu.cn/jietang/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《国内机器学习算法及应用领域人物篇:唐杰》<i class="icon-external"></i></a></li></ul><p>介绍:清华大学副教授，是图挖掘方面的专家。他主持设计和实现的Arnetminer是国内领先的图挖掘系统，该系统也是多个会议的支持商.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cse.ust.hk/%7Eqyang/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《国内机器学习算法及应用领域人物篇:杨强》<i class="icon-external"></i></a></li></ul><p>介绍:迁移学习的国际领军人物.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs.nju.edu.cn/zhouzh/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《国内机器学习算法及应用领域人物篇:周志华》<i class="icon-external"></i></a></li></ul><p>介绍:在半监督学习，multi-label学习和集成学习方面在国际上有一定的影响力.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ir.hit.edu.cn/%7Ewanghaifeng/whf_pub.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">《国内机器学习算法及应用领域人物篇:王海峰》<i class="icon-external"></i></a></li></ul><p>介绍:信息检索，自然语言处理，机器翻译方面的专家.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.jhu.edu/%7Ejunwu/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《国内机器学习算法及应用领域人物篇:吴军》<i class="icon-external"></i></a></li></ul><p>介绍:吴军博士是当前Google中日韩文搜索算法的主要设计者。在Google其间，他领导了许多研发项目，包括许多与中文相关的产品和自然语言处理的项目,他的<a href="https://link.zhihu.com/?target=https%3A//sites.google.com/site/junwu02" class=" wrap external" target="_blank" rel="nofollow noreferrer">新个人主页<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.eecs.berkeley.edu/%7Ejunyanz/cat/cat_papers.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Cat Paper Collection》<i class="icon-external"></i></a></li></ul><p>介绍:喵星人相关论文集.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.dato.com/how-to-evaluate-machine-learning-models-part-1-orientation" class=" wrap external" target="_blank" rel="nofollow noreferrer">《How to Evaluate Machine Learning Models, Part 1: Orientation》<i class="icon-external"></i></a></li></ul><p>介绍:如何评价机器学习模型系列文章,<a href="https://link.zhihu.com/?target=http%3A//blog.dato.com/how-to-evaluate-machine-learning-models-part-2a-classification-metrics" class=" wrap external" target="_blank" rel="nofollow noreferrer">How to Evaluate Machine Learning Models, Part 2a: Classification Metrics<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//blog.dato.com/how-to-evaluate-machine-learning-models-part-2b-ranking-and-regression-metrics" class=" wrap external" target="_blank" rel="nofollow noreferrer">How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//blog.twitter.com/2015/building-a-new-trends-experience" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Building a new trends experience》<i class="icon-external"></i></a></li></ul><p>介绍:Twitter新trends的基本实现框架.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.packtpub.com/big-data-and-business-intelligence/storm-blueprints-patterns-distributed-real-time-computation" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Storm Blueprints: Patterns for Distributed Real-time Computation》<i class="icon-external"></i></a></li></ul><p>介绍:Storm手册，国内有<a href="https://link.zhihu.com/?target=https%3A//github.com/cjie888/storm-trident" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文翻译版本<i class="icon-external"></i></a>,谢谢作者.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/haifengl/smile" class=" wrap external" target="_blank" rel="nofollow noreferrer">《SmileMiner》<i class="icon-external"></i></a></li></ul><p>介绍:Java机器学习算法库SmileMiner.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//nlp.csai.tsinghua.edu.cn/%7Ely/talks/cwmt14_tut.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《机器翻译学术论文写作方法和技巧》<i class="icon-external"></i></a></li></ul><p>介绍:机器翻译学术论文写作方法和技巧，Simon Peyton Jones的<a href="https://link.zhihu.com/?target=http%3A//research.microsoft.com/en-us/um/people/simonpj/papers/giving-a-talk/giving-a-talk.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">How to write a good research paper<i class="icon-external"></i></a>同类视频<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3Dg3dkRsTqdDA" class=" wrap external" target="_blank" rel="nofollow noreferrer">How to Write a Great Research Paper<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/s/ayG13we2volht" class=" wrap external" target="_blank" rel="nofollow noreferrer">how to paper talk<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/45288129" class=" wrap external" target="_blank" rel="nofollow noreferrer">《神经网络训练中的Tricks之高效BP（反向传播算法）》<i class="icon-external"></i></a></li></ul><p>介绍:神经网络训练中的Tricks之高效BP,博主的其他博客也挺精彩的.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.52cs.org/%3Fp%3D499" class=" wrap external" target="_blank" rel="nofollow noreferrer">《我和NLP的故事》<i class="icon-external"></i></a></li></ul><p>介绍:作者是NLP方向的硕士，短短几年内研究成果颇丰,推荐新入门的朋友阅读.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.ucla.edu/%7Epalsberg/h-number.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The h Index for Computer Science 》<i class="icon-external"></i></a></li></ul><p>介绍:UCLA的Jens Palsberg根据Google Scholar建立了一个计算机领域的H-index牛人列表,我们熟悉的各个领域的大牛绝大多数都在榜上，包括1位诺贝尔奖得主，35位图灵奖得主，近百位美国工程院/科学院院士，300多位ACM Fellow,在这里推荐的原因是大家可以在google通过搜索牛人的名字来获取更多的资源,这份资料很宝贵.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ttic.uchicago.edu/%7Embansal/papers/acl14_structuredTaxonomy.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Structured Learning for Taxonomy Induction with Belief Propagation》<i class="icon-external"></i></a></li></ul><p>介绍:用大型语料库学习概念的层次关系，如鸟是鹦鹉的上级，鹦鹉是虎皮鹦鹉的上级。创新性在于模型构造，用因子图刻画概念之间依存关系，因引入兄弟关系，图有环，所以用有环扩散（loopy propagation）迭代计算边际概率（marginal probability）.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.stata.com/stata14/bayesian-analysis/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Bayesian analysis》<i class="icon-external"></i></a></li></ul><p>介绍: 这是一款贝叶斯分析的商业软件,官方写的<a href="https://link.zhihu.com/?target=http%3A//www.stata.com/manuals14/bayes.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">贝叶斯分析的手册<i class="icon-external"></i></a>有250多页,虽然R语言 已经有类似的<a href="https://link.zhihu.com/?target=http%3A//cran.r-project.org/web/views/Bayesian.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">项目<i class="icon-external"></i></a>,但毕竟可以增加一个可选项.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.quora.com/Boris-Babenko/Posts/deep-net-highlights-from-2014" class=" wrap external" target="_blank" rel="nofollow noreferrer">《deep net highlights from 2014》<i class="icon-external"></i></a></li></ul><p>介绍:deep net highlights from 2014.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1504.08083v1.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Fast R-CNN》<i class="icon-external"></i></a></li></ul><p>介绍:This paper proposes Fast R-CNN, a clean and fast framework for object detection.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//realpython.com/blog/python/fingerprinting-images-for-near-duplicate-detection/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Fingerprinting Images for Near-Duplicate Detection》<i class="icon-external"></i></a></li></ul><p>介绍:图像指纹的重复识别,作者<a href="https://link.zhihu.com/?target=https%3A//github.com/realpython/image-fingerprinting/blob/master/code/output.csv" class=" wrap external" target="_blank" rel="nofollow noreferrer">源码<i class="icon-external"></i></a>,国内<a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/wing1995/p/4471034.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">翻译版本<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.ubc.ca/%7Elowe/vision.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The Computer Vision Industry 》<i class="icon-external"></i></a></li></ul><p>介绍:提供计算机视觉、机器视觉应用的公司信息汇总.应用领域包括：自动辅助驾驶和交通管理、眼球和头部跟踪、影视运动分析、影视业、手势识别、通用视觉系统、各种工业自动化和检验、医药和生物、移动设备目标识别和AR、人群跟踪、摄像、安全监控、生物监控、三维建模、web和云应用.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/mwaskom/seaborn" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Seaborn: statistical data visualization》<i class="icon-external"></i></a></li></ul><p>介绍:Python版可视化数据统计开源库.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.juanklopper.com/opencourseware/mathematics-2/ipython-lecture-notes/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《IPython lecture notes for OCW MIT 18.06》<i class="icon-external"></i></a></li></ul><p>介绍:麻省理工Gilbert Strang线性代数课程笔记,Gilbert Strang《Linear Algebra》课程主页<a href="https://link.zhihu.com/?target=http%3A//ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/index.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">视频+讲义<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning4j.org/canova.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Canova: A Vectorization Lib for ML》<i class="icon-external"></i></a></li></ul><p>介绍:面向机器学习/深度学习的数据向量化工具Canova,<a href="https://link.zhihu.com/?target=https%3A//github.com/deeplearning4j/Canova" class=" wrap external" target="_blank" rel="nofollow noreferrer">github<i class="icon-external"></i></a>, 支持CSV文件、MNIST数据、TF-IDF/Bag of Words/word2vec文本向量化.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//java.dzone.com/articles/dzone-refcardz-distributed" class=" wrap external" target="_blank" rel="nofollow noreferrer">《DZone Refcardz: Distributed Machine Learning with Apache Mahout》<i class="icon-external"></i></a></li></ul><p>介绍:快速入门：基于Apache Mahout的分布式机器学习.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//nbviewer.ipython.org/github/gmonce/scikit-learn-book/tree/master/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning scikit-learn: Machine Learning in Python》<i class="icon-external"></i></a></li></ul><p>介绍:基于scikit-learn讲解了一些机器学习技术，如SVM，NB，PCA，DT，以及特征工程、特征选择和模型选择问题.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//speakerdeck.com/nivdul/lightning-fast-machine-learning-with-spark" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Lightning fast Machine Learning with Spark》<i class="icon-external"></i></a></li></ul><p>介绍:基于Spark的高效机器学习,<a href="https://link.zhihu.com/?target=https%3A//www.parleys.com/tutorial/lightning-fast-machine-learning-spark" class=" wrap external" target="_blank" rel="nofollow noreferrer">视频地址<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.wepay.com/how-were-using-machine-learning-to-fight-shell-selling/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《How we’re using machine learning to fight shell selling》<i class="icon-external"></i></a></li></ul><p>介绍:WePay用机器学习对抗信用卡"shell selling"诈骗.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.datasciencecentral.com/profiles/blog/show%3Fid%3D6448529%3ABlogPost%3A273276" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Data Scientists Thoughts that Inspired Me》<i class="icon-external"></i></a></li></ul><p>介绍:16位数据科学家语录精选.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.journalofbigdata.com/content/2/1/1" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep learning applications and challenges in big data analytics》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习在大数据分析领域的应用和挑战.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//resrc.io/list/10/list-of-free-programming-books/%23machine-learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Free book:Machine Learning,Mathematics》<i class="icon-external"></i></a></li></ul><p>介绍:免费的机器学习与数学书籍,除此之外还有其他的<a href="https://link.zhihu.com/?target=https%3A//github.com/vhf/resrc" class=" wrap external" target="_blank" rel="nofollow noreferrer">免费编程书籍<i class="icon-external"></i></a>,编程语言,设计,操作系统等.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1505.01749.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Object detection via a multi-region &amp; semantic segmentation-aware CNN model》<i class="icon-external"></i></a></li></ul><p>介绍:一篇关于CNN模型对象识别Paper.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.shakirm.com/2015/05/a-statistical-view-of-deep-learning-v-generalisation-and-regularisation/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Statistical View of Deep Learning (V): Generalisation and Regularisation》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习的统计分析V:泛化和正则化.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1505.00387" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Highway Networks》<i class="icon-external"></i></a></li></ul><p>介绍:用SGD能高效完成训练的大规模(多层)深度网络HN.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.erogol.com/what-i-read-for-deep-learning/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《What I Read For Deep-Learning》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习解读文章.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//dataconomy.com/an-introduction-to-recommendation-engines" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Introduction to Recommendation Engines》<i class="icon-external"></i></a></li></ul><p>介绍:Coursera上的推荐系统导论（Introduction to Recommender Systems）公开课.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.holehouse.org/mlclass/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Stanford Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:Andrew Ng经典机器学习课程笔记.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//yaroslavvb.blogspot.de/2015/05/iclr-2015_12.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《ICLR 2015》<i class="icon-external"></i></a></li></ul><p>介绍:ICLR 2015见闻录,<a href="https://link.zhihu.com/?target=http%3A//yaroslavvb.blogspot.de/" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客<i class="icon-external"></i></a>的其他机器学习文章也不错.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cripac.ia.ac.cn/People/sw/Xu2015PSR.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Stanford Machine Learning》<i class="icon-external"></i></a></li></ul><p>介绍:推荐系统"个性化语义排序"模型.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//senseable.mit.edu/tweetbursts/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The More Excited We Are, The Shorter We Tweet》<i class="icon-external"></i></a></li></ul><p>介绍:激情时分更惜字——MIT的最新Twitter研究结果.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//hlt.suda.edu.cn/paper.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《苏州大学人类语言技术研究论文主页》<i class="icon-external"></i></a></li></ul><p>介绍:苏州大学人类语言技术研究相关论文.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1505.00387" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Neural Turing Machines implementation》<i class="icon-external"></i></a></li></ul><p>介绍:实现神经图灵机(NTM),<a href="https://link.zhihu.com/?target=https%3A//github.com/fumin/ntm" class=" wrap external" target="_blank" rel="nofollow noreferrer">项目地址<i class="icon-external"></i></a>,此外推荐相关神经图灵机<a href="https://link.zhihu.com/?target=http%3A//www.i-programmer.info/news/105-artificial-intelligence/7923-neural-turing-machines-learn-their-algorithms.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">算法<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cse.wustl.edu/%7Efurukawa/cse559a/2015_spring/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Computer Vision - CSE 559A, Spring 2015》<i class="icon-external"></i></a></li></ul><p>介绍:华盛顿大学的机器视觉(2015),参考资料<a href="https://link.zhihu.com/?target=http%3A//szeliski.org/Book/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Computer Vision: Algorithms and Applications<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.mmds.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Mining of Massive Datasets》<i class="icon-external"></i></a></li></ul><p>介绍:"Mining of Massive Datasets"发布第二版,Jure Leskovec, Anand Rajaraman, Jeff Ullman 新版增加Jure Leskovec作为合作作者，新增社交网络图数据挖掘、降维和大规模机器学习三章,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1GvtpG" class=" wrap external" target="_blank" rel="nofollow noreferrer">电子版<i class="icon-external"></i></a>依旧免费.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//rt.dgyblog.com/ref/ref-learning-deep-learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍:一个深度学习资源页,资料很丰富.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//vdisk.weibo.com/s/ayG13we2ler9b" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Learning Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍:免费电子书"Learning Deep Learning".</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.astroml.org/sklearn_tutorial/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Tutorial: Machine Learning for Astronomy with Scikit-learn》<i class="icon-external"></i></a></li></ul><p>介绍:Machine Learning for Astronomy with scikit-learn.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//info.salford-systems.com/an-introduction-to-random-forests-for-beginners" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Introduction to Random Forests for Beginners》<i class="icon-external"></i></a></li></ul><p>介绍:免费电子书"随机森林入门指南".</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//rayli.net/blog/data/top-10-data-mining-algorithms-in-plain-english/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Top 10 data mining algorithms in plain English》<i class="icon-external"></i></a></li></ul><p>介绍:白话数据挖掘十大算法.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.mapr.com/blog/inside-look-at-components-of-recommendation-engine%23.VVmZ5vmqqko" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Inside Look at the Components of a Recommendation Engine》<i class="icon-external"></i></a></li></ul><p>介绍:基于Mahout和Elasticsearch的推荐系统,<a href="https://link.zhihu.com/?target=http%3A//www.csdn.net/article/2015-05-14/2824676" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内译版<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//aaltodoc.aalto.fi/bitstream/handle/123456789/15585/isbn9789526061498.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Advances in Extreme Learning Machines》<i class="icon-external"></i></a></li></ul><p>介绍:博士学位论文:ELM研究进展.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//vimeo.com/59324550" class=" wrap external" target="_blank" rel="nofollow noreferrer">《10-minute tour of pandas》<i class="icon-external"></i></a></li></ul><p>介绍:Pandas十分钟速览,<a href="https://link.zhihu.com/?target=http%3A//nbviewer.ipython.org/urls/gist.github.com/wesm/4757075/raw/a72d3450ad4924d0e74fb57c9f62d1d895ea4574/PandasTour.ipynb" class=" wrap external" target="_blank" rel="nofollow noreferrer">ipn<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pudo.org/blog/2015/05/15/document-mining.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Data doesn't grow in tables: harvesting journalistic insight from documents》<i class="icon-external"></i></a></li></ul><p>介绍:面向数据新闻的文本挖掘.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//grail.cs.washington.edu/projects/timelapse/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Time-lapse Mining from Internet Photos》<i class="icon-external"></i></a></li></ul><p>介绍:用网络图片合成延时视频(SIGGRAPH 2015).</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The Curse of Dimensionality in classification》<i class="icon-external"></i></a></li></ul><p>介绍:分类系统的维数灾难.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.computervisionblog.com/2015/05/deep-learning-vs-big-data-who-owns-what.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning vs Big Data: Who owns what?》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习vs.大数据——从数据到知识：版权的思考,[翻译版](<a href="https://link.zhihu.com/?target=http%3A//www.csdn.net/article/2015-05-19/2824707" class=" wrap external" target="_blank" rel="nofollow noreferrer">深度学习 vs. 大数据：神经网络权值的版权属于谁？-CSDN.NET<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.nature.com/ctg/journal/v5/n1/abs/ctg201319a.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Primer on Predictive Models》<i class="icon-external"></i></a></li></ul><p>介绍:预测模型入门.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.terminal.com/demistifying-long-short-term-memory-lstm-recurrent-neural-networks/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Demistifying LSTM Neural Networks》<i class="icon-external"></i></a></li></ul><p>介绍:深入浅出LSTM.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPLhiWXaTdsWB8PnrVZquVyqlRFWXM4ijYz" class=" wrap external" target="_blank" rel="nofollow noreferrer">《ICLR 2015》<i class="icon-external"></i></a></li></ul><p>介绍:2015年ICLR会议<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1bnbbRyR" class=" wrap external" target="_blank" rel="nofollow noreferrer">视频<i class="icon-external"></i></a>与<a href="https://link.zhihu.com/?target=http%3A//www.iclr.cc/doku.php%3Fid%3Diclr2015%3Amain" class=" wrap external" target="_blank" rel="nofollow noreferrer">讲义<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//dataremixed.com/2015/05/on-visualizing-data-well/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《On Visualizing Data Well》<i class="icon-external"></i></a></li></ul><p>介绍:Ben Jones的数据可视化建议.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//bigdata-madesimple.com/decoding-dimensionality-reduction-pca-and-svd/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Decoding Dimensionality Reduction, PCA and SVD》<i class="icon-external"></i></a></li></ul><p>介绍:解读数据降维/PCA/SVD.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//ryancompton.net/assets/ml_cheat_sheet/supervised_learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Supervised learning superstitions cheat sheet》<i class="icon-external"></i></a></li></ul><p>介绍:IPN:监督学习方法示例/对比参考表,覆盖logistic回归, 决策树, SVM, KNN, Naive Bayes等方法.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1505.04771" class=" wrap external" target="_blank" rel="nofollow noreferrer">《DopeLearning: A Computational Approach to Rap Lyrics Generation》<i class="icon-external"></i></a></li></ul><p>介绍:基于RankSVM和DNN自动(重组)生成Rap歌词.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.sics.se/%7Emange/papers/RI_intro.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《An Introduction to Random Indexing》<i class="icon-external"></i></a></li></ul><p>介绍:随机索引RI词空间模型专题.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.vdiscover.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《VDiscover》<i class="icon-external"></i></a></li></ul><p>介绍:基于机器学习的漏洞检测工具VDiscover.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/dmlc/minerva" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Minerva》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习系统minerva。拥有python编程接口。多GPU几乎达到线性加速。在4块GPU上能在4天内将GoogLeNet训练到68.7%的top-1以及89.0%的top-5准确率。和同为dmlc项目的cxxnet相比，采用动态数据流引擎，提供更多灵活性。未来将和cxxnet一起整合为mxnet项目，互取优势.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.cv-foundation.org/openaccess/CVPR2015.py" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CVPR 2015 paper》<i class="icon-external"></i></a></li></ul><p>介绍:2015年国际计算机视觉与模式识别会议paper.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.quora.com/What-are-the-advantages-of-different-classification-algorithms/answer/Xavier-Amatriain" class=" wrap external" target="_blank" rel="nofollow noreferrer">《What are the advantages of different classification algorithms?》<i class="icon-external"></i></a></li></ul><p>介绍:Netflix工程总监眼中的分类算法：深度学习优先级最低,<a href="https://link.zhihu.com/?target=http%3A//www.csdn.net/article/2015-05-24/2824758" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.codalab.org/competitions/3221%23results" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Results for Microsoft COCO Image Captioning Challenge》<i class="icon-external"></i></a></li></ul><p>介绍:Codalab图像标注竞赛排行+各家论文,Reddit上flukeskywalker整理了各家技术<a href="https://link.zhihu.com/?target=http%3A//www.reddit.com/r/MachineLearning/comments/376b28/comparison_of_official_test_scores_of_current/" class=" wrap external" target="_blank" rel="nofollow noreferrer">相关论文<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1504.04343" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Caffe con Troll: Shallow Ideas to Speed Up Deep Learning》<i class="icon-external"></i></a></li></ul><p>介绍:基于Caffe的加速深度学习系统CcT.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.7024" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Low precision storage for deep learning》<i class="icon-external"></i></a></li></ul><p>介绍:深度学习(模型)低精度(训练与)存储.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.mbmlbook.com/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Model-Based Machine Learning (Early Access)》<i class="icon-external"></i></a></li></ul><p>介绍:新书预览:模型机器学习.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.princeton.edu/%7Esbubeck/SurveyBCB12.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems》<i class="icon-external"></i></a></li></ul><p>介绍:免费电子书多臂老虎机,此外推荐<a href="https://link.zhihu.com/?target=https%3A//sites.google.com/site/banditstutorial/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Introduction to Bandits: Algorithms and Theory<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.datacamp.com/courses/kaggle-tutorial-on-machine-learing-the-sinking-of-the-titanic" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Kaggle R Tutorial on Machine Learing》<i class="icon-external"></i></a></li></ul><p>介绍:基于Kaggle's Titanic Competition的交互式R机器学习教程,介绍<a href="https://link.zhihu.com/?target=http%3A//blog.kaggle.com/2015/05/27/interactive-r-tutorial-machine-learning-for-the-titanic-competition/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Interactive R Tutorial: Machine Learning for the Titanic Competition》<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//suanfazu.com/t/deep-learning/9401" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Deep Learning（深度学习）学习笔记整理系列》<i class="icon-external"></i></a></li></ul><p>介绍:Deep Learning（深度学习）学习笔记整理系列.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Introduction to Neural Machine Translation with GPUs 》<i class="icon-external"></i></a></li></ul><p>介绍:神经(感知)机器翻译介绍.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3Dn1ViNeWhC24%26hd%3D1" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Andrew Ng: Deep Learning, Self-Taught Learning and Unsupervised Feature Learning》<i class="icon-external"></i></a></li></ul><p>介绍:Andrew Ng关于深度学习/自学习/无监督特征学习的报告,<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1jG8DUN8" class=" wrap external" target="_blank" rel="nofollow noreferrer">国内云<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1505.04630" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Recurrent Neural Network Training with Dark Knowledge Transfer》<i class="icon-external"></i></a></li></ul><p>介绍:论文:通过潜在知识迁移训练RNN.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/chrischris292/ShowMeTheMoney" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Show Me The Money》<i class="icon-external"></i></a></li></ul><p>介绍:面向金融数据的情感分析工具.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/bmabey/pyLDAvis" class=" wrap external" target="_blank" rel="nofollow noreferrer">《pyLDAvis》<i class="icon-external"></i></a></li></ul><p>介绍:(Python)主题模型交互可视化库pyLDAvis.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//nbviewer.ipython.org/github/tfolkman/learningwithdata/blob/master/Logistic%2520Gradient%2520Descent.ipynb" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Logistic Regression and Gradient Descent》<i class="icon-external"></i></a></li></ul><p>介绍:Logistic回归与优化实例教程.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1dDGVL53" class=" wrap external" target="_blank" rel="nofollow noreferrer">《贾扬清微信讲座记录》<i class="icon-external"></i></a></li></ul><p>介绍:贾扬清（谷歌大脑科学家、caffe缔造者）微信讲座记录.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/udibr/sketch" class=" wrap external" target="_blank" rel="nofollow noreferrer">《sketch》<i class="icon-external"></i></a></li></ul><p>介绍:Theano/Blocks实现RNN手写字符串生成sketch.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//chris.de-vries.id.au/2015/05/web-scale-document-clustering.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Web Scale Document Clustering: Clustering 733 Million Web Pages》<i class="icon-external"></i></a></li></ul><p>介绍:基于TopSig的海量(7亿+)网页聚类.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//aclweb.org/anthology/N/N15/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NAACL 2015 Proceedings on ACL Anthology》<i class="icon-external"></i></a></li></ul><p>介绍:NAACL 2015 论文papers.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.anlytcs.com/2015/05/stock-forecasting-with-machine-learning.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Stock Forecasting With Machine Learning - Seven Possible Errors》<i class="icon-external"></i></a></li></ul><p>介绍:机器学习预测股市的七个问题.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.reddit.com/r/MachineLearning/comments/378but/are_there_any_good_resources_for_learning_about/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Are there any good resources for learning about neural networks?》<i class="icon-external"></i></a></li></ul><p>介绍:神经网络学习资料推荐.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1506.00019v1" class=" wrap external" target="_blank" rel="nofollow noreferrer">《A Critical Review of Recurrent Neural Networks for Sequence Learning》<i class="icon-external"></i></a></li></ul><p>介绍:面向序列学习的RNN综述.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//gastonsanchez.com/Handling_and_Processing_Strings_in_R.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Handling and Processing Strings in R》<i class="icon-external"></i></a></li></ul><p>介绍:R文本处理手册.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/s16h/py-must-watch" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Must-watch videos about Python》<i class="icon-external"></i></a></li></ul><p>介绍:“必看”的Python视频集锦.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//malteschwarzkopf.de/research/assets/google-stack.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《The Google Stack》<i class="icon-external"></i></a></li></ul><p>介绍:Google(基础结构)栈.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/mmahoney/f13-stat260-cs294/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Randomized Algorithms for Matrices and Data》<i class="icon-external"></i></a></li></ul><p>介绍:矩阵和数据的随机算法(UC Berkeley 2013).</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//www.datacamp.com/courses/intermediate-r" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Intermediate R》<i class="icon-external"></i></a></li></ul><p>介绍:DataCamp中级R语言教程.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.topologywithouttears.net/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Topology Without Tears》<i class="icon-external"></i></a></li></ul><p>介绍:免费电子书:轻松掌握拓扑学,<a href="https://link.zhihu.com/?target=http%3A//www.topologywithouttears.net/topbookchinese.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//www.inference.phy.cam.ac.uk/itprnn_lectures/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Information Theory, Pattern Recognition, and Neural Networks》<i class="icon-external"></i></a></li></ul><p>介绍:<a href="https://link.zhihu.com/?target=http%3A//www.inference.phy.cam.ac.uk/itprnn/book.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Book<i class="icon-external"></i></a>,<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/user/jakobfoerster/videos" class=" wrap external" target="_blank" rel="nofollow noreferrer">video<i class="icon-external"></i></a>.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/scikit-learn/scikit-learn" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Scikit-learn》<i class="icon-external"></i></a></li></ul><p>介绍:Scikit-learn 是基于Scipy为机器学习建造的的一个Python模块，他的特色就是多样化的分类，回归和聚类的算法包括支持向量机，逻辑回归，朴素贝叶斯分类器，随机森林，Gradient Boosting，聚类算法和DBSCAN。而且也设计出了Python numerical和scientific libraries Numpy and Scipy</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/lisa-lab/pylearn2" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Pylearn2》<i class="icon-external"></i></a></li></ul><p>介绍:Pylearn是一个让机器学习研究简单化的基于Theano的库程序。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/numenta/nupic" class=" wrap external" target="_blank" rel="nofollow noreferrer">《NuPIC》<i class="icon-external"></i></a></li></ul><p>介绍:NuPIC是一个以HTM学习算法为工具的机器智能平台。HTM是皮层的精确计算方法。HTM的核心是基于时间的持续学习算法和储存和撤销的时空模式。NuPIC适合于各种各样的问题,尤其是检测异常和预测的流数据来源。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/nilearn/nilearn" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Nilearn》<i class="icon-external"></i></a></li></ul><p>介绍:Nilearn 是一个能够快速统计学习神经影像数据的Python模块。它利用Python语言中的scikit-learn 工具箱和一些进行预测建模，分类，解码，连通性分析的应用程序来进行多元的统计。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/pybrain/pybrain" class=" wrap external" target="_blank" rel="nofollow noreferrer">《PyBrain》<i class="icon-external"></i></a></li></ul><p>介绍:Pybrain是基于Python语言强化学习，人工智能，神经网络库的简称。 它的目标是提供灵活、容易使用并且强大的机器学习算法和进行各种各样的预定义的环境中测试来比较你的算法。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/clips/pattern" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Pattern》<i class="icon-external"></i></a></li></ul><p>介绍:Pattern 是Python语言下的一个网络挖掘模块。它为数据挖掘，自然语言处理，网络分析和机器学习提供工具。它支持向量空间模型、聚类、支持向量机和感知机并且用KNN分类法进行分类。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/mila-udem/fuel" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Fuel》<i class="icon-external"></i></a></li></ul><p>介绍:Fuel为你的机器学习模型提供数据。他有一个共享如MNIST, CIFAR-10 (图片数据集), Google’s One Billion Words (文字)这类数据集的接口。你使用他来通过很多种的方式来替代自己的数据。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/idiap/bob" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Bob》<i class="icon-external"></i></a></li></ul><p>介绍:Bob是一个免费的信号处理和机器学习的工具。它的工具箱是用Python和C++语言共同编写的，它的设计目的是变得更加高效并且减少开发时间，它是由处理图像工具,音频和视频处理、机器学习和模式识别的大量软件包构成的。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/jaberg/skdata" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Skdata》<i class="icon-external"></i></a></li></ul><p>介绍:Skdata是机器学习和统计的数据集的库程序。这个模块对于玩具问题，流行的计算机视觉和自然语言的数据集提供标准的Python语言的使用。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/luispedro/milk" class=" wrap external" target="_blank" rel="nofollow noreferrer">《MILK》<i class="icon-external"></i></a></li></ul><p>介绍:MILK是Python语言下的机器学习工具包。它主要是在很多可得到的分类比如SVMS,K-NN,随机森林，决策树中使用监督分类法。 它还执行特征选择。 这些分类器在许多方面相结合,可以形成不同的例如无监督学习、密切关系金传播和由MILK支持的K-means聚类等分类系统。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/machinalis/iepy" class=" wrap external" target="_blank" rel="nofollow noreferrer">《IEPY》<i class="icon-external"></i></a></li></ul><p>介绍:IEPY是一个专注于关系抽取的开源性信息抽取工具。它主要针对的是需要对大型数据集进行信息提取的用户和想要尝试新的算法的科学家。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/machinalis/quepy" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Quepy》<i class="icon-external"></i></a></li></ul><p>介绍:Quepy是通过改变自然语言问题从而在数据库查询语言中进行查询的一个Python框架。他可以简单的被定义为在自然语言和数据库查询中不同类型的问题。所以，你不用编码就可以建立你自己的一个用自然语言进入你的数据库的系统。现在Quepy提供对于Sparql和MQL查询语言的支持。并且计划将它延伸到其他的数据库查询语言。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/hannes-brt/hebel" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Hebel》<i class="icon-external"></i></a></li></ul><p>介绍:Hebel是在Python语言中对于神经网络的深度学习的一个库程序，它使用的是通过PyCUDA来进行GPU和CUDA的加速。它是最重要的神经网络模型的类型的工具而且能提供一些不同的活动函数的激活功能，例如动力，涅斯捷罗夫动力，信号丢失和停止法。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/rasbt/mlxtend" class=" wrap external" target="_blank" rel="nofollow noreferrer">《mlxtend》<i class="icon-external"></i></a></li></ul><p>介绍:它是一个由有用的工具和日常数据科学任务的扩展组成的一个库程序。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/dnouri/nolearn" class=" wrap external" target="_blank" rel="nofollow noreferrer">《nolearn》<i class="icon-external"></i></a></li></ul><p>介绍:这个程序包容纳了大量能对你完成机器学习任务有帮助的实用程序模块。其中大量的模块和scikit-learn一起工作，其它的通常更有用。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/kvh/ramp" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Ramp》<i class="icon-external"></i></a></li></ul><p>介绍:Ramp是一个在Python语言下制定机器学习中加快原型设计的解决方案的库程序。他是一个轻型的pandas-based机器学习中可插入的框架，它现存的Python语言下的机器学习和统计工具（比如scikit-learn,rpy2等）Ramp提供了一个简单的声明性语法探索功能从而能够快速有效地实施算法和转换。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/machinalis/featureforge" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Feature Forge》<i class="icon-external"></i></a></li></ul><p>介绍:这一系列工具通过与scikit-learn兼容的API，来创建和测试机器学习功能。这个库程序提供了一组工具，它会让你在许多机器学习程序使用中很受用。当你使用scikit-learn这个工具时，你会感觉到受到了很大的帮助。（虽然这只能在你有不同的算法时起作用。）</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/yandex/rep" class=" wrap external" target="_blank" rel="nofollow noreferrer">《REP》<i class="icon-external"></i></a></li></ul><p>介绍:REP是以一种和谐、可再生的方式为指挥数据移动驱动所提供的一种环境。它有一个统一的分类器包装来提供各种各样的操作，例如TMVA, Sklearn, XGBoost, uBoost等等。并且它可以在一个群体以平行的方式训练分类器。同时它也提供了一个交互式的情节。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/awslabs/machine-learning-samples" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Python 学习机器样品》<i class="icon-external"></i></a></li></ul><p>介绍:用亚马逊的机器学习建造的简单软件收集。</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/ty4z2008/Qix/blob/master/www.github.com/dclambert/Python-ELM" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Python-ELM》<i class="icon-external"></i></a></li></ul><p>介绍:这是一个在Python语言下基于scikit-learn的极端学习机器的实现。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//forum.memect.com/thread/dimension-reduction/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Dimension Reduction》<i class="icon-external"></i></a></li></ul><p>介绍:电子书降维方法,此外还推荐<a href="https://link.zhihu.com/?target=http%3A//www.stat.washington.edu/courses/stat539/spring14/Resources/tutorial_nonlin-dim-red.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Dimensionality Reduction A Short Tutorial<i class="icon-external"></i></a>、<a href="https://link.zhihu.com/?target=http%3A//lvdmaaten.github.io/drtoolbox/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Matlab Toolbox for Dimensionality Reduction<i class="icon-external"></i></a>、<a href="https://link.zhihu.com/?target=http%3A//www.cs.berkeley.edu/%7Ejordan/papers/wang-sha-jordan-nips11.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Unsupervised Kernel Dimension Reduction<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//deeplearning.net/datasets/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Datasets Used For Benchmarking Deep Learning Algorithms》<i class="icon-external"></i></a></li></ul><p>介绍:<a href="https://link.zhihu.com/?target=http%3A//deeplearning.net" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">deeplearning.net</span><span class="invisible"></span><i class="icon-external"></i></a>整理的深度学习数据集列表.</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/advancedlogic/go-freeling" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Golang Natural Language Processing》<i class="icon-external"></i></a></li></ul><p>介绍:Go语言编写的自然语言处理工具.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.4930" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Rehabilitation of Count-based Models for Word Vector Representations》<i class="icon-external"></i></a></li></ul><p>介绍:词频模型对词向量的反击,参考<a href="https://link.zhihu.com/?target=https%3A//levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Improving Distributional Similarity with Lessons Learned from Word Embeddings <i class="icon-external"></i></a>。</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//static1.squarespace.com/static/51156277e4b0b8b2ffe11c00/t/55344152e4b0ff30bb9ec163/1429487954122/ASA_Kuhn.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Three Aspects of Predictive Modeling》<i class="icon-external"></i></a></li></ul><p>介绍:预测模型的三个方面.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//cs224d.stanford.edu/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《CS224d: Deep Learning for Natural Language Processing》<i class="icon-external"></i></a></li></ul><p>介绍:斯坦福大学深度学习与自然语言处理课程,部分课程笔记<a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0%25E4%25B8%258E%25E8%2587%25AA%25E7%2584%25B6%25E8%25AF%25AD%25E8%25A8%2580%25E5%25A4%2584%25E7%2590%2586%25E7%25AC%25AC%25E4%25BA%258C%25E8%25AE%25B2%25E8%25AF%258D%25E5%2590%2591%25E9%2587%258F" class=" wrap external" target="_blank" rel="nofollow noreferrer">词向量<i class="icon-external"></i></a>、<a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0%25E4%25B8%258E%25E8%2587%25AA%25E7%2584%25B6%25E8%25AF%25AD%25E8%25A8%2580%25E5%25A4%2584%25E7%2590%2586%25E7%25AC%25AC%25E4%25B8%2580%25E8%25AE%25B2%25E5%25BC%2595%25E8%25A8%2580" class=" wrap external" target="_blank" rel="nofollow noreferrer">引言<i class="icon-external"></i></a></p><ul><li><a href="https://link.zhihu.com/?target=http%3A//googleresearch.blogspot.jp/2015/06/google-computer-vision-research-at-cvpr.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Google Computer Vision research at CVPR 2015》<i class="icon-external"></i></a></li></ul><p>介绍:CVPR2015上Google的CV研究列表.</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//public.hudl.com/bits/archives/2015/06/05/highlights/" class=" wrap external" target="_blank" rel="nofollow noreferrer">《Using Deep Learning to Find Basketball Highlights》<i class="icon-external"></i></a></li></ul><p>介绍:利用(Metamind)深度学习自动发现篮球赛精彩片段.</p></blockquote>感谢 Qix，深度学习准备由此入坑。</span><!-- react-empty: 489 --></div></div></div><div class="ContentItem-actions"><span><button class="VoteButton VoteButton--up" aria-label="赞同"><svg viewBox="0 0 20 18" class="Icon VoteButton-upIcon Icon--triangle" width="9" height="16" aria-hidden="true" style="height: 16px; width: 9px;"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"></path></g></svg><!-- react-text: 496 -->3359<!-- /react-text --></button><button class="VoteButton VoteButton--down" aria-label="反对"><svg viewBox="0 0 20 18" class="Icon VoteButton-downIcon Icon--triangle" width="9" height="16" aria-hidden="true" style="height: 16px; width: 9px;"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"></path></g></svg></button></span><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 18 18" class="Icon Icon--comment Icon--left" width="12" height="16" aria-hidden="true" style="height: 16px; width: 12px;"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"></path></g></svg><!-- react-text: 505 -->105 条评论<!-- /react-text --><!-- react-empty: 506 --></button><div class="Popover ShareMenu ContentItem-action"><div id="Popover-73341-44743-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73341-44743-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" class="Icon Icon--share Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"></path></g></svg><!-- react-text: 513 -->分享<!-- /react-text --></button></div><!-- react-empty: 514 --></div><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"></path></g></svg><!-- react-text: 519 -->收藏<!-- /react-text --><!-- react-empty: 520 --></button><button class="Button ContentItem-action Button--plain" type="button"><svg width="14" height="16" viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--thank Icon--left" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><path d="M0 5.437C0 2.505 2.294.094 5.207 0 7.243 0 9.092 1.19 10 3c.823-1.758 2.65-3 4.65-3C17.546 0 20 2.507 20 5.432 20 13.24 11.842 18 10 18 8.158 18 0 13.24 0 5.437z" fill-rule="evenodd"></path></g></svg><!-- react-text: 525 -->感谢<!-- /react-text --></button><div class="Popover ContentItem-action"><button class="Button Button--plain" type="button" id="Popover-73343-74951-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73343-74951-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" width="14" height="16" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><g><circle cx="2" cy="2" r="2"></circle><circle cx="9" cy="2" r="2"></circle><circle cx="16" cy="2" r="2"></circle></g></g></svg></button><!-- react-empty: 531 --></div><button class="Button ContentItem-action ContentItem-rightButton Button--plain" type="button"><!-- react-text: 533 -->阅读全文<!-- /react-text --><svg viewBox="0 0 10 6" class="Icon ContentItem-arrowIcon Icon--arrow" width="10" height="16" aria-hidden="true" style="height: 16px; width: 10px;"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"></path></g></svg></button></div></div><!-- react-empty: 537 --><!-- react-empty: 538 --></div></div><div class="List-item"><div data-za-module="AnswerItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Answer&quot;,&quot;token&quot;:&quot;135825424&quot;,&quot;upvote_num&quot;:922,&quot;comment_num&quot;:73,&quot;publish_timestamp&quot;:null,&quot;parent_token&quot;:&quot;26006703&quot;,&quot;author_member_hash_id&quot;:&quot;520a9854e4a78db23219189d4e3b1c43&quot;}}}"><div class="ContentItem" data="[object Object]"><div class="ContentItem-meta"><div class="AnswerItem-meta AnswerItem-meta--related"><div class="AuthorInfo"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover-73345-88363-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73345-88363-content"><a class="UserLink-link" href="https://www.zhihu.com/people/deep-description"><img class="Avatar AuthorInfo-avatar" src="./深度学习如何入门？ - 知乎_files/v2-2948d750eb80a8dcd310664049ef415d_xs.jpg" srcset="https://pic2.zhimg.com/v2-2948d750eb80a8dcd310664049ef415d_l.jpg 2x" alt="Deeper" style="width: 38px; height: 38px;"></a></div><!-- react-empty: 550 --></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-title"><div class="AuthorInfo-name"><span class="UserLink"><div class="Popover"><div id="Popover-73346-97289-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-73346-97289-content"><a class="UserLink-link" href="https://www.zhihu.com/people/deep-description">Deeper</a></div><!-- react-empty: 558 --></div></span></div></div><div class="RichText AuthorInfo-badge">机器学习\深度学习\语音识别</div></div></div><div class="AnswerItem-extraInfo"><span class="Voters"><button class="Button Button--plain" type="button">922 人赞同了该回答</button><!-- react-empty: 563 --></span></div></div></div><div class="ContentItem-content ContentItem-content--unescapable"><div><div><span class="RichText CopyrightRichText-richText">昨天被日报转载了，褒贬不一，仍过千赞；最好的礼物。但是，除了日报，其它的转载请提前私信我，并注明出处。感谢各位捧场！<br>------------------------------------------------------------新年快乐    鸡年大吉--------------------------------------------------------<br>因为近期要做一个关于深度学习入门的技术分享，不想堆砌公式，让大家听得一头雾水不知不觉摸裤兜掏手机刷知乎。所以花了大量时间查资料看论文，有的博客或者论文写得非常赞，比如三巨头LeCun，Bengio和Hinton 2015年在Nature上发表综述论文的“<a href="https://link.zhihu.com/?target=http%3A//www.nature.com/nature/journal/v521/n7553/pdf/nature14539.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Learning<i class="icon-external"></i></a>”，言简意赅地引用了上百篇论文，但适合阅读，不适合presentation式的分享；再如Michael Nielsen写的电子书《神经网络与深度学习》（<a href="https://link.zhihu.com/?target=http%3A//www.tensorfly.cn/home/" class=" wrap external" target="_blank" rel="nofollow noreferrer">中文版<i class="icon-external"></i></a>，<a href="https://link.zhihu.com/?target=http%3A//neuralnetworksanddeeplearning.com/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">英文版<i class="icon-external"></i></a>）通俗易懂，用大量的例子解释了深度学习中的相关概念和基本原理，但适合于抽两三天的功夫来细品慢嚼，方能体会到作者的良苦用心；还有Colah写的<a href="https://link.zhihu.com/?target=http%3A//colah.github.io/" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客<i class="icon-external"></i></a>，每一篇详细阐明了一个主题，如果已经入门，这些博客将带你进阶，非常有趣。<br><br>还翻了很多知乎问答，非常赞。但发现很多”千赞侯”走的是汇总论文视频教程以及罗列代码路线，本来想两小时入门却一脚踏进了汪洋大海；私以为，这种适合于有一定实践积累后按需查阅。还有很多”百赞户”会拿鸡蛋啊猫啊狗啊的例子来解释深度学习的相关概念，生动形象，但我又觉得有避重就轻之嫌。我想，既然要入门深度学习，得有微积分的基础，会求导数偏导数，知道链式法则，最好还学过线性代数；否则，真的，不建议入门深度学习。<br><br>最后，实在没找到我想要的表达方式。我想以图的方式概要而又系统性的呈现深度学习所涉及到的基本模型和相关概念。论文“<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1506.00019" class=" wrap external" target="_blank" rel="nofollow noreferrer">A Critical Review of Recurrent Neural Networks for Sequence Learning<i class="icon-external"></i></a>”中的示意图画得简单而又形象，足以说明问题，但这篇文章仅就RNN而展开论述，并未涉及CNN，RBM等其它经典模型；<a href="https://link.zhihu.com/?target=https%3A//deeplearning4j.org/cn/neuralnet-overview.html%23forward" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deeplearning4j<i class="icon-external"></i></a>上的教程貌似缺少关于编码器相关内容的介绍，而<a href="https://link.zhihu.com/?target=http%3A//ufldl.stanford.edu/wiki/index.php/UFLDL%25E6%2595%2599%25E7%25A8%258B" class=" wrap external" target="_blank" rel="nofollow noreferrer">UFLDL教程<i class="icon-external"></i></a>只是详细介绍了编码器的方方面面。但是如果照抄以上三篇的图例，又涉及到图例中的模块和符号不统一的问题。所以，索性自己画了部分模型图；至于直接引用的图，文中已经给了链接或出处。如有不妥之处，望指正。以下，以飨来访。<br><br><p><b>1. </b> 从经典的二分类开始说起，为此构建二分类的神经网络单元，并以Sigmoid函数和平方差损失（比较常用的还有交叉熵损失函数）函数来举例说明<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA5ODUxOTA5Mg%3D%3D%26mid%3D2652550294%26idx%3D1%26sn%3D820ddc89e1d1af35f14ccf645b963a76%26chksm%3D8b7e45cdbc09ccdb985b3bbc22fbc0dcd013d53e9e9a6073d09d1b676b338af7bd8b7dd2a92d%26mpshare%3D1%26scene%3D1%26srcid%3D0930LxixeTcq5wCcRStBTylE%26pass_ticket%3Dw2yCF%252F3Z2KTqyWW%252FUwkvnidRV3HF9ym5iEfJ%252BZ1dMObpcYUW3hQymA4BpY9W3gn4%23rd" class=" wrap external" target="_blank" rel="nofollow noreferrer">梯度下降法<i class="icon-external"></i></a>以及基于链式法则的反向传播（BP），所有涉及到的公式都在这里：</p><noscript>&lt;img src="https://pic2.zhimg.com/v2-eabfde057dc289980a47b30cb4f13d21_b.png" data-rawwidth="921" data-rawheight="446" class="origin_image zh-lightbox-thumb" width="921" data-original="https://pic2.zhimg.com/v2-eabfde057dc289980a47b30cb4f13d21_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-eabfde057dc289980a47b30cb4f13d21_b.png" data-rawwidth="921" data-rawheight="446" class="origin_image zh-lightbox-thumb lazy" width="921" data-original="https://pic2.zhimg.com/v2-eabfde057dc289980a47b30cb4f13d21_r.png" data-actualsrc="https://pic2.zhimg.com/v2-eabfde057dc289980a47b30cb4f13d21_b.png"><br><p><b>2. </b>神经元中的非线性变换激活函数（<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI1NTE4NTUwOQ%3D%3D%26mid%3D2650325236%26idx%3D1%26sn%3D7bd8510d59ddc14e5d4036f2acaeaf8d%26mpshare%3D1%26scene%3D1%26srcid%3D1214qIBJrRhevScKXQQuqas4%26pass_ticket%3Dw2yCF%252F3Z2KTqyWW%252FUwkvnidRV3HF9ym5iEfJ%252BZ1dMObpcYUW3hQymA4BpY9W3gn4%23rd" class=" wrap external" target="_blank" rel="nofollow noreferrer">深度学习中的激活函数导引<i class="icon-external"></i></a>）及其作用（参考<a class="internal" href="https://www.zhihu.com/people/yan-qin-rui">颜沁睿</a>的<a href="https://www.zhihu.com/question/22334626/answer/103835591" class="internal">回答</a>），激活函数是神经网络强大的基础，好的激活函数（根据任务来选择）还可以加速训练：</p><noscript>&lt;img src="https://pic1.zhimg.com/v2-9227fb8304a64498209ea07772cdd7e0_b.png" data-rawwidth="1879" data-rawheight="869" class="origin_image zh-lightbox-thumb" width="1879" data-original="https://pic1.zhimg.com/v2-9227fb8304a64498209ea07772cdd7e0_r.png"&gt;不同的激活函数搭配不同的参数初始化策略，比如Tahn和</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-9227fb8304a64498209ea07772cdd7e0_b.png" data-rawwidth="1879" data-rawheight="869" class="origin_image zh-lightbox-thumb lazy" width="1879" data-original="https://pic1.zhimg.com/v2-9227fb8304a64498209ea07772cdd7e0_r.png" data-actualsrc="https://pic1.zhimg.com/v2-9227fb8304a64498209ea07772cdd7e0_b.png">不同的激活函数搭配不同的参数初始化策略，比如Tahn和<a href="https://link.zhihu.com/?target=http%3A//jmlr.csail.mit.edu/proceedings/papers/v9/glorot10a/glorot10a.pdf%3Forigin%3Dpublication_detail" class=" wrap external" target="_blank" rel="nofollow noreferrer">Xavier初始化<i class="icon-external"></i></a>方法:<br><noscript>&lt;img src="https://pic4.zhimg.com/v2-326600169cb13d57c7ac1f05f46cdfd3_b.png" data-rawwidth="327" data-rawheight="64" class="content_image" width="327"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-326600169cb13d57c7ac1f05f46cdfd3_b.png" data-rawwidth="327" data-rawheight="64" class="content_image lazy" width="327" data-actualsrc="https://pic4.zhimg.com/v2-326600169cb13d57c7ac1f05f46cdfd3_b.png"><br>以及ReLU和MSRAFiller初始化(<a href="https://link.zhihu.com/?target=http%3A//xueshu.baidu.com/s%3Fwd%3Dpaperuri%253A%2528d7da5edfb3250f7fbbdeaab4e0d82ee9%2529%26filter%3Dsc_long_sign%26tn%3DSE_xueshusource_2kduw22v%26sc_vurl%3Dhttp%253A%252F%252Farxiv.org%252Fabs%252F1502.01852%26ie%3Dutf-8%26sc_us%3D9914304850284386500" class=" wrap external" target="_blank" rel="nofollow noreferrer">S<i class="icon-external"></i></a>r<a href="https://link.zhihu.com/?target=http%3A//xueshu.baidu.com/s%3Fwd%3Dpaperuri%253A%2528d7da5edfb3250f7fbbdeaab4e0d82ee9%2529%26filter%3Dsc_long_sign%26tn%3DSE_xueshusource_2kduw22v%26sc_vurl%3Dhttp%253A%252F%252Farxiv.org%252Fabs%252F1502.01852%26ie%3Dutf-8%26sc_us%3D9914304850284386500" class=" wrap external" target="_blank" rel="nofollow noreferrer">urpassing<i class="icon-external"></i></a><a href="https://link.zhihu.com/?target=http%3A//xueshu.baidu.com/s%3Fwd%3Dpaperuri%253A%2528d7da5edfb3250f7fbbdeaab4e0d82ee9%2529%26filter%3Dsc_long_sign%26tn%3DSE_xueshusource_2kduw22v%26sc_vurl%3Dhttp%253A%252F%252Farxiv.org%252Fabs%252F1502.01852%26ie%3Dutf-8%26sc_us%3D9914304850284386500" class=" wrap external" target="_blank" rel="nofollow noreferrer"> Human<i class="icon-external"></i></a>)方法。<br><p><b>3.</b> 前馈性神经网络和自动编码器的区别在于输出层，从而引出无监督学习的概念；而降噪编码器和自动编码器的区别又在输入层，即对输入进行部分遮挡或加入噪声；稀疏编码器（引出<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA5ODUxOTA5Mg%3D%3D%26mid%3D2652549828%26idx%3D1%26sn%3D5b77192a91d593342e00a984f1132c50%26mpshare%3D1%26scene%3D1%26srcid%3D0802dqmt7jHAo8DZuBVYHO7T%26pass_ticket%3Dw2yCF%252F3Z2KTqyWW%252FUwkvnidRV3HF9ym5iEfJ%252BZ1dMObpcYUW3hQymA4BpY9W3gn4%23rd" class=" wrap external" target="_blank" rel="nofollow noreferrer">正则项<i class="icon-external"></i></a>的概念）和自动编码器的区别在隐藏层，即隐藏层的节点数大于输入层节点数；而编码器都属于无监督学习的范畴。浅层网络的不断栈式叠加构成相应的深度网络。</p><noscript>&lt;img src="https://pic2.zhimg.com/v2-d8190365ba77b450d64de91f4538e2a9_b.png" data-rawwidth="929" data-rawheight="446" class="origin_image zh-lightbox-thumb" width="929" data-original="https://pic2.zhimg.com/v2-d8190365ba77b450d64de91f4538e2a9_r.png"&gt;值得一提的是，三层前馈型神经网络（只包含一个隐藏层）的word2vec(</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-d8190365ba77b450d64de91f4538e2a9_b.png" data-rawwidth="929" data-rawheight="446" class="origin_image zh-lightbox-thumb lazy" width="929" data-original="https://pic2.zhimg.com/v2-d8190365ba77b450d64de91f4538e2a9_r.png" data-actualsrc="https://pic2.zhimg.com/v2-d8190365ba77b450d64de91f4538e2a9_b.png">值得一提的是，三层前馈型神经网络（只包含一个隐藏层）的word2vec(<a href="https://link.zhihu.com/?target=http%3A//suanfazu.com/t/word2vec-zhong-de-shu-xue-yuan-li-xiang-jie-duo-tu-wifixia-yue-du/178/1" class=" wrap external" target="_blank" rel="nofollow noreferrer">数学原理详解<i class="icon-external"></i></a>)是迈向NLP的大门，包括CBOW和skip-gram两种模型，另外在输出层还分别做了基于Huffman树的Hierarchical Softmax以及negative sampling（就是选择性地更新连接负样本的权重参数）的加速。<br><br><p><b>4. </b>受限波兹曼机RBM属于无监督学习中的生成学习，输入层和隐藏层的传播是双向的，分正向过程和反向过程，学习的是数据分布，因此又引出马尔可夫过程和Gibbs采样的概念，以及KL散度的度量概念：</p><noscript>&lt;img src="https://pic4.zhimg.com/v2-cd53ee50bf533b453408318d3f13dc73_b.png" data-rawwidth="940" data-rawheight="434" class="origin_image zh-lightbox-thumb" width="940" data-original="https://pic4.zhimg.com/v2-cd53ee50bf533b453408318d3f13dc73_r.png"&gt;与生成学习对应的是判别学习也就是大多数的分类器，生成对抗网络GAN融合两者；对抗是指生成模型与判别模型的零和博弈，近两年最激动人心的应用是从文本生成图像（</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-cd53ee50bf533b453408318d3f13dc73_b.png" data-rawwidth="940" data-rawheight="434" class="origin_image zh-lightbox-thumb lazy" width="940" data-original="https://pic4.zhimg.com/v2-cd53ee50bf533b453408318d3f13dc73_r.png" data-actualsrc="https://pic4.zhimg.com/v2-cd53ee50bf533b453408318d3f13dc73_b.png">与生成学习对应的是判别学习也就是大多数的分类器，生成对抗网络GAN融合两者；对抗是指生成模型与判别模型的零和博弈，近两年最激动人心的应用是从文本生成图像（<a href="https://link.zhihu.com/?target=http%3A//www.evolvingai.org/ppgn" class=" wrap external" target="_blank" rel="nofollow noreferrer">Evolving AI Lab - University of Wyoming<i class="icon-external"></i></a>）：<br><noscript>&lt;img src="https://pic4.zhimg.com/v2-53b180b2f2b7e9f37f712c8ae12e8f43_b.png" data-rawwidth="1279" data-rawheight="599" class="origin_image zh-lightbox-thumb" width="1279" data-original="https://pic4.zhimg.com/v2-53b180b2f2b7e9f37f712c8ae12e8f43_r.png"&gt;再推荐一个讲DCGAN的超赞教程</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-53b180b2f2b7e9f37f712c8ae12e8f43_b.png" data-rawwidth="1279" data-rawheight="599" class="origin_image zh-lightbox-thumb lazy" width="1279" data-original="https://pic4.zhimg.com/v2-53b180b2f2b7e9f37f712c8ae12e8f43_r.png" data-actualsrc="https://pic4.zhimg.com/v2-53b180b2f2b7e9f37f712c8ae12e8f43_b.png">再推荐一个讲DCGAN的超赞教程<a href="https://link.zhihu.com/?target=http%3A//bamos.github.io/2016/08/09/deep-completion/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Image Completion with Deep Learning in TensorFlow<i class="icon-external"></i></a>：<br><noscript>&lt;img src="https://pic4.zhimg.com/v2-c26e080dd30e8a07d31173578c52ae07_b.png" data-rawwidth="815" data-rawheight="336" class="origin_image zh-lightbox-thumb" width="815" data-original="https://pic4.zhimg.com/v2-c26e080dd30e8a07d31173578c52ae07_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-c26e080dd30e8a07d31173578c52ae07_b.png" data-rawwidth="815" data-rawheight="336" class="origin_image zh-lightbox-thumb lazy" width="815" data-original="https://pic4.zhimg.com/v2-c26e080dd30e8a07d31173578c52ae07_r.png" data-actualsrc="https://pic4.zhimg.com/v2-c26e080dd30e8a07d31173578c52ae07_b.png"><p><b>5. </b>深度网络的实现基于逐层贪心训练算法，而随着模型的深度逐渐增加，会产生梯度消失或梯度爆炸的问题，梯度爆炸一般采用阈值截断的方法解决，而梯度消失不易解决；网络越深，这些问题越严重，这也是深度学习的核心问题，出现一系列技术及衍生模型。</p><noscript>&lt;img src="https://pic2.zhimg.com/v2-247ecfca25fcad04aa4122eb1e892765_b.png" data-rawwidth="869" data-rawheight="441" class="origin_image zh-lightbox-thumb" width="869" data-original="https://pic2.zhimg.com/v2-247ecfca25fcad04aa4122eb1e892765_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-247ecfca25fcad04aa4122eb1e892765_b.png" data-rawwidth="869" data-rawheight="441" class="origin_image zh-lightbox-thumb lazy" width="869" data-original="https://pic2.zhimg.com/v2-247ecfca25fcad04aa4122eb1e892765_r.png" data-actualsrc="https://pic2.zhimg.com/v2-247ecfca25fcad04aa4122eb1e892765_b.png"><p>深度制胜，网络越深越好，因此有了<a href="https://link.zhihu.com/?target=http%3A//xueshu.baidu.com/s%3Fwd%3Dpaperuri%253A%25283821a90f58762386e257eb4e6fa11f79%2529%26filter%3Dsc_long_sign%26tn%3DSE_xueshusource_2kduw22v%26sc_vurl%3Dhttp%253A%252F%252Farxiv.org%252Fabs%252F1512.03385%26ie%3Dutf-8%26sc_us%3D13213678896270879240" class=" wrap external" target="_blank" rel="nofollow noreferrer">深度残差网络<i class="icon-external"></i></a>将深度扩展到152层，并在ImageNe多项竞赛任务中独孤求败：<br><noscript>&lt;img src="https://pic3.zhimg.com/7b3ee9e4f4a2e61acf35820a2768cc12_b.png" class="content_image"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/7b3ee9e4f4a2e61acf35820a2768cc12_b.png" class="content_image lazy" data-actualsrc="https://pic3.zhimg.com/7b3ee9e4f4a2e61acf35820a2768cc12_b.png"></p><br><p><b>6.</b> 卷积神经网络在层与层之间采取局部链接的方式，即卷积层和采样层，在计算机视觉的相关任务上有突出表现，关于卷积神经网络的更多介绍请参考我的另一篇文章（<a href="https://zhuanlan.zhihu.com/p/21699462" class="internal">戳戳戳</a>）：</p><noscript>&lt;img src="https://pic2.zhimg.com/v2-aa4855dc4cf11dc0bff5c131a278c4e9_b.png" data-rawwidth="1845" data-rawheight="877" class="origin_image zh-lightbox-thumb" width="1845" data-original="https://pic2.zhimg.com/v2-aa4855dc4cf11dc0bff5c131a278c4e9_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-aa4855dc4cf11dc0bff5c131a278c4e9_b.png" data-rawwidth="1845" data-rawheight="877" class="origin_image zh-lightbox-thumb lazy" width="1845" data-original="https://pic2.zhimg.com/v2-aa4855dc4cf11dc0bff5c131a278c4e9_r.png" data-actualsrc="https://pic2.zhimg.com/v2-aa4855dc4cf11dc0bff5c131a278c4e9_b.png"><br>而在NIPS 2016上来自康奈尔大学计算机系的副教授 Killan Weinberger 探讨了深度极深的卷积网络，在数据集CIFAR-10 上训练一个 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1603.09382v3.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">1202 层深的网络<i class="icon-external"></i></a>。<br><br><p><b>7.</b> 循环神经网络在隐藏层之间建立了链接，以利用时间维度上的历史信息和未来信息，与此同时在时间轴上也会产生梯度消失和梯度爆炸现象，而LSTM和GRU则在一定程度上解决了这个问题，两者与经典RNN的区别在隐藏层的神经元内部结构，在语音识别，NLP（比如RNNLM）和机器翻译上有突出表现（<a href="https://link.zhihu.com/?target=http%3A//karpathy.github.io/2015/05/21/rnn-effectiveness/" class=" wrap external" target="_blank" rel="nofollow noreferrer">推荐阅读<i class="icon-external"></i></a>）：</p><p><noscript>&lt;img src="https://pic1.zhimg.com/v2-057c850ac4e3275ab87440af8b446ac8_b.png" data-rawwidth="1207" data-rawheight="605" class="origin_image zh-lightbox-thumb" width="1207" data-original="https://pic1.zhimg.com/v2-057c850ac4e3275ab87440af8b446ac8_r.png"&gt;除了RNNLM采用最简单最经典的RNN模型，其他任务隐层神经元往往采用LSTM或者GRU形式，关于LSTM的进化历史，一图胜千言，更多内容可以参阅</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-057c850ac4e3275ab87440af8b446ac8_b.png" data-rawwidth="1207" data-rawheight="605" class="origin_image zh-lightbox-thumb lazy" width="1207" data-original="https://pic1.zhimg.com/v2-057c850ac4e3275ab87440af8b446ac8_r.png" data-actualsrc="https://pic1.zhimg.com/v2-057c850ac4e3275ab87440af8b446ac8_b.png">除了RNNLM采用最简单最经典的RNN模型，其他任务隐层神经元往往采用LSTM或者GRU形式，关于LSTM的进化历史，一图胜千言，更多内容可以参阅<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1503.04069.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">LSTM: A Search Space Odyssey<i class="icon-external"></i></a>：</p><noscript>&lt;img src="https://pic1.zhimg.com/v2-76ed6e05615409d1069793b21bd18a08_b.png" data-rawwidth="912" data-rawheight="427" class="origin_image zh-lightbox-thumb" width="912" data-original="https://pic1.zhimg.com/v2-76ed6e05615409d1069793b21bd18a08_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-76ed6e05615409d1069793b21bd18a08_b.png" data-rawwidth="912" data-rawheight="427" class="origin_image zh-lightbox-thumb lazy" width="912" data-original="https://pic1.zhimg.com/v2-76ed6e05615409d1069793b21bd18a08_r.png" data-actualsrc="https://pic1.zhimg.com/v2-76ed6e05615409d1069793b21bd18a08_b.png"><p>RNN模型在一定程度上也算是分类器，在图像描述（<a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/deepimagesent/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deep Visual-Semantic Alignments for Generating Image Descriptions<i class="icon-external"></i></a>）的任务中已经取得了不起的成果（第四节GAN用文本生成图像是逆过程，注意区别）：</p><noscript>&lt;img src="https://pic4.zhimg.com/v2-efb1bc6baa74b79ab5ff2757e75f3337_b.png" data-rawwidth="1271" data-rawheight="585" class="origin_image zh-lightbox-thumb" width="1271" data-original="https://pic4.zhimg.com/v2-efb1bc6baa74b79ab5ff2757e75f3337_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-efb1bc6baa74b79ab5ff2757e75f3337_b.png" data-rawwidth="1271" data-rawheight="585" class="origin_image zh-lightbox-thumb lazy" width="1271" data-original="https://pic4.zhimg.com/v2-efb1bc6baa74b79ab5ff2757e75f3337_r.png" data-actualsrc="https://pic4.zhimg.com/v2-efb1bc6baa74b79ab5ff2757e75f3337_b.png"><br>另外，关于RNN的最新研究是基于attention机制来建立模型（<a href="https://link.zhihu.com/?target=http%3A//distill.pub/2016/augmented-rnns/" class=" wrap external" target="_blank" rel="nofollow noreferrer">推荐阅读文章<i class="icon-external"></i></a>），即能够在时间轴上选择有效信息加以利用，比如百度App中的"<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1610.09889" class=" wrap external" target="_blank" rel="nofollow noreferrer">为你写诗<i class="icon-external"></i></a>"的功能核心模型就是attention-based RNN encoder-decoder：<noscript>&lt;img src="https://pic3.zhimg.com/v2-3463b8dbd7ed0e92c21d5f73043513fe_b.png" data-rawwidth="1086" data-rawheight="542" class="origin_image zh-lightbox-thumb" width="1086" data-original="https://pic3.zhimg.com/v2-3463b8dbd7ed0e92c21d5f73043513fe_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-3463b8dbd7ed0e92c21d5f73043513fe_b.png" data-rawwidth="1086" data-rawheight="542" class="origin_image zh-lightbox-thumb lazy" width="1086" data-original="https://pic3.zhimg.com/v2-3463b8dbd7ed0e92c21d5f73043513fe_r.png" data-actualsrc="https://pic3.zhimg.com/v2-3463b8dbd7ed0e92c21d5f73043513fe_b.png"><noscript>&lt;img src="https://pic3.zhimg.com/v2-205b838a0cb13544f14f25e28d9bb8b6_b.png" data-rawwidth="896" data-rawheight="386" class="origin_image zh-lightbox-thumb" width="896" data-original="https://pic3.zhimg.com/v2-205b838a0cb13544f14f25e28d9bb8b6_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-205b838a0cb13544f14f25e28d9bb8b6_b.png" data-rawwidth="896" data-rawheight="386" class="origin_image zh-lightbox-thumb lazy" width="896" data-original="https://pic3.zhimg.com/v2-205b838a0cb13544f14f25e28d9bb8b6_r.png" data-actualsrc="https://pic3.zhimg.com/v2-205b838a0cb13544f14f25e28d9bb8b6_b.png"><br><p><b>8.</b> 总结了深度学习中的基本模型并再次解释部分相关的技术概念：</p><noscript>&lt;img src="https://pic2.zhimg.com/v2-487f13a5de2ef2105a90be878e5f3ed5_b.png" data-rawwidth="1249" data-rawheight="607" class="origin_image zh-lightbox-thumb" width="1249" data-original="https://pic2.zhimg.com/v2-487f13a5de2ef2105a90be878e5f3ed5_r.png"&gt;</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-487f13a5de2ef2105a90be878e5f3ed5_b.png" data-rawwidth="1249" data-rawheight="607" class="origin_image zh-lightbox-thumb lazy" width="1249" data-original="https://pic2.zhimg.com/v2-487f13a5de2ef2105a90be878e5f3ed5_r.png" data-actualsrc="https://pic2.zhimg.com/v2-487f13a5de2ef2105a90be878e5f3ed5_b.png"><br><p>最后，现在深度学习在工业中的应用往往是整合多个模型到产品中去，比如在语音识别的端到端系统中，利用无监督模型或者CNN作为前期处理提取特征，然后用RNN模型进行逻辑推理和判断，从而达到可媲美人类交流的水平，如百度的<a href="https://link.zhihu.com/?target=http%3A//xueshu.baidu.com/s%3Fwd%3Dpaperuri%253A%25281ba47fa102a2d61cb4a8a5d85049707c%2529%26filter%3Dsc_long_sign%26tn%3DSE_xueshusource_2kduw22v%26sc_vurl%3Dhttp%253A%252F%252Farxiv.org%252Fabs%252F1512.02595%26ie%3Dutf-8%26sc_us%3D8168572815923394227" class=" wrap external" target="_blank" rel="nofollow noreferrer">DeepSpeech2<i class="icon-external"></i></a>:</p><p><noscript>&lt;img src="https://pic4.zhimg.com/v2-79855f5d20b86111df9c374863815e5f_b.png" data-rawwidth="535" data-rawheight="546" class="origin_image zh-lightbox-thumb" width="535" data-original="https://pic4.zhimg.com/v2-79855f5d20b86111df9c374863815e5f_r.png"&gt;画图是个细活慢活，周末加班很辛苦，觉得好就动动手指给个赞吧。</noscript><img src="./深度学习如何入门？ - 知乎_files/v2-79855f5d20b86111df9c374863815e5f_b.png" data-rawwidth="535" data-rawheight="546" class="origin_image zh-lightbox-thumb lazy" width="535" data-original="https://pic4.zhimg.com/v2-79855f5d20b86111df9c374863815e5f_r.png" data-actualsrc="https://pic4.zhimg.com/v2-79855f5d20b86111df9c374863815e5f_b.png">画图是个细活慢活，周末加班很辛苦，觉得好就动动手指给个赞吧。</p><p>不喜请喷，转载请注明出处，谢谢。</p></span><div class="ContentItem-time"><a href="https://www.zhihu.com/question/26006703/answer/135825424" target="_blank"><span data-tooltip="发布于 2016-12-14"><!-- react-text: 672 -->编辑于 <!-- /react-text --><!-- react-text: 673 -->2017-03-02<!-- /react-text --></span></a></div><!-- react-empty: 824 --></div></div></div><div><div class="ContentItem-actions Sticky is-fixed is-bottom" style="width: 688.545px; bottom: 0px; left: 16.7273px;"><span><button class="VoteButton VoteButton--up" aria-label="赞同"><svg viewBox="0 0 20 18" class="Icon VoteButton-upIcon Icon--triangle" width="9" height="16" aria-hidden="true" style="height: 16px; width: 9px;"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"></path></g></svg><!-- react-text: 780 -->922<!-- /react-text --></button><button class="VoteButton VoteButton--down" aria-label="反对"><svg viewBox="0 0 20 18" class="Icon VoteButton-downIcon Icon--triangle" width="9" height="16" aria-hidden="true" style="height: 16px; width: 9px;"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"></path></g></svg></button></span><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 18 18" class="Icon Icon--comment Icon--left" width="12" height="16" aria-hidden="true" style="height: 16px; width: 12px;"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"></path></g></svg><!-- react-text: 789 -->73 条评论<!-- /react-text --><!-- react-empty: 790 --></button><div class="Popover ShareMenu ContentItem-action"><div id="Popover-19510-39700-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-19510-39700-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" class="Icon Icon--share Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"></path></g></svg><!-- react-text: 797 -->分享<!-- /react-text --></button></div><!-- react-empty: 798 --></div><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" width="13" height="16" aria-hidden="true" style="height: 16px; width: 13px;"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"></path></g></svg><!-- react-text: 803 -->收藏<!-- /react-text --><!-- react-empty: 804 --></button><button class="Button ContentItem-action Button--plain" type="button"><svg width="14" height="16" viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--thank Icon--left" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><path d="M0 5.437C0 2.505 2.294.094 5.207 0 7.243 0 9.092 1.19 10 3c.823-1.758 2.65-3 4.65-3C17.546 0 20 2.507 20 5.432 20 13.24 11.842 18 10 18 8.158 18 0 13.24 0 5.437z" fill-rule="evenodd"></path></g></svg><!-- react-text: 809 -->感谢<!-- /react-text --></button><div class="Popover ContentItem-action"><button class="Button Button--plain" type="button" id="Popover-19511-47566-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover-19511-47566-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" width="14" height="16" aria-hidden="true" style="height: 16px; width: 14px;"><title></title><g><g><circle cx="2" cy="2" r="2"></circle><circle cx="9" cy="2" r="2"></circle><circle cx="16" cy="2" r="2"></circle></g></g></svg></button><!-- react-empty: 815 --></div><button class="Button ContentItem-action ContentItem-rightButton Button--plain" type="button"><!-- react-text: 817 -->收起<!-- /react-text --><svg viewBox="0 0 10 6" class="Icon ContentItem-arrowIcon is-active Icon--arrow" width="10" height="16" aria-hidden="true" style="height: 16px; width: 10px;"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"></path></g></svg></button></div><div class="Sticky--holder" style="position: static; top: auto; right: auto; bottom: auto; left: auto; display: flex; float: none; margin: 0px -24px -4px; height: 56px; width: 688.545px;"></div></div></div><!-- react-empty: 616 --><!-- react-empty: 617 --></div></div></div></div><div class="Card" data-za-module="MessageItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;item_num&quot;:102}}}"><a class="QuestionMainAction" data-za-detail-view-element_name="ViewAll" href="https://www.zhihu.com/question/26006703"><!-- react-text: 243 -->查看全部 <!-- /react-text --><!-- react-text: 244 -->102<!-- /react-text --><!-- react-text: 245 --> 个回答<!-- /react-text --></a></div></div><div class="Question-sideColumn" data-za-module="RightSideBar" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;member_hash_id&quot;:&quot;ceff5c1e402891df07f3216271d2da55&quot;}}}"><div><!-- react-empty: 248 --><div class="Card AnswerAuthor"><div class="Card-header AnswerAuthor-title"><div class="Card-headerText">关于作者</div></div><div class="Card-section"><div class="AnswerAuthor-user"><div class="AnswerAuthor-user-avatar"><span class="UserLink"><a class="UserLink-link" href="https://www.zhihu.com/people/jacky-yang-30"><img class="Avatar Avatar--large UserLink-avatar" src="./深度学习如何入门？ - 知乎_files/v2-15e541b81efc194fa83052bd46ceb60d_im.jpg" srcset="https://pic2.zhimg.com/v2-15e541b81efc194fa83052bd46ceb60d_xl.jpg 2x" alt="jacky yang" style="width: 60px; height: 60px;"></a></span></div><div class="AnswerAuthor-user-content"><div class="AnswerAuthor-user-name"><span class="UserLink"><a class="UserLink-link" href="https://www.zhihu.com/people/jacky-yang-30">jacky yang</a></span></div><div class="AnswerAuthor-user-headline"><div class="RichText">深度学习，人脸识别，人工智能</div></div></div></div></div><div class="Card-section"></div><div class="Card-section"><div class="AnswerAuthor-counts"><div class="NumberBoard"><a class="Button NumberBoard-item Button--plain" data-za-detail-view-element_name="Answer" type="button" href="https://www.zhihu.com/people/jacky-yang-30/answers"><div class="NumberBoard-name">回答</div><div class="NumberBoard-value">49</div></a><a class="Button NumberBoard-item Button--plain" data-za-detail-view-element_name="Post" type="button" href="https://www.zhihu.com/people/jacky-yang-30/posts"><div class="NumberBoard-name">文章</div><div class="NumberBoard-value">0</div></a><a class="Button NumberBoard-item Button--plain" data-za-detail-view-element_name="Follower" type="button" href="https://www.zhihu.com/people/jacky-yang-30/followers"><div class="NumberBoard-name">关注者</div><div class="NumberBoard-value">7576</div></a></div></div><div class="MemberButtonGroup AnswerAuthor-buttons"><button class="Button FollowButton Button--primary Button--blue" icon="plus" type="button"><span><!-- react-text: 427 -->关注<!-- /react-text --><!-- react-text: 428 -->他<!-- /react-text --></span></button><button class="Button" type="button"><svg viewBox="0 0 20 20" class="Icon Button-icon Icon--comments" width="15" height="16" aria-hidden="true" style="height: 16px; width: 15px;"><title></title><g><g>     <path d="M9 0C3.394 0 0 4.13 0 8c0 1.654.522 3.763 2.014 5.566.314.292.518.82.454 1.17-.165 1.488-.842 1.905-.842 1.905-.328.332.105.67.588.582 1.112-.2 2.07-.58 3.526-1.122.4-.202.464-.147.78-.078C11.524 17.764 18 14 18 8c0-3.665-3.43-8-9-8z"></path>     <path d="M19.14 9.628c.758.988.86 2.01.86 3.15 0 1.195-.62 3.11-1.368 3.938-.21.23-.354.467-.308.722.12 1.073.614 1.5.614 1.5.237.24-.188.563-.537.5-.802-.145-1.494-.42-2.545-.81-.29-.146-.336-.106-.563-.057-2.043.712-4.398.476-6.083-.926 5.964-.524 8.726-3.03 9.93-8.016z"></path>   </g></g></svg><span>发私信</span><!-- react-empty: 434 --></button></div></div></div><div class="Card"><div class="Card-header AnswerInfo-title"><div class="Card-headerText"><!-- react-text: 338 -->被收藏<!-- /react-text --><!-- react-text: 339 --> <!-- /react-text --><button class="Button Button--plain" type="button">6598</button><!-- react-text: 341 --> <!-- /react-text --><!-- react-text: 342 -->次<!-- /react-text --></div></div><div class="Card-section AnswerInfo-favlists" data-za-module="CollectionList"><div class="AnswerInfo-favlist" data-za-module="CollectionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Collection&quot;,&quot;token&quot;:&quot;19928423&quot;,&quot;follower_num&quot;:84394,&quot;author_member_hash_id&quot;:&quot;e86556453318a3cafc5de890933ce0a2&quot;}}}"><div class="AnswerInfo-favlist-title"><a class="Button Button--plain" target="_blank" data-za-detail-view-element_name="Collection" title="赞同超过1000的回答" href="https://www.zhihu.com/collection/19928423" type="button">赞同超过1000的回答</a></div><div class="AnswerInfo-favlist-author"><span class="UserLink"><a class="UserLink-link" target="_blank" data-za-detail-view-element_name="Author" href="https://www.zhihu.com/people/longsi">hx liang</a></span><!-- react-text: 350 --> 创建<!-- /react-text --></div><div class="AnswerInfo-favlist-followers"><!-- react-text: 352 -->84394<!-- /react-text --><!-- react-text: 353 --> 人关注<!-- /react-text --></div></div><div class="AnswerInfo-favlist" data-za-module="CollectionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Collection&quot;,&quot;token&quot;:&quot;29523424&quot;,&quot;follower_num&quot;:7102,&quot;author_member_hash_id&quot;:&quot;c53ee3f5472b3ad08301d11a2d701567&quot;}}}"><div class="AnswerInfo-favlist-title"><a class="Button Button--plain" target="_blank" data-za-detail-view-element_name="Collection" title="收藏中转站" href="https://www.zhihu.com/collection/29523424" type="button">收藏中转站</a></div><div class="AnswerInfo-favlist-author"><span class="UserLink"><a class="UserLink-link" target="_blank" data-za-detail-view-element_name="Author" href="https://www.zhihu.com/people/monsoon-46">Monsoon</a></span><!-- react-text: 360 --> 创建<!-- /react-text --></div><div class="AnswerInfo-favlist-followers"><!-- react-text: 362 -->7102<!-- /react-text --><!-- react-text: 363 --> 人关注<!-- /react-text --></div></div><div class="AnswerInfo-favlist" data-za-module="CollectionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Collection&quot;,&quot;token&quot;:&quot;20154562&quot;,&quot;follower_num&quot;:5967,&quot;author_member_hash_id&quot;:&quot;1e6fa0b65bcf743b8e0bf57e11fd90f2&quot;}}}"><div class="AnswerInfo-favlist-title"><a class="Button Button--plain" target="_blank" data-za-detail-view-element_name="Collection" title="一杯茶的时间 与好问题偶遇" href="https://www.zhihu.com/collection/20154562" type="button">一杯茶的时间 与好问题偶遇</a></div><div class="AnswerInfo-favlist-author"><span class="UserLink"><a class="UserLink-link" target="_blank" data-za-detail-view-element_name="Author" href="https://www.zhihu.com/people/chen-zi-cheng-zi">尘子橙子</a></span><!-- react-text: 370 --> 创建<!-- /react-text --></div><div class="AnswerInfo-favlist-followers"><!-- react-text: 372 -->5967<!-- /react-text --><!-- react-text: 373 --> 人关注<!-- /react-text --></div></div><div class="AnswerInfo-favlist" data-za-module="CollectionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Collection&quot;,&quot;token&quot;:&quot;20023116&quot;,&quot;follower_num&quot;:4656,&quot;author_member_hash_id&quot;:&quot;f881a324a1f0094d756860d935163581&quot;}}}"><div class="AnswerInfo-favlist-title"><a class="Button Button--plain" target="_blank" data-za-detail-view-element_name="Collection" title="有用的东西" href="https://www.zhihu.com/collection/20023116" type="button">有用的东西</a></div><div class="AnswerInfo-favlist-author"><span class="UserLink"><a class="UserLink-link" target="_blank" data-za-detail-view-element_name="Author" href="https://www.zhihu.com/people/mang-dou-81">氓逗</a></span><!-- react-text: 380 --> 创建<!-- /react-text --></div><div class="AnswerInfo-favlist-followers"><!-- react-text: 382 -->4656<!-- /react-text --><!-- react-text: 383 --> 人关注<!-- /react-text --></div></div><div class="AnswerInfo-favlist" data-za-module="CollectionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Collection&quot;,&quot;token&quot;:&quot;118261499&quot;,&quot;follower_num&quot;:2959,&quot;author_member_hash_id&quot;:&quot;ad60131dd1b9474e4a5c84ddfdbc8498&quot;}}}"><div class="AnswerInfo-favlist-title"><a class="Button Button--plain" target="_blank" data-za-detail-view-element_name="Collection" title="知乎实时热门" href="https://www.zhihu.com/collection/118261499" type="button">知乎实时热门</a></div><div class="AnswerInfo-favlist-author"><span class="UserLink"><a class="UserLink-link" target="_blank" data-za-detail-view-element_name="Author" href="https://www.zhihu.com/people/zsodur">zsodur</a></span><!-- react-text: 390 --> 创建<!-- /react-text --></div><div class="AnswerInfo-favlist-followers"><!-- react-text: 392 -->2959<!-- /react-text --><!-- react-text: 393 --> 人关注<!-- /react-text --></div></div></div><!-- react-empty: 394 --><!-- react-empty: 395 --></div><!-- react-empty: 251 --><div class="Card" data-za-module="RelatedQuestions"><div class="Card-header SimilarQuestions-title"><div class="Card-headerText">相关问题</div></div><div class="Card-section SimilarQuestions-list"><div class="SimilarQuestions-item" data-za-module="QuestionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Question&quot;,&quot;token&quot;:&quot;24627666&quot;,&quot;author_member_hash_id&quot;:&quot;e0281682d7015e34e863b2222abaf99e&quot;}}}"><a class="Button Button--plain" target="_blank" type="button" href="https://www.zhihu.com/question/24627666">机器学习有很多关于核函数的说法，核函数的定义和作用是什么？</a><!-- react-text: 312 --> <!-- /react-text --><!-- react-text: 313 -->42<!-- /react-text --><!-- react-text: 314 --> 个回答<!-- /react-text --></div><div class="SimilarQuestions-item" data-za-module="QuestionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Question&quot;,&quot;token&quot;:&quot;30694287&quot;,&quot;author_member_hash_id&quot;:&quot;e65fa26842c56c15a6973194872a637d&quot;}}}"><a class="Button Button--plain" target="_blank" type="button" href="https://www.zhihu.com/question/30694287">BRETT 机器人算有「学习」的能力么？</a><!-- react-text: 317 --> <!-- /react-text --><!-- react-text: 318 -->16<!-- /react-text --><!-- react-text: 319 --> 个回答<!-- /react-text --></div><div class="SimilarQuestions-item" data-za-module="QuestionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Question&quot;,&quot;token&quot;:&quot;20962240&quot;,&quot;author_member_hash_id&quot;:&quot;e3231a59cd2576130f6bdb1b6a6a8b86&quot;}}}"><a class="Button Button--plain" target="_blank" type="button" href="https://www.zhihu.com/question/20962240">如何用简单易懂的例子解释隐马尔可夫模型？</a><!-- react-text: 322 --> <!-- /react-text --><!-- react-text: 323 -->30<!-- /react-text --><!-- react-text: 324 --> 个回答<!-- /react-text --></div><div class="SimilarQuestions-item" data-za-module="QuestionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Question&quot;,&quot;token&quot;:&quot;29687860&quot;,&quot;author_member_hash_id&quot;:&quot;7130186e22fbb170db66b4911ff727f5&quot;}}}"><a class="Button Button--plain" target="_blank" type="button" href="https://www.zhihu.com/question/29687860">机器学习专家与统计学家观点上有哪些不同？</a><!-- react-text: 327 --> <!-- /react-text --><!-- react-text: 328 -->54<!-- /react-text --><!-- react-text: 329 --> 个回答<!-- /react-text --></div><div class="SimilarQuestions-item" data-za-module="QuestionItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Question&quot;,&quot;token&quot;:&quot;23255632&quot;,&quot;author_member_hash_id&quot;:&quot;a60fdbbdcabfd9db5e999fcb95feb701&quot;}}}"><a class="Button Button--plain" target="_blank" type="button" href="https://www.zhihu.com/question/23255632">概率图模型（PGM）有必要系统地学习一下吗？</a><!-- react-text: 332 --> <!-- /react-text --><!-- react-text: 333 -->25<!-- /react-text --><!-- react-text: 334 --> 个回答<!-- /react-text --></div></div></div><div class="Card" data-za-module="RelatedLives"><div class="Card-header RelatedLives-title"><div class="Card-headerText">相关 Live 推荐</div></div><div class="Card-section RelatedLives-list"><a class="Button RelatedLives-item Button--plain" target="_blank" href="https://www.zhihu.com/lives/819543866939174912" type="button" data-za-module="LiveItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Live&quot;,&quot;id&quot;:&quot;819543866939174912&quot;,&quot;author_member_hash_id&quot;:&quot;4548fa13d3ec9a64b413b79d0893a238&quot;}}}"><img class="Avatar Avatar--medium RelatedLives-avatar" src="./深度学习如何入门？ - 知乎_files/d7bd4f986_xs.jpg" srcset="https://pic3.zhimg.com/d7bd4f986_l.jpg 2x" style="width: 40px; height: 40px;"><div class="RelatedLives-subject">机器学习中的特征工程</div></a><a class="Button RelatedLives-item Button--plain" target="_blank" href="https://www.zhihu.com/lives/814797938382503936" type="button" data-za-module="LiveItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Live&quot;,&quot;id&quot;:&quot;814797938382503936&quot;,&quot;author_member_hash_id&quot;:&quot;71434fedff29e9d833f559dbe8e522a9&quot;}}}"><img class="Avatar Avatar--medium RelatedLives-avatar" src="./深度学习如何入门？ - 知乎_files/v2-89b5bf43cecdc38d47383f47d80c92e7_xs.jpg" srcset="https://pic4.zhimg.com/v2-89b5bf43cecdc38d47383f47d80c92e7_l.jpg 2x" style="width: 40px; height: 40px;"><div class="RelatedLives-subject">和吴军、刘长明在 RSA 谈创业</div></a><a class="Button RelatedLives-item Button--plain" target="_blank" href="https://www.zhihu.com/lives/790184832209674240" type="button" data-za-module="LiveItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Live&quot;,&quot;id&quot;:&quot;790184832209674240&quot;,&quot;author_member_hash_id&quot;:&quot;4eedf55cf1de9f94173b352f9c5a8d2b&quot;}}}"><img class="Avatar Avatar--medium RelatedLives-avatar" src="./深度学习如何入门？ - 知乎_files/v2-ac4af6270e33b0ae86a7d8121611c02e_xs.jpg" srcset="https://pic3.zhimg.com/v2-ac4af6270e33b0ae86a7d8121611c02e_l.jpg 2x" style="width: 40px; height: 40px;"><div class="RelatedLives-subject">深层学习入门误区</div></a><a class="Button RelatedLives-item Button--plain" target="_blank" href="https://www.zhihu.com/lives/795264798257479680" type="button" data-za-module="LiveItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Live&quot;,&quot;id&quot;:&quot;795264798257479680&quot;,&quot;author_member_hash_id&quot;:&quot;710eba6a35a79b11101c571177962ffd&quot;}}}"><img class="Avatar Avatar--medium RelatedLives-avatar" src="./深度学习如何入门？ - 知乎_files/v2-969b00dda95cbadbaa93d6bf44c80715_xs.jpg" srcset="https://pic2.zhimg.com/v2-969b00dda95cbadbaa93d6bf44c80715_l.jpg 2x" style="width: 40px; height: 40px;"><div class="RelatedLives-subject">如何快速攻克传统算法和数据结构？</div></a><a class="Button RelatedLives-item Button--plain" target="_blank" href="https://www.zhihu.com/lives/791637633754353664" type="button" data-za-module="LiveItem" data-za-module-info="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Live&quot;,&quot;id&quot;:&quot;791637633754353664&quot;,&quot;author_member_hash_id&quot;:&quot;e0f83e6b8ce35049dceab581862f46e0&quot;}}}"><img class="Avatar Avatar--medium RelatedLives-avatar" src="./深度学习如何入门？ - 知乎_files/884ad996ed57a147ee049351c3c5f3ee_xs.jpg" srcset="https://pic3.zhimg.com/884ad996ed57a147ee049351c3c5f3ee_l.jpg 2x" style="width: 40px; height: 40px;"><div class="RelatedLives-subject">人文学科如何看待人工智能</div></a></div></div><!-- react-empty: 254 --></div><footer class="Footer"><a class="Footer-item" target="_blank" href="https://liukanshan.zhihu.com/">刘看山</a><span class="Footer-dot"></span><a class="Footer-item" target="_blank" href="https://www.zhihu.com/question/19581624">知乎指南</a><span class="Footer-dot"></span><a class="Footer-item" target="_blank" href="https://www.zhihu.com/terms">知乎协议</a><span class="Footer-dot"></span><a class="Footer-item" target="_blank" href="https://www.zhihu.com/app">应用</a><span class="Footer-dot"></span><a class="Footer-item" target="_blank" href="https://www.zhihu.com/careers">工作</a><br><a class="Footer-item" target="_blank" href="https://www.zhihu.com/contact">联系我们</a><span> © 2017 知乎</span></footer></div></div><!-- react-empty: 256 --></div></main><!-- react-empty: 257 --><!-- react-empty: 258 --><!-- react-empty: 259 --><div class="CornerButtons CornerButtons--showBackToTopButton"><button class="Button CornerButtons-button CornerButton Button--plain" data-tooltip="建议反馈" data-tooltip-position="left" type="button"><svg width="18" height="16" viewBox="0 0 18 16" xmlns="http://www.w3.org/2000/svg" class="Icon CornerButton-icon Icon--feedback" aria-hidden="true" style="height: 16px; width: 18px;"><title>建议反馈</title><g><path d="M1.01 2.99L3 1s1-1 2-1h8c1 0 2 1 2 1l2 2s1 1 1 2v9s0 2-2.002 2H2c-2 0-2-2-2-2V5c0-1 1.01-2.01 1.01-2.01zM4.5 1.5h9L16 4H2l2.5-2.5zm2 5.5h5s.5 0 .5.5-.5.5-.5.5h-5S6 8 6 7.5s.5-.5.5-.5z" fill-rule="evenodd"></path></g></svg></button><button class="Button CornerButtons-button CornerButton Button--plain" data-tooltip="回到顶部" data-tooltip-position="left" type="button"><svg width="16" height="16" viewBox="0 0 17 17" xmlns="http://www.w3.org/2000/svg" class="Icon CornerButton-icon Icon--backToTopArrow" aria-hidden="true" style="height: 16px; width: 16px;"><title>回到顶部</title><g><path d="M12.036 15.59c0 .55-.453.995-.997.995H5.032c-.55 0-.997-.445-.997-.996V8.584H1.03c-1.1 0-1.36-.633-.578-1.416L7.33.29c.39-.39 1.026-.385 1.412 0l6.878 6.88c.782.78.523 1.415-.58 1.415h-3.004v7.004z" fill-rule="evenodd"></path></g></svg></button></div></div></div><script src="./深度学习如何入门？ - 知乎_files/vendor.60663dc1f11fa46ecfe9.js.下载" data-reactid="21"></script><script src="./深度学习如何入门？ - 知乎_files/main.raven.6923901a47bffac5991c.js.下载" async="" data-reactid="22"></script><script src="./深度学习如何入门？ - 知乎_files/main.app.75a0143c851aa3092461.js.下载" data-reactid="23"></script><div><div data-reactroot=""><div class="Mask SearchBar-mask Mask-hidden"><div class="Mask-mask Mask-mask--black"></div></div></div></div><div><div data-reactroot="" style="display: none;">想来知乎工作？请发送邮件到 jobs@zhihu.com</div></div><span><div></div></span></body></html>