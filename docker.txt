Namespace  隔离内容
UTS 主机名与域名
IPC   	信号量、消息队列和共享内存
PID  进程编号
Network  网络设备、网络栈、端口等等
Mount  挂载点（文件系统）
User  用户和用户组
cgroups。他不仅可以限制被namespace隔离起来的资源，还可以为资源设置权重、计算使用量、操控进程启停等等 
 Control Groups，并被整合进Linux内核。顾名思义就是把进程放到一个组里面统一加以控制
通俗的来说，cgroups可以限制、记录、隔离进程组所使用的物理资源（包括：CPU、memory、IO等），为容器实现虚拟化提供了基本保证，是构建Docker等一系列虚拟化管理工具的基石。

20161023
Register 
docker run -d -p 5000:5000 --restart=always --name registry   -v 、/app/docker/data:/var/lib/registry   registry:2
和本地时间同步
 -v /etc/localtime:/etc/localtime 
把现有的Local image打上标签 
docker tag ubuntu localhost:5000/myfirstimage
然后push到 register 
docker push localhost:5000/myfirstimage
拉回来
docker pull localhost:5000/myfirstimage


docker pull ubuntu instructs docker to pull an image named ubuntu from the official Docker Hub. This is simply a shortcut for the longer docker pull docker.io/library/ubuntu command
docker pull myregistrydomain:port/foo/bar instructs docker to contact the registry located  at myregistrydomain:port to find the image foo/bar


docker dameon 日志 在 /var/log/message里面 

20161021
docker swarm mode使用 swarmkit构建 ，每个节点都可以是管理节点和工作节点，使用 raft协议做分布式存储和协调
service 运行在多node上的一个image ，
global services, 每个节点都运行该service
task是指在某个具体的node上运行的image 
对外使用 ingress network做负载均衡 ，不管有没有运行该service的node都支持通过该节点访问服务，对内使用 自带dns 负载均衡或者vip负载均衡

Containers on the network share DNS mappings for the service via gossip so any container on the network can access the service via its service name.

swarm mode  需要打开的端口
TCP port 2377 for cluster management communications
TCP and UDP port 7946 for communication among nodes
TCP and UDP port 4789 for overlay network traffic

iptables -I  INPUT -p tcp --dport 2377 -j ACCEPT
iptables -I  INPUT -p udp --dport 7946 -j ACCEPT
iptables -I  INPUT -p tcp --dport 7946 -j ACCEPT
iptables -I  INPUT -p udp --dport 4789 -j ACCEPT

docker swarm init --advertise-addr  10.163.89.11
查看状态
docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
cme5m2g6wqtwnyuw7prz0hgwg *  D2-WZY11  Ready   Active        Leader
添加node 
docker swarm join --token SWMTKN-1-49r0sdbz4u3zwukbjzo63x50w66fnk20el3kfneasyf17j4r4s-cqhoua8fddrorzky43a8cmfj1     10.163.89.11:2377
添加服务 通过NAT对外发布服务   
docker service create --replicas 3  --publish 8088:8080 --name myservice  tomcat     
创建gloabal service       可以根据节点的metadata来做更精细的部署控制
docker service create --name myservice --mode global alpine top 
查看服务状态
docker service ps myservice2
docker service list
扩容  (不会自动同步image ,如果其他节点没有image,就不能run )
docker service scale myservice2=3
删除服务
docker service rm myservice2
启动一个支持滚动升级的service
docker service create \
  --replicas 3 \
  --name redis \
  --update-delay 10s \
  redis:3.0.6
升级 
docker service update --image redis:3.0.7 redis
重新启动升级，如果已经因为各种原因暂停的 
docker service update redis
暂停一个node 接收service服务
docker node update --availability drain D2-WZY12 
docker node update --availability active D2-WZY12 
建议把管理节点设置为drain不用来发布容器

docker node promote   D2-WZY12 升级到 manage
docker node demote     D2-WZY12 降级到 worker.

swarm join-token --rotate  worker 生成新的worker 加入token ，避免旧的token被乱用
获取当前 worker node 加入 token 
docker swarm join-token worker 
获取当前manager 加入token
docker swarm join-token manager

The docker swarm join command does the following:

switches the Docker Engine on the current node into swarm mode.
requests a TLS certificate from the manager.
names the node with the machine hostname
joins the current node to the swarm at the manager listen address based upon the swarm token.
sets the current node to Active availability, meaning it can receive tasks from the scheduler.
extends the ingress overlay network to the current node.

service里面的程序修改无法动态生效？？？ 新加入 w1.jsp不生效
 
[root@D2-WZY12 ~]# docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
1fixpfc8pb1hpnvzi7mj6ull3 *  D2-WZY12  Ready   Active        Reachable
87wwrlja6uu9t8rsbv307vaha    D2-WZY14  Ready   Active        Reachable
cme5m2g6wqtwnyuw7prz0hgwg    D2-WZY11  Ready   Active        Leader

Active means that the scheduler can assign tasks to a node.
Pause means the scheduler doesn’t assign new tasks to the node, but existing tasks remain running.
Drain means the scheduler doesn’t assign new tasks to the node. The scheduler shuts down any existing tasks and schedules them on an available node.

查看节点自己的状态
docker node inspect self --pretty
创建 Overlay网络
docker network create --driver overlay my-network
docker service create \
  --replicas 3 \
  --network pub_net \
  --env MYVAR=myvalue \
  --workdir /tmp \
  --user my_user  \
  --publish 8080:80\
  --name my-web \
  tomcat
  
   docker network create \
  --driver overlay \
  --subnet 10.0.9.0/24 \
  --opt encrypted \
  my-network


# Mount a read-write bind   要求所有的节点都有这个 path
$ docker service create \
  --mount type=bind,src=<HOST-PATH>,dst=<CONTAINER-PATH> \
  --name myservice \
  <IMAGE>
查看service的VIP
docker service inspect \
  --format='{{json .Endpoint.VirtualIPs}}' \
  my-web

服务命令 my-web对应 的VIP会出现在动态dns 解析里面，同一个 network的都能看到
通过  nslookup tasks.my-web 能看到所有的ip
Name:      tasks.my-web
Address 1: 10.0.0.4 my-web.1.7zvw57ffd0fk8wla3yfp4x5wd.my-network
Address 2: 10.0.0.3 my-web.3.0hcyznnsvafshjcw2oqewh8or.my-network
Address 3: 10.0.0.5 my-web.2.abhyt84z9zbypajq165ry8eah.my-network

使用dns load balance   这种方式下 nslookup  my-dnsrr-service 会有三条记录
 docker service create \
  --replicas 3 \
  --name my-dnsrr-service \
  --network my-network \
  --endpoint-mode dnsrr \
  tomcat 
  
 Docker manager nodes store the swarm state and manager logs in the following directory:
/var/lib/docker/swarm/raft

You should never restart a manager node by copying the raft directory from another node. The data directory is unique to a node ID. A node can only use a node ID once to join the swarm. The node ID space should be globally unique.

To cleanly re-join a manager node to a cluster:

To demote the node to a worker, run docker node demote <NODE>.
To remove the node from the swarm, run docker node rm <NODE>.
Re-join the node to the swarm with a fresh state using docker swarm join.
如果cluster完全摧毁，可以通过这种方式强行恢复
docker swarm init --force-new-cluster --advertise-addr node01:2377   这个指令保留service/network/tasks信息，但是丢掉了member信息，变成一个节点的cluster

查看网络状态 
当创建一个 docker run -d tomcat ,使用缺省网络 
host 下  ip a 
175: vethbb7c83e@if174: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP 
brctl show
docker0         8000.024232511ac3       no              vethbb7c83e
 ethtool  -S vethbb7c83e
    peer_ifindex: 174 
这个174就在刚才创建的container里面


ln -s  /var/run/docker/netns  /var/run/   就能看到不同的 network namespace             
检查  ip netns exec 76cc8e10d64e  ip a 

[root@D2-WZY11 run]# ip netns ls
udp port 4789 -vvvn 76cc8e10d64e (id: 2)
659d029bec78 (id: 1)
1-6syxj3p6e8 (id: 4)
ingress_sbox (id: 5)

创建一个 service后   docker service create --replicas 3  --publish 8088:8080 --name myservice  tomcat 
service情况下 container通过  docker_gwbridge 对外通信 
 btctl show
docker0         8000.024232511ac3       no              vethbb7c83e
docker_gwbridge         8000.024282721ea3       no              veth3e1d17e
                                                        vethb092323
host  ip  a 
179: veth3e1d17e@if178: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker_gwbridge state UP

[root@D2-WZY11 netns]#  ethtool  -S veth3e1d17e    对端出现在 container 里面
NIC statistics:
     peer_ifindex: 178 
 docker exec -it 9978332ff8b1 ip a     
 eth0  不同container通信用 ，同时内部vip也在该网段 因为要走 vlan，所以 MTU=1500-50(VxLAN tag length)
 176: eth0@if177: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    link/ether 02:42:0a:ff:00:06 brd ff:ff:ff:ff:ff:ff
    inet 10.255.0.6/16 scope global eth0
     inet 10.255.0.2/32 scope global eth0              --这个是VIP的地址，每个service内的container里面都有该地址
       valid_lft forever preferred_lft forever
eth1 该container通过host出去用
178: eth1@if179: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default 
    link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.3/16 scope global eth1

查看对应 176的pair 

查看对应的overlay网络  
[root@D2-WZY11 run]# ip netns exec 1-6syxj3p6e8 ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP 
    link/ether 36:22:51:99:6f:5c brd ff:ff:ff:ff:ff:ff
    inet 10.255.0.1/16 scope global br0
       valid_lft forever preferred_lft forever
    inet6 fe80::d88e:48ff:fe7c:50b4/64 scope link 
       valid_lft forever preferred_lft forever
76: vxlan1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master br0 state UNKNOWN 
    link/ether de:47:d8:e8:3c:a4 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::dc47:d8ff:fee8:3ca4/64 scope link 
       valid_lft forever preferred_lft forever
78: veth2@if77: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master br0 state UP 
    link/ether 7e:41:18:9c:48:9f brd ff:ff:ff:ff:ff:ff link-netnsid 1
    inet6 fe80::7c41:18ff:fe9c:489f/64 scope link 
       valid_lft forever preferred_lft forever
177: veth8@if176: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master br0 state UP 
    link/ether 36:22:51:99:6f:5c brd ff:ff:ff:ff:ff:ff link-netnsid 2
    inet6 fe80::3422:51ff:fe99:6f5c/64 scope link 
       valid_lft forever preferred_lft forever     

查看其转发路由表  ip netns exec 1-6syxj3p6e8 bridge fdb show 
02:42:0a:ff:00:04 dev vxlan1 dst 10.163.89.12 link-netnsid 0 self permanent
02:42:0a:ff:00:05 dev vxlan1 dst 10.163.89.14 link-netnsid 0 self permanent
02:42:0a:ff:00:07 dev vxlan1 dst 10.163.89.12 link-netnsid 0 self permanent
02:42:0a:ff:00:08 dev vxlan1 dst 10.163.89.14 link-netnsid 0 self permanent

                                                                     
           这个是 container  的net namespace
[root@D2-WZY11 var]#   docker inspect 9978332ff8b1 | grep SandboxKey
            "SandboxKey": "/var/run/docker/netns/76cc8e10d64e",
            

在node1 container ping node2上的  做node2 做 tcpdump 能看到 vxlan的通信
tcpdump -i eno16777984 udp port 4789 -vvvn 

12:26:18.610379 IP (tos 0x0, ttl 64, id 64510, offset 0, flags [none], proto UDP (17), length 134)
    10.163.89.12.46806 > 10.163.89.11.4789: [no cksum] VXLAN, flags [I] (0x08), vni 256
IP (tos 0x0, ttl 64, id 54811, offset 0, flags [none], proto ICMP (1), length 84)
    10.255.0.7 > 10.255.0.6: ICMP echo reply, id 74, seq 58, length 64
    
    
    

20151111

微服务和Docker为什么重要呢？因为今天在云的世界里竞争是非常激烈，优胜劣汰。那些为应用程序开发者提供简单、快速、伸缩和灵活性的工具成功了，而其他的工具失败了。Docker做的事情就是缩短了构建、测试和部署的周期，并且提供了一种分离方式，通过微服务来分离基础设施、平台和应用程序团队的功能。
20150923
docker现在支持windows通过 oracle VirtualBox(原来sun的) 现在直接用hyper-v了
Kitematic, the Docker GUI, runs on Mac OS X and Windows operating systems
Docker Machine is supported on Windows, OS X, and Linux operating systems.
 Docker Swarm to host and schedule a cluster of Docker containers.
1.8 安装 运行
关闭firewalld 
systemctl stop  firewalld.service
 systemctl enable docker
systemctl start docker 
systemctl stop docker

systemctl restart docker
docker dameon 在centos 7下面的 配置文件需要手工创建在  /etc/systemd/system/docker.service.d/docker.conf 
mkdir -p /etc/systemd/system/docker.service.d
vi /etc/systemd/system/docker.service.d/http-proxy.conf  
[Service]
Environment="HTTP_PROXY=http://192.168.31.77:8080"   "HTTPS_PROXY=http://192.168.31.77:8080"   "NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com"
systemctl daemon-reload
systemctl restart docker
检查变量是否加载
systemctl show --property=Environment docker

show --property=Environment docker
Environment=HTTP_PROXY=http://192.168.31.77:8080 HTTPS_PROXY=http://192.168.31.77:8080 NO_PROXY=lo

vi /etc/systemd/system/docker.service.d/docker.conf  
[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -D


查看 docker dameon的日志
journalctl -u docker
 
 

如果你的做好了所有代码，想分发给你的使用者，这种无疑代码放到image是最佳的，包括你的数据库初始化脚本等。例如wordpress .

如果你是开发环境，代码是用于调试，代码是不应该在image里面的，利用dockerfile，自动git pull也不是好的方案，当然更不提倡ssh到容器，去修改代码

建议用 Dockerfile build 镜像，镜像文档化
Swarm 目前使用较多
最小化镜像大小，分层设计，尽量复用
一容器一进程，便于服务监控与资源隔离
如果有高性能需求，并且你的container是跑在物理机上的，建议使用 local volume + host dev 方案；


容器的网络模式

host模式： 容器和宿主机共享Network namespace。
container模式： 容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。
none模式： 容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair 和网桥连接，配置IP等。
bridge模式： Bridge模式是Docker的默认模式，下面这张图即为Bridge模式下Docker容器的网络连接图。 其实就是NAT

embedded DNS server reachable at 127.0.0.11 will be listed in the container’s resolv.conf 

overlay : 容器间通信用 基于 VxLan
macvlan/ipvlan:容器间通信用，也可以用于容器直接对外提供服务

Use Macvlan:
When you only need to provide egress connection to the physical network to your VMs or containers.
Because it uses less host CPU and provides slightly better throughput.

macvlan bridge 模式同一个parent下面的容器能够直接通信，不通parent下面的在同一host的，也要走外部router路由
macvlan模式下，container不能直接和主机的ip(或者父节点)通信   一个父亲节点只能有一个子节点，但是可以通过 eth0.10这样的vlan方式来解决,同一Host 不通网段的container，也需要走外部router互联
macvlan模式下，如果主机的网卡 down了，那么子节点也都down了，无法正常通信 
macvlan模式下，docker的IPAM不会注意到外部DHCP的信息，所以需要特别管理

所以macvlan模式下，一个host的网卡，最多只能有4096个macvlan网络，每个都有独立的ip和mac address
ipvaln下，mac地址一样，ip不一样 ，有L3路由功能,所以同一Host的vm网段不一样，也可以直接通信，不需要通过外部的router 
Use Bridge:
When you need to connect VMs or containers on the same host.
For complex topologies with multiple bridges and hybrid environments (hosts in the same Layer2 domain both on the same host and outside the host).
You need to apply advanced flood control, FDB manipulation, etc.

Swarm将每一个主机上的docker-egnine管理起来，对外提供容器集群服务。最上面是Compose项目，Compose项目主要用来提供基于容器的应用的编排。用户通过yml文件描述由多个容器组成的应用，然后由Compose解析yml，调用Docker API，在Swarm集群上创建出对应的容器。
一般是要求 
容器无状态，容器中不要留中间数据
360的使用经验
容器内部绑定独立IP。
容器内部开启多进程服务。
自动添加监控。
CPU配额硬限制。
容器绑定独立IP这样外部可直接SSH了。
Run only one process per container  如果确实需要多个进程，通过 supervisor这样的程序来启动 多个process

持续集成当然是Docker最纯粹的玩法了，通过『Dockerfile-构建镜像-创建新容器』来完成环境的变更


mesosphere=marathon+mesos+Chronos 用来部署docker 
或者用Kubernetes  
Mesos是C++

2006年， 谷歌第一次对外介绍容器化组件cgroups和namespaces，可以说这是现代Linux容器的开端
Twitter，几乎完全是在Mesos上面运行的
Apache Mesos从研究论文开始，2010年成为Apache孵化项目，后来从ASF“毕业”，并于2013年建立商业实体Mesosphere。


Docker可以使用COW（copy-on-write）文件系统来缓存Dockerfile指令， 类似于LVM的快照， 
联合文件是把不通目录来源的文件统一以一个目录的方式展示，分层，需要修改到下面层的时候，会copy一份出来 最上层的container 层是可读写的
Docker uses a copy-on-write technology with both images and containers. 
This sharing of image layers is what makes Docker images and containers so space efficient.
docker能共享iamge,不用每个都加载一次
OverlayFS supports page cache sharing. This means multiple containers accessing the same file can share a single page cache entry
Btrfs does not support page cache sharing. This means that n containers accessing the same file require n copies to be cached
AUFS efficiently shares images between multiple running containers, enabling fast container start times and minimal use of disk space

到现在仍然仅仅支持满是问题的AuFS（AnotherUnionFS）。
支持下面的存储方式(支持层级的文件系统 union在一起）
AuFS最稳定，最早
Devicemapper redhat/centos 专用  块复制，但是底层的文件不share内存 ，适合io密集型
overlayfs      新一代，快，稳定 有 overlyafs2 ，修改的时候是整个文件copy，所以大文件性能差，不适合密集io
btrfs 不太稳定  块复制，但是底层的文件不share内存 
ZFS 也不太稳定  块复制，但是底层的文件不share内存  


代码是用于调试，代码是不应该在image里面的，用volume挂载合适
如果你的做好了所有代码，想分发给你的使用者，这种无疑代码放到image是最佳的
老服务，不想大改造，一个就一个呗。有精力能重构，拆分成适合Docker的一个服务一个镜像为好。一步步来，把需要能剥离的先做
。随着自己水平的提高和Docker自身的发展，选择可以不一样。 
对于应用架构而言，Docker希望应用尽量无状态、可重新部署、可水平扩展，如果应用比较传统可能需要调整。
对于运维来说，监控采集的指标可能会发生一些变化，不能把传统的针对OS和虚机的监控简单迁移到Docker来，
需要针对其数量和生命周期进行相应的调整。

应用场景：打包发布程序，动态升级，生产回滚等等
目前对Docker的使用分为两大类，你要么把容器当系统中的一个进程，要么会把容器当一台虚拟机来使用。


docker 运行直接共享host的kernel，而kvm需要独立的kernel
docker 支持运行的时候设置cgroup信息比如  -c, --cpu-shares Set the cpu priority for the container.  -m, --memory Set the maximum amount of memory the container can
use, specify units with b, k, m or g.

也可以用virsh来做lxc的container 
每个 LXC "容器" 之间或许不兼容，但是 docker 采用了一种标准的配置方法使得由不同 docker 创建出的 LXC 能够完全兼容。
LXC 的定位是作为一种虚拟机的替代方案。虽然所有的软件都可以安装在由 LXC 或者 docker 管理的容器中， 但是 docker 更倾向于在一个容器中运行一个应用。


要在虚拟机上执行命令，可以通过  docker inspect -f {{.State.Pid}} container_id 先获取进程号，然后
 nsenter 来运行 比如  nsenter -m -u -n -i -p -t 进程号 命令来执行
 
安装 
禁用 SELINUX
/etc/selinux/config
SELINUX=disabled 
SELINUXTYPE=targeted

  yum install docker  
  
redhat使用  device mapper thin provisioning plus this loopback mounted device  代替AUFS 
docker使用如下顺序的unionfs
// Slice of drivers that should be used in an order
 priority = []string{
 "aufs",
 "btrfs",
 "devicemapper",
 "vfs",
 "overlayfs",
 
运行
docker -d & 或者指定端口运行 docker -H 0.0.0.0:5555 -d & or docker -H   tcp://[host][:port]` or `unix://path
查看版本
docker version
 
export HTTP_PROXY=http://192.168.8.26:8080 设置后需要重启 docker 

 然后重启  docker 

下载image 
在hub注册
https://hub.docker.com/
然后 docker login

image放在 /var/lib/docker 

查看container 
docker ps  only live的 或者 docker ps -a 全部的包括已经停止的
关闭 
docker stop stupefied_albattani
获取log
docker logs name 

运行container 
docker run -t -i centos:7 /bin/bash
自动运行container 当系统重启后
docker run -t -i  --restart always  centos:7 /bin/bash 

-t flag assigns a pseudo-tty or terminal inside our new container and the -i flag allows us to make an interactive connection by grabbing the standard in (STDIN) of the container
-P flag was used to automatically map any network ports inside it to a random high port from the range 49153 to 65535 on our Docker host
docker ps -l
指定端口 运行 -p 127.0.0.1:5000:5000  -p  5000:5000   -p 127.0.0.1::5000(任意Local host的可用端口) -p 127.0.0.1:5000:5000/udp 
docker run -d -p 5000:5000 training/webapp python app.py
查看log 
docker logs -f nostalgic_morse
查看container的top trade
docker top nostalgic_morse
查看container信息
docker inspect nostalgic_morse
查看container的port map
docker port evil_pasteur  5000  

根据container 创建新的image 
ocker commit -m="Added txt" -a="Roger" f89f833aa7c1 centos/roger
给image打tag
docker tag 4a7c282f5a9d centos/roger:v2 打完之后出现一个新的 image 
删除 image
docker rmi centos/roger
删除container 
docker rm test1
link container alias和别名会自动push 到 hosts
docker run -t -i --name test2 --link db:db centos:7 /bin/bash
volume共享 两边就能同时共享了 会在container上面mount这个目录 只读 -v /src/webapp:/opt/webapp:ro
文件基本的共享  -v ~/.bash_history:/.bash_history
docker run -d -P --name web -v /webapp:/test training/webapp python app.py

docker run --rm -v /foo -v awesome:/bar busybox top
This command creates an anonymous /foo volume. When the container is removed, the Docker Engine removes the /foo volume but not the awesome volume.
这种方式下 会在 /var/lib/docker下面创建一个新的data file给 container 的 /foo 用 ，使用了 --rm选项，就会在container退出后，自动删除，否则一直保留

attach 到container ,用 ctrl+p 然后 ctrl+q退出
docker attach container2

attach 网络到 container 
docker network connect my-bridge-network web
docker network disconnect my-bridge-network web

创建network    
docker network create -d bridge --subnet 172.25.0.0/16 isolated_nw
docker network create -d host    --subnet 10.163.1.11/24 --gateway 10.163.89.1  host_nw
docker network create -d macvlan    --subnet=10.163.89.0/24    --gateway=10.163.89.1     -o parent=eno16777984  pub_net

docker network create -d macvlan    --subnet=10.163.89.0/24    --gateway=10.163.89.1     -o parent=eno16777984.10  pub2_net

docker run --network=pub_net --ip=10.163.89.16 -itd   busybox

macvlan  bridge模式下，host的网卡可以没有ip地址
 In Macvlan you are not able to ping or communicate with the default namespace IP address
bridge 模式下，缺省能联通外网 ，通过host主机联通 做了 post nat  MASQUERADE
联通外网，可以通过nat方式，也可以通过macvlan/ipvlan或者 把host adapter直接挂到bridge 


启动的时候关联network
docker run --network=pub_net --ip=10.163.89.16 -itd --name=container6 busybox


docker network  create  -d macvlan \
    --subnet=192.168.50.0/24 \
    --gateway=192.168.50.1 \
    -o parent=eth0.50 macvlan50
eth.50 表示vlan 50 ,docker创建网络的时候会自动创建 vlan相关的东西
等于  ip link add link eth0 name eth0.50 type vlan id 50.



通过datavolume container 共享


docker run -t -i --name test2 -v /root/:/test centos:7 /bin/bash
docker run -t -i --name test1 --volumes-from test2 centos:7 /bin/bash 这样 test1/test2里面会有个/test 和host的 /root一样

备份一个container里面的一个mount的volume 内容到 host的当前目录
docker run --volumes-from dbdata -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata
从container copy 到host 
docker cp test_container:/etc/hosts .
导出 container 到 file  docker export container_name 导入  docker import source
导出 image docker save --output=file_name image_name  导入 docker load --input=archive

导出 image 
docker save mynewimage > /tmp/mynewimage.tar
导入image 
docker load < /tmp/mynewimage.tar
 
build一个新的image  
多使用copy 少使用 add 
CMD 代表container起来需要运行的命令
也可以通过 ENTRYPOINT 指定，然后在 run container 的时候指定运行参数

ENTRYPOINT ["nginx"]  指定缺省命令
CMD ["--help"]              指定缺省参数

Dockerfile 

FROM        ubuntu:trusty
RUN         apt-get update && apt-get install -y redis-server
EXPOSE      6379
ENTRYPOINT  ["/usr/bin/redis-server"]

docker build -t <your username>/redis .


Dockerfile  
COPY  app 会把 app下面的东西都copy走，不包括 app自己
FROM centos
MAINTAINER Roger <SvenDowideit@docker.com>

RUN yum -y install openssh-server;yum clean all
RUN mkdir /var/run/sshd
RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key
RUN /bin/echo 'root:123456'|chpasswd
COPY  wzy.txt /home
RUN /bin/sed -i 's/.*session.*required.*pam_loginuid.so.*/session optional pam_loginuid.so/g' /etc/pam.d/sshd
RUN /bin/echo -e "LANG=\"en_US.UTF-8\"" > /etc/default/local
EXPOSE 22
CMD ["/usr/sbin/sshd", "-D"]

tomcat docker 
FROM centos
MAINTAINER Roger <Roger@docker.com>

RUN mkdir /home/tomcat
RUN mkdir /home/java
COPY apache-tomcat-8.5.5 /home/tomcat/
COPY jdk1.8.0_101      /home/java
EXPOSE 8080
ENV JAVA_HOME=/home/java
ENV PATH=$JAVA_HOME/bin:$PATH
CMD ["/home/tomcat/bin/catalina.sh","run"]    #必须使用run命令 



配置veth pair
ip netns add ns1
ip netns add ns2

brctl addbr br-test
brctl stp br-test off
ip link set dev  br-test up

ip addr add 10.0.2.1/8 dev  br-test

#for ns1
ip link add tap1 type veth peer name br-tap1
brctl addif br-test br-tap1
ip link set tap1 netns ns1
ip netns exec ns1 ip link set dev tap1 up
ip link set dev br-tap1 up
ip addr add 10.0.2.2/8 dev tap1
#lo起来之后才能ping通本地的地址
ip link set lo up   
#for ns2
ip link add tap2 type veth peer name br-tap2
brctl addif br-test br-tap2
ip link set tap2 netns ns2
ip netns exec ns2 ip link set dev tap2 up
ip link set dev br-tap2 up
ip addr add 10.0.2.3/8 dev tap2
ip link set lo up

这样两个ns就能ping通了，firewalld关闭也能通
联通外网
ip netns exec ns1 route add default gw 10.0.2.1 tap1
#必须放到通外网的网卡上 或者不加网卡
iptables -t nat -I POSTROUTING -s 10.0.2.0/24 -o team0 -j MASQUERADE  

监控 ping 
tcpdump -e -i any -p icmp  and   host 192.168.193.176 

7万多
