、 网站 
 http://neuralnetworksanddeeplearning.com
 
 scipy.sparse 处理稀疏矩阵
hyperplane   [数] 超平面
Sepal   [植] 萼片；花萼
polynomial   [数] 多项式
sigmoid    S形状
Stochastic Gradient Descent (SGD) 随机
permute   变换，排列交换
Ensemble  n. 全体；总效果
heuristic    启发式的；探索的
  Univariate   单变量的
  hyperbolic  adj. 双曲线的；夸张的
  diabetes  n. 糖尿病；多尿症

 使用 O 记号法（Big O Notation）表示最坏运行情况的上界。例如，
线性复杂度 O(n) 表示每个元素都要被处理一次。
平方复杂度 O(n2) 表示每个元素都要被处理 n 次。 
O(1)  操作的数量为常数，与输入的数据的规模无关。
O(log2 n)   操作的数量与输入数据的规模 n 的比例是 log2 (n)。
 O(2n) 指数级的操作，快速的增长。
  
  
  把文档向量化  
  
  
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
count_vect = CountVectorizer()
train_data=['I love you','fuck','I like it','this is bad ','I am angry','you love me']
train_label=['good','bad','good','bad','bad','good']
 #先向量化数据
X_train_counts = count_vect.fit_transform(train_data)
 #tfidf 处理
tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)
X_train_tfidf.shape
#训练分类器 linear support vector machine (SVM) 也是比较好的文本分类器
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB().fit(X_train_tfidf, train_label)
#预测
docs_new = ['God is love', 'Fuck,I am angry']
X_new_counts = count_vect.transform(docs_new)
X_new_tfidf = tfidf_transformer.transform(X_new_counts)
predicted = clf.predict(X_new_tfidf)

流水线作业
from sklearn.pipeline import Pipeline
text_clf = Pipeline([('vect', CountVectorizer()),
                      ('tfidf', TfidfTransformer()),
                      ('clf', MultinomialNB()), ])
这样一条命令就能做完
text_clf = text_clf.fit(train_data,train_label)
text_clf.predict(docs_new)
               
from sklearn.linear_model import SGDClassifier
text_clf = Pipeline([('vect', CountVectorizer()),
                   ('tfidf', TfidfTransformer()),
                   ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42))])
                   
 评估统计信息
 from sklearn import metrics
 print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))
 
metrics.confusion_matrix(twenty_test.target, predicted)
 参数最佳评定
 
 from sklearn.model_selection import GridSearchCV
 parameters = {'vect__ngram_range': [(1, 1), (1, 2)],
             'tfidf__use_idf': (True, False),
               'clf__alpha': (1e-2, 1e-3)
 }              
 gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)  # job=-1并行运行
#训练
gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])
#预测
twenty_train.target_names[gs_clf.predict(['God is love'])[0]]
#查看得分
gs_clf.best_score_  
for param_name in sorted(parameters.keys()):
     print("%s: %r" % (param_name, gs_clf.best_params_[param_name]))

clf__alpha: 0.01
tfidf__use_idf: True
vect__ngram_range: (1, 2)

查看更多参数
gs_clf.cv_results_

中文分词  (中科软和结巴都不错) 不光是算法，还有词库更重要
import jieba
seg_list = jieba.cut("我来到北京清华大学")


TF-IDF（Term FrequencyCInverse Document Frequency）是一种用于资讯检索与文本挖掘的常用加权技术。TF-IDF是一种统计方法，用以评估一个字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。
TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TF-IDF实际上是：TF * IDF。
词频（Term Frequency，TF）指的是某一个给定的词语在该文件中出现的频率。即词w在文档d中出现的次数count(w, d)和文档d中总词数size(d)的比值。
逆向文件频率（Inverse Document Frequency，IDF）是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。即文档总数n与词w所出现文件数docs(w, D)比值的对数。　

SVM也可以用来做回归 ，支持多 class 分类 
 Stochastic Gradient Descent (SGD) 也可以用来做分类
 
>>> from sklearn import datasets
>>> iris = datasets.load_iris()
>>> digits = datasets.load_digits()
>>> from sklearn import svm
>>> clf = svm.SVC(gamma=0.001, C=100.)
>>> clf.fit(digits.data[:-1], digits.target[:-1])  
SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
  >>> clf.predict(digits.data[-1:])
array([8])
持久化模型
>>> from sklearn.externals import joblib
>>> joblib.dump(clf, 'filename.pkl') 
clf = joblib.load('filename.pkl') 

输入数据再sci里面都转成 float64
设置参数
>>> clf.set_params(kernel='linear').fit(X, y)  
重置参数
clf.set_params(kernel='rbf').fit(X, y)  
  
  
  np.random.seed(0)
  indices = np.random.permutation(len(iris_X))  生成随机坐标
  
  宜人贷用 算法：LR、RF、Kmeans、LDA  Go做为高校开发和运行基础   Python连接到后台 
SKLearn、GBDT、事件识别  Cypher图谱关系挖掘   Neo4j 用来保存图像数据 
  
  随机森林和SVM效果好  还有 GBDT  gradient boosting decision tree
  决策树好解释  基于树的算法通常抗噪能力更强   kaggle 比赛中 gbdt 和 random forest
  neuron network 简单粗暴效果好，尤其是图形识别，NLP
  SVM 能够训练大量（上万的词）特征，不用考虑特征离散化或者分段，非线性映射可以很好的分类。 GBDT 在特征较少的时候（200以内），能够高效bootstrap 抽取样本和特征，训练多颗树。能够自动做特征重要性排序，通过gini系数等指标判断分割点。能够表达非常复杂的规则。
svm 更适合去处理 “同性质”的特征，例如图像特征提取中的 lbp 。而从不同 channel 中来的 feature 则更适合 tree-based model, 这些模型对数据的 distributation 通常并不敏感。
xgboost号称scalable tree boosting system   xgboost 只是GBDT其中一种实现 ，能并行，能分布式
整体加速算法 有两类 1.平均，根据不同独立的基础算法汇总得出结果 ，比如 bagging,随机森林 2.boosting 根据弱的基础算法，一轮轮的迭代，不停优化得出结果 比如 adabooost,GBRT
通常bagging适合复杂的模型，boosting适合简单的模型



import xgboost as xgb

 
  Ridge regression  岭回归
  import LogisticRegression
 logistic = linear_model.LogisticRegression(C=1e5)
logistic.fit(digits.data[:-10],digits.target[:-10])
svc = svm.SVC(kernel='linear')   svc = svm.SVC(kernel='rbf')   svc = svm.SVC(kernel='poly')   
k_means = cluster.KMeans(n_clusters=3)
pca = decomposition.PCA()

regr = linear_model.LinearRegression()   线性回归
regr.fit(diabetes_X_train, diabetes_y_train)

knn = KNeighborsClassifier() 
每个预测函数都有一个score函数，用来评价评估结果
svc.fit(X_digits[:-100], y_digits[:-100]).score(X_digits[-100:], y_digits[-100:])
用k-fold方式测试
 X_folds = np.array_split(X_digits, 3)  
 y_folds = np.array_split(y_digits, 3)
 scores = list()
for k in range(3):
    # We use 'list' to copy, in order to 'pop' later on
    X_train = list(X_folds)
    X_test  = X_train.pop(k)
    X_train = np.concatenate(X_train)
    y_train = list(y_folds)
    y_test  = y_train.pop(k)
    y_train = np.concatenate(y_train)
    scores.append(svc.fit(X_train, y_train).score(X_test, y_test))
print(scores)
或者用sci现成的方法
from sklearn.model_selection import KFold, cross_val_score
X = ["a", "a", "b", "c", "c", "c"]
Y=[1,2,3,3,2,1]
k_fold = KFold(n_splits=3)
for train_indices, test_indices in k_fold.split(X):
     print('Train: %s | test: %s' % (train_indices, test_indices))
 
 for train_indices, test_indices in k_fold.split(X):
     print('Train: %s | test: %s' % (train_indices, test_indices))    
  
[svc.fit(X_digits[train], y_digits[train]).score(X_digits[test], y_digits[test])
   for train, test in k_fold.split(X_digits)]  
 也可以直接用下面方法计算 
 cross_val_score(svc, X_digits, y_digits, cv=k_fold, n_jobs=-1)   n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.
或者  scores = cross_val_score(svc, iris.data, iris.target, cv=5, n_jobs=-1)

也可以用下面的方法进行交叉验证
>>> from sklearn.model_selection import StratifiedShuffleSplit
>>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
>>> y = np.array([0, 0, 1, 1])
>>> sss = StratifiedShuffleSplit(n_splits=3, test_size=0.5, random_state=0)
>>> sss.get_n_splits(X, y)
3
>>> print(sss)       # doctest: +ELLIPSIS
StratifiedShuffleSplit(n_splits=3, random_state=0, ...)
>>> for train_index, test_index in sss.split(X, y):
...    print("TRAIN:", train_index, "TEST:", test_index)
...    X_train, X_test = X[train_index], X[test_index]
...    y_train, y_test = y[train_index], y[test_index]
TRAIN: [1 2] TEST: [3 0]
TRAIN: [0 2] TEST: [1 3]
TRAIN: [0 2] TEST: [3 1]

数据标准化  还有 区间缩放，返回值为缩放到[0, 1]区间的数据  MinMaxScaler().fit_transform(iris.data)
>>> from sklearn import preprocessing
>>> X_train, X_test, y_train, y_test = train_test_split(
...     iris.data, iris.target, test_size=0.4, random_state=0)
>>> scaler = preprocessing.StandardScaler().fit(X_train)       # (x-mean(x))/stand(s)
>>> X_train_transformed = scaler.transform(X_train)
>>> clf = svm.SVC(C=1).fit(X_train_transformed, y_train)
>>> X_test_transformed = scaler.transform(X_test)
>>> clf.score(X_test_transformed, y_test)  
用f1得分更好
sklearn.metrics.f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)

 随机划分数据集
 from sklearn.model_selection import train_test_split
     X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.4, random_state=0)
    
    
     
自动替换多参数，进行求解   GridSearchCV uses a 3-fold cross-validation
>>> from sklearn.model_selection import GridSearchCV, cross_val_score
>>> Cs = np.logspace(-6, -1, 10)
>>> clf = GridSearchCV(estimator=svc, param_grid=dict(C=Cs),
...                    n_jobs=-1)
>>> clf.fit(X_digits[:1000], y_digits[:1000])        
GridSearchCV(cv=None,...
>>> clf.best_score_                                  
0.925...
>>> clf.best_estimator_.C                            
0.0077...

>>> # Prediction performance on test set is not as good as on train set
>>> clf.score(X_digits[1000:], y_digits[1000:])      
>>> cross_val_score(clf, X_digits, y_digits)
线性回归
x=array([[1],[2],[3],[4]])
y=array([6.5,11,15.5,20])
from sklearn import linear_model
reg = linear_model.LinearRegression()
reg.fit (x,y)
reg.coef_  ,reg.intercept_
岭回归
reg = linear_model.Ridge (alpha = .5)  alpha=0的时候和预测相对准

from sklearn.neighbors import NearestNeighbors
nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X) 
KNeighborsClassifier 用的更多
RadiusNeighborsClassifier 适合数据没有均匀采样  数据量/特征量太大的时候，用 KD tree 或者 Ball Tree（适合多特征)
朴素贝叶斯
>>> from sklearn.naive_bayes import GaussianNB
>>> gnb = GaussianNB()
>>> y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)
>>> print("Number of mislabeled points out of a total %d points : %d"
...       % (iris.data.shape[0],(iris.target != y_pred).sum()))

from sklearn import tree
clf = tree.DecisionTreeClassifier()
clf.fit(x,y)
决策树容易出现过拟合，当特征比较多的时候 

export_graphviz  能够导出决策树的图出来

随机森林
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=10)
Adaboosting   缺省用 decision stumps 作为 base weak algorithm 

from sklearn.ensemble import AdaBoostClassifier

AdaBoost是adaptive boosting（自适应boosting）的缩写，运行过程如下：赋予训练集中的每个样本一个权值D，一开始权值都是相等的，
然后训练一个弱分类器并计算错误率，分类正确的样本会降低权重，而分类错误的样本会提高权重，接着再次根据权重训练一个弱分类器，
这么做是为了让新的弱分类器在训练中更加关注未被分类正确的样本。

clf=AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),
                         algorithm="SAMME",
                         n_estimators=200)
                         
from sklearn.ensemble import GradientBoostingClassifier   
clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,     max_depth=1, random_state=0)
     
     
性能比较   clf.fit(digits.data[:-100], digits.target[:-100]).score(digits.data[-100:], digits.target[-100:])   iris data clf.fit(iris.data[:-20], iris.target[:-20]).score(iris.data[-20:], iris.target[-20:])
SVM   98%              90%      
KNN  97.9%            100%
随机森林 96%          90%
逻辑回归 94%           90%
SGDC 91%               100%
贝叶斯 87%              90%
决策树 85%              95%
adaboost   84%             95%
神经网络  99%       100%
GBRT        93%            85%
from sklearn.feature_selection import VarianceThreshold  减少不合适的特征
sel = VarianceThreshold(threshold=(.8 * (1 - .8)))
sel.fit_transform(X)

半监督学习算法
from sklearn.semi_supervised import label_propagation

bagging法：自举汇聚法，从原始数据集选择S次后得到S个数据集的一种技术，新的数据集和原始数据集大小相等。每个数据及都是通过在原始数据集中随机选择一个样本进行替换得到（又放回）。这一性质允许新的数据集中可以有重复的值，而某些值在新集合中将不出现。将某个学习算法分别作用于每个数据集就得到了S个分类器（S个测试数据集针对同一算法训练出S个分类器），当要对新数据进行分类时，应用这S个分类器进行分类。得到结果采取投票的方式，选取最多类别作为最后的结果


MLPClassifier  使用Backpropagation
from sklearn.neural_network import MLPClassifier 
激活函数有    'identity', 'logistic', 'tanh', 'relu'}   实际应用中，tanh 会比 sigmoid 更好  近年来，ReLU 变的越来越受欢迎。
激活函数可以引入非线性因素，解决线性模型所不能解决的问题

 clf = MLPClassifier(solver='lbfgs', alpha=1e-10, hidden_layer_sizes=(60), random_state=1,activation='logistic')
 clf.fit(digits.data[:-100], digits.target[:-100]).score(digits.data[-100:], digits.target[-100:])
0.98999999999999999

Restricted Boltzmann machines (RBM)  是非监督非线性算法

Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, 
都是降维的算法 ，但是上面这些算法容易丢失数据里面非线性特性，
Linear Discriminant Analysis 是监督学习，PCA是非监督学习
Manifold Learning   可以避免 上面这些模型的问题，属于非监督学习
 
 
 from sklearn.cluster import KMeans
 n_samples = 1500
random_state = 170
X, y = make_blobs(n_samples=n_samples, random_state=random_state)

# Incorrect number of clusters
y_pred = KMeans(n_clusters=2, random_state=random_state).fit_predict(X)


Incremental PCA 可以增量batch处理 数据，PCA只能一次性处理所有数据
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.decomposition import PCA, IncrementalPCA
pca = PCA(n_components=2)
X_r = pca.fit(X).transform(X)

pca.explained_variance_ratio_
array([ 0.92461621,  0.05301557])

lda = LinearDiscriminantAnalysis(n_components=2)
X_r2 = lda.fit(X, y).transform(X)

In [560]: lda.explained_variance_ratio_
Out[560]: array([ 0.99147248,  0.00852752])

ipca = IncrementalPCA(n_components=n_components, batch_size=10)
X_ipca = ipca.fit_transform(X)
pca = PCA(n_components=n_components)
X_pca = pca.fit_transform(X)

预处理数据 
标准化数据库
from sklearn import preprocessing
X_scaled = preprocessing.scale(X)     减去均值，除于标准差

min_max_scaler = preprocessing.MinMaxScaler() 
>>> X_train_minmax = min_max_scaler.fit_transform(X_train)
然后可以把这个应用到测试集上
X_test_minmax = min_max_scaler.transform(X_test)

 robust_scale and RobustScaler  可以防止有离群数据情况
 Normalization    正态化数据集
X_normalized = preprocessing.normalize(X, norm='l2')
用来处理离散变量
preprocessing.OneHotEncoder()
用来自动补全缺失数据   mean, the median or the most frequent value of the row or column
from sklearn.preprocessing import Imputer


分类问题用 StrtifiedKFold
回归问题用 KFold
应用算法解决 Kaggle 问题，一般有以下几个步骤：
如果是稀疏的，就用 sparse 的 hstack：
SVD：Singular Value Decomposition，奇异值分解，是线性代数中一种重要的矩阵分解，它总能找到标准化正交基后方差最大的维度，因此用它进行降维去噪。

第一步：识别问题
第二步：分离数据
第三步：构造提取特征
第四步：组合数据
第五步：分解
第六步：选择特征
第七步：选择算法进行训练

   
   数据预处理
　　通过特征提取，我们能得到未经处理的特征，这时的特征可能有以下问题：

不属于同一量纲：即特征的规格不一样，不能够放在一起比较。无量纲化可以解决这一问题。
信息冗余：对于某些定量特征，其包含的有效信息为区间划分，例如学习成绩，假若只关心“及格”或不“及格”，那么需要将定量的考分，转换成“1”和“0”表示及格和未及格。二值化可以解决这一问题。
定性特征不能直接使用：某些机器学习算法和模型只能接受定量特征的输入，那么需要将定性特征转换为定量特征。最简单的方式是为每一种定性值指定一个定量值，但是这种方式过于灵活，增加了调参的工作。通常使用哑编码的方式将定性特征转换为定量特征：假设有N种定性值，则将这一个特征扩展为N种特征，当原始特征值为第i种定性值时，第i个扩展特征赋值为1，其他扩展特征赋值为0。哑编码的方式相比直接指定的方式，不用增加调参的工作，对于线性模型来说，使用哑编码后的特征可达到非线性的效果。
存在缺失值：缺失值需要补充。
信息利用率低：不同的机器学习算法和模型对数据中信息的利用是不同的，之前提到在线性模型中，使用对定性特征哑编码可以达到非线性的效果。类似地，对定量变量多项式化，或者进行其他的转换，都能达到非线性的效果。
　　我们使用sklearn中的preproccessing库来进行数据预处理，可以覆盖以上问题的解决方案。

无量纲化使不同规格的数据转换到同一规格。常见的无量纲化方法有标准化和区间缩放法。标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布。
区间缩放法利用了边界值信息，将特征的取值区间缩放到某个特点的范围，例如[0, 1]等。
简单来说，无量纲化是依照特征矩阵的列处理数据，正则化是依照特征矩阵的行处理数据。正则化的前提是样本各特征值服从正态分布，正则化后将其转换成标准正态分布。正则化的公式类似于标准化，不同的是样本均值和样本标准差改为特征值均值和特征值标准差。
　定量特征二值化的核心在于设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0，公式表达如下
3 #二值化，阈值设置为3，返回值为二值化后的数据
4 Binarizer(threshold=3).fit_transform(iris.data)

bagging：从训练集从进行子抽样组成每个基模型所需要的子训练集，对所有基模型预测的结果进行综合产生最终的预测结果
boosting：训练过程为阶梯状，基模型按次序一一进行训练（实现上可以做到并行），基模型的训练集按照某种策略每次都进行一定的转化。对所有基模型预测的结果进行线性综合产生最终的预测结果：
stacking：将训练好的所有基模型对训练基进行预测，第j个基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第j个特征值，最后基于新的训练集进行训练。同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后再对测试集进行预测
   
   1. 正确率 = 提取出的正确信息条数 /  提取出的信息条数     
   
    2. 召回率 = 提取出的正确信息条数 /  样本中的正确信息条数    
两者取值在0和1之间，数值越接近1，查准率或查全率就越高。   
    3. F1值  = 正确率 * 召回率 * 2 / (正确率 + 召回率) （F 值即为正确率和召回率的调和平均值） 越大越好，1为理想状态，此时precision为1，recall为1
不妨举这样一个例子：某池塘有1400条鲤鱼，300只虾，300只鳖。现在以捕鲤鱼为目的。撒一大网，逮着了700条鲤鱼，200只虾，100只鳖。那么，这些指标分别如下：
正确率 = 700 / (700 + 200 + 100) = 70%
召回率 = 700 / 1400 = 50%
F值 = 70% * 50% * 2 / (70% + 50%) = 58.3%
不妨看看如果把池子里的所有的鲤鱼、虾和鳖都一网打尽，这些指标又有何变化：
正确率 = 1400 / (1400 + 300 + 300) = 70%
召回率 = 1400 / 1400 = 100%
F值 = 70% * 100% * 2 / (70% + 100%) = 82.35%        
由此可见，正确率是评估捕获的成果中目标成果所占得比例；召回率，顾名思义，就是从关注领域中，召回目标类别的比例；而F值，则是综合这二者指标的评估指标，用于综合反映整体的指标。

当然希望检索结果Precision越高越好，同时Recall也越高越好，但事实上这两者在某些情况下有矛盾的。比如极端情况下，我们只搜索出了一个结果，且是准确的，那么Precision就是100%，但是Recall就很低；而如果我们把所有结果都返回，那么比如Recall是100%，但是Precision就会很低。因此在不同的场合中需要自己判断希望Precision比较高或是Recall比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。


机器学习

机箱
直接选跟 Nvidia DevBox 同款的机箱，即 Corsair Carbide Air 540，工作站需要足够的空间，材质稳定，大多深度学习工作站都选取此款机箱。
硬性要求：
X99平台
四个 PCI-E Gen3 x16 接口
众所周知单机多卡进行训练时，总线带宽是瓶颈，所以主板有越多的PCI-e 3.0 接口越好，可以尽可能把显卡的性能发挥出来。计划上四块 GTX 1080，那么至少需要四路 PCI-e 3.0 的 x16 接口。
Nvidia DevBox 用的是 Asus X99-E WS 
华硕 X99-E WS/USB 3.1 是 Asus X99-E WS 的新版
众所周知单机多卡进行训练时，总线带宽是瓶颈，所以 CPU 的 PCI-e lane 越多越好，一般消费级的CPU，PCI-e总线根数是 16, 28 或 40，最大就是40，再大就需要上服务器CPU或者双路CPU了。选40， 这个条件下，有两款 CPU 入围，I7-5930K和 I7-5960X, 5860X太贵了，一般机器学习训练中CPU不是瓶颈，所以选 5930K就可以了，这也是 Nvidia 官方推出的 DevBox 工作站所使用的CPU。
再大就没必要了，李沐的这篇博客GPU集群折腾手记 末尾有说到过，单机4卡的机器，64G内存绰绰有余了。
一般 Nvidia 的旗舰显卡，功耗都是压着 300W的线的，四卡就 1200W了，加上主板，CPU等耗电，选一个 1600W的电源吧。
括PCI-E 3.0、2.0、1.1三种标准版本。三者的x1单向带宽分别为1GB/s、512MB/s、256MB/s，x16双向带宽就是32GB/s、16GB/s、8GB/s。
HBA卡是 pcie 3.0 *8  单向8GB
Nvidia DevBox 用的是 EVGA 1600W 80+ Gold 120-G2-1600-X1 ，那我也用它吧。



如果要做事，想赶快入门，速度出活，请先死记住：
 深度学习=多层的神经网络
如果要写论文，要作报告，要闲聊，请坚持一个原则：
深度学习绝不仅仅是多层的神经网络。
神经网络最重要的用途是分类
 
机器学习的输入是数据（Data），学到的结果叫模型（Model）  从数据中学得模型这个过程通过执行某个学习算法（Learning Algorithm）来完成。
机器学到的模型是一个映射。难以用规则解决的问题，可以尝试用机器学习来解决 永远不要跟机器学习专家说：“加条规则呗”
训练数据的属性称为 特征(feature)

根据用户的人口统计学推荐(比如性别，年龄，地域等）
基于内容的推荐(比如物品本身的标签)，协同过滤(比如物品和用户的关联关系）
基于关联规则的推荐(比如那些物品经常一起购买，或者用户购买一些物品后通常会再购买那些其他物品等)
基于模型的推荐(通过算法对数据做训练，找出模型)
基于模型的协同过滤不需要机器理解物品的属性，纯粹是数学计算

混合推荐
加权混合  切换混合 分区混合 分层混合(采用多种推荐机制，一个推荐的结果作为另一个的输入)
通常要对数据进行降噪归一处理
电商通常采用 itemCF ,新闻类通常采用 userCF(物品比人多) 通常两个算法一起用 
算法要考虑推荐的多样性(覆盖率)和精度
聚类分析通常用于文档分类，有基于概率分布和基于距离两种

拉格朗日乘子法 是一种寻找多元函数在一组约束下的极值的方法

监督学习：给定的采样数据已经包含结果   决策树/神经网络/回归/贝叶斯/KNN          监督学习又大致分成两类：分类（Classification）和回归（Regression） 价格作为标注就是一个连续值，属于回归问题。
非监督学习：给定的采样数据没有结果，需要通过模型来判断分类  聚类模型  （k-means)
半监督：少量标注样本和大量未标注样本
强化学习：输入数据作为对模型的反馈

分类：LR，SVM，朴素贝叶斯，决策树，HMM NN
聚类：k-means，Dirichlet Process，Minhash，Canopy，Spectral
回归：Linear Regression
特征选择：SVD，PCA，ICA
关联规则：FP growth
推荐算法：ItemCF
时间序列：exponential smoothing


 PLA，全称 Perceptron Learning Algorithm。其中 Perceptron 译作感知机，它是人工神经网络中最基础的两层神经网络模型
训练数据是线性可分的 (Liner Seperable) ，是 PLA 能够学习的必要条件。

回归问题，人的经验很重要，要通过人分析数据，画图先确定曲线的形状。
逻辑回归 是分类函数，取值通过 sigmoid 函数变成(0,1)之间的值 ，可以认为是某件事情发生的可能性
决策树的关键步骤是分裂属性，就是在某个节点处按照某一特征属性的不同进行分支，要尽可能的纯，就是相同的分到同一个分支下面。
属性选择的核心思想就是以信息增益度量属性最大的进行分裂，ID3算法在每次分裂的时，需要计算每个属性的增益度，选择最大的
ID3的缺点是偏向选择多值属性，比如，存在唯一标识属性ID，就一定会选择ID作为分裂属性。所以C4.5 使用增益率来优化
实际过程中，会进行剪枝，就是进行降噪处理 
使用熵来表示不定性的度量 熵越大，随机变量的不确定越大
信息增益是针对某个特征，看系统有它和没有它信息量各是多少，两者的差就是这个特征给系统带来的信息量，也就是信息增益
信息增益大表明信息增多，则不确定性就越小。
信息增益的思想来源于信息论的香农定理，定义为离散随机事件出现的概率，越有序，信息熵就越小 ，反正越高
CART=classification and regresssion tree  是一种二分地柜分割技术，先把当年样本分为两个子样本。然后计算Gini指标，以最小Gini作为分裂属性
随机森林 随机森林由多个决策树注册，因为这些决策树的形成采用了随机的方法，所以叫随机森林，最后取所有决策树中分类结果最多的那个为最终结果

神经网络的用途就是分类，一条直线把平面一分为二，一个平面把三维空间一份为二，一个n-1维超平面把N维空间一分为二，两边各属于不同的类
深度学习=多个隐层的神经网络  主要用于解决线性不可分的问题




贝叶斯定理：
　P(A|B) = P(B|A) P(A) / P(B)
假设某个体有n项特征（Feature），分别为F1、F2、...、Fn。现有m个类别（Category），分别为C1、C2、...、Cm。贝叶斯分类器就是计算出概率最大的那个分类，也就是求下面这个算式的最大值：
　P(C|F1F2...Fn) 
　　= P(F1F2...Fn|C)P(C) / P(F1F2...Fn)
朴素贝叶斯分类器则是更进一步，假设所有特征都彼此独立 在现实中不太可能成立，但是它可以大大简化计算

SVM是让应用数学家真正得到应用的一种算法
  线圈出来的点就是所谓的支持向量(support vector)  Maximum Marginal，是SVM的一个理论基础之一。选择使得间隙最大的函数作为分割平面
  让空间从原本的线性空间变成一个更高维的空间，在这个高维的线性空间下，再用一个超平面进行划分
  用这个函数可以将平面中的点映射到一个三维空间（z1,z2,z3)  对映射后的坐标加以旋转之后就可以得到一个线性可分的点集了
  对于所有的两个物体，我们可以通过增加维度来让他们最终有所区别，比如说两本书，从(颜色，内容)两个维度来说，可能是一样的，我们可以加上 作者 这个维度，是在不行我们还可以加入页码，可以加入 拥有者，可以加入 购买地点，可以加入 笔记内容等等。当维度增加到无限维的时候，一定可以让任意的两个物体可分了
  
  聚类属于无监督学习，以往的回归、朴素贝叶斯、SVM等都是有类别标签y的，也就是说样例中已经给出了样例的分类。
  而聚类的样本中却没有给定y，只有特征x，比如假设宇宙中的星星可以表示成三维空间中的点集 。聚类的目的是找到每个样本x潜在的类别y，并将同类别y的样本x放在一起
  K-means算法是将样本聚类成k个簇（cluster）
  K-Means的算法如下：
1.	随机在图中取K（这里K=2）个种子点。
2.	然后对图中的所有点求到这K个种子点的距离，假如点Pi离种子点Si最近，那么Pi属于Si点群。（上图中，我们可以看到A,B属于上面的种子点，C,D,E属于下面中部的种子点）
3.	接下来，我们要移动种子点到属于他的“点群”的中心。（见图上的第三步）
4.	然后重复第2）和第3）步，直到，种子点没有移动（我们可以看到图中的第四步上面的种子点聚合了A,B,C，下面的种子点聚合了D，E）。

K-Means主要有两个最重大的缺陷――都和初始值有关：
?	 K 是事先给定的，这个 K 值的选定是非常难以估计的。很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。（ ISODATA 算法通过类的自动合并和分裂，得到较为合理的类型数目 K）
?	K-Means算法需要用初始随机种子点来搞，这个随机种子点太重要，不同的随机种子点会有得到完全不同的结果。（K-Means++算法可以用来解决这个问题，其可以有效地选择初始点）
K-Means++算法步骤：
1.	先从我们的数据库随机挑个随机点当“种子点”。
2.	对于每个点，我们都计算其和最近的一个“种子点”的距离D(x)并保存在一个数组里，然后把这些距离加起来得到Sum(D(x))。
3.	然后，再取一个随机值，用权重的方式来取计算下一个“种子点”。这个算法的实现是，先取一个能落在Sum(D(x))中的随机值Random，然后用Random -= D(x)，直到其<=0，此时的点就是下一个“种子点”。
4.	重复第（2）和第（3）步直到所有的K个种子点都被选出来。
5.	进行K-Means算法。

KNN算法和K-Means算法不同的是，K-Means算法用来聚类，用来判断哪些东西是一个比较相近的类型，
而KNN算法是用来做归类的，也就是说，有一个样本空间里的样本分成很几个类型，然后，给定一个待分类的数据，
通过计算接近自己最近的K个样本来判断这个待分类数据属于哪个分类。你可以简单的理解为由那离自己最近的K个点来投票决定待分类数据归为哪一类。

 

用户u1喜欢的电影是A，B，C
用户u2喜欢的电影是A, C, E, F
用户u3喜欢的电影是B，D
我们需要解决的问题是：决定对u1是不是应该推荐F这部电影
基于内容的做法：要分析F的特征和u1所喜欢的A、B、C的特征，需要知道的信息是A（战争片），B（战争片），C（剧情片），如果F（战争片），那么F很大程度上可以推荐给u1，这是基于内容的做法，你需要对item进行特征建立和建模。
协同过滤的办法：那么你完全可以忽略item的建模，因为这种办法的决策是依赖user和item之间的关系，也就是这里的用户和电影之间的关系。我们不再需要知道ABCF哪些是战争片，哪些是剧情片，我们只需要知道用户u1和u2按照item向量表示，他们的相似度比较高，那么我们可以把u2所喜欢的F这部影片推荐给u1。

用户u1喜欢的电影是A，B，C
用户u2喜欢的电影是A, C, E, F
用户u3喜欢的电影是B，D
我们需要解决的问题是：决定对u1是不是应该推荐F这部电影
基于内容的做法：要分析F的特征和u1所喜欢的A、B、C的特征，需要知道的信息是A（战争片），B（战争片），C（剧情片），如果F（战争片），那么F很大程度上可以推荐给u1，这是基于内容的做法，你需要对item进行特征建立和建模。
协同过滤的办法：那么你完全可以忽略item的建模，因为这种办法的决策是依赖user和item之间的关系，也就是这里的用户和电影之间的关系。我们不再需要知道ABCF哪些是战争片，哪些是剧情片，我们只需要知道用户u1和u2按照item向量表示，他们的相似度比较高，那么我们可以把u2所喜欢的F这部影片推荐给u1。
 
 