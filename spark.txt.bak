spark硬件配置
建议和hdfs datanode 放一起
建议4-8个硬盘，no raid   ,mount with noatime option 
JVM不支持超过 200 GB of RAM，大内存，需要多个jvm ，留 75%的给 spark


map
map是对RDD中的每个元素都执行一个指定的函数来产生一个新的RDD。任何原RDD中的元素在新RDD中都有且只有一个元素与之对应。
mapPartitions
mapPartitions是map的一个变种。map的输入函数是应用于RDD中每个元素，而mapPartitions的输入函数是应用于每个分区，也就是把每个分区中的内容作为整体来处理的。
mapValues
mapValues顾名思义就是输入函数应用于RDD中Kev-Value的Value，原RDD中的Key保持不变，与新的Value一起组成新的RDD中的元素。因此，该函数只适用于元素为KV对的RDD。
flatMap
与map类似，区别是原RDD中的元素经map处理后只能生成一个元素，而原RDD中的元素经flatmap处理后可生成多个元素来构建新RDD。 
reduce
reduce将RDD中元素两两传递给输入函数，同时产生一个新的值，新产生的值与RDD中下一个元素再被传递给输入函数直到最后只有一个值为止。


spark 支持如下机器学学模型

分类 ：逻辑回归 决策树 随机森林 朴素贝叶斯 多层感知(神经网络) 迭代决策树 (Gradient Boost Regression Tree)
回归：线性回归  决策树回归 随机森林回归 
聚类：K-means  潜在狄利克雷分布（atent Dirichlet allocation (LDA) ）,是文本语义分析中比较重要的一个模型,L  高斯混合模型 Gaussian Mixture Model (GMM) 
协同过滤： 采用 ALS(Alternating Least Squares) 交替最小二乘法 用来补全数据 

Mahout 还支持 隐藏式马可夫模型 (HMM)  奇异值分解 (SVD) 

DAG directed acyclic graph 有向无环图  ，如果一个有向图无法从某个顶点出发经过若干边回到该点，就是 DAG
目前hadoop生态中有两大列存储格式，一个是由Hortonworks和Microsoft开发的ORCFile，另一个是由Cloudera和Twitter开发的Parquet。
多数据源查询：Presto支持从mysql，cassandra，甚至kafka中去读取数据，这就大大减少了数据整合时间，不需要放到HDFS里才能查询。
Impala和Hive也支持查询hbase。Spark SQL也在1.2版本开始支持External Datasource。国内也有类似的工作，如秒针改造Impala使之能查询postgres。
Impala对内存消耗过高，在进行一些大表的Join时容易crash 
Presto，是目前开源界最接近RedShift的方案
HAWQ是GreenPlum将查询优化层独立出来，并且以HDFS作为数据载体的OLAP方案。GreenPlum的数据库层在HAWQ里只作为执行引擎，而不再负责存储，因此可以方便得引入GreenPlum的其他特性，比如标准SQL，ACID事务，以及查询优化器。GreenPlum的负责人仍然公开宣称HAWQ比GreenPlum慢，但是利用HDFS存储数据的优势，可以让HAWQ更适合作为统一数据分析平台的基础组件。今年的2月和10月，HAWQ和GreenPlum分别先后开源，因此这是一个值得深入研究的平台。
下面看看HAWQ/GreenPlum性能优势的最主要组件：基于成本模型的并行查询执行计划Cost Based Parallel Query Optimizer and Planner[5]。

kudu是一个分布式存储引擎，介于 hdfs(完全批处理)和hbase(oltp)之间，适合小数据量的高并发处理(select,update) ,适合20T以内的数据处理，再多导入HDFS
kudu适合并发度高，数据量小的小作业，时候数据进来后还需要在修改的，比如实时交易数据进来后面还要继续修改
适合做ODS，保存一天的数据，挖掘完后，继续存储hdfs

ETL 大部分可以用hive sql搞定，少部分用 spark搞定
hbase可以用来存放画像信息，完全打散到最细粒度标签按列存放

mpp适合tb级别数据，不适合pb级别数据

招行第一期50个节点，500TB数据，完成从terradata数仓的off load etl，etl之后的数据回到 terradata,长期存量数据还是存hdfs（5年后的)
每天增量约5.3T数据




presto支持hdfs上和外面的data source, HAWQ只支持HDFS
presto不存储数据，只是SQL engine  ，不是M/R架构，是MPP架构 全内存保存储  不支持cost based optimization
impala(c++开发） 不支持同时join不同数据源的表 ，presto支持(java开发)
presto支持存放在s3上的，impala不支持

  spark sql支持 hive/parquet/json/cassandra/mysql/pg类型作为存储源
  spark sql主要用于在spark pipeline中工作，比如和spark ml一起工作
  hive算通用性的sql on hadoop
  可以使用 hive on tez 提速
  spark sql 不是太成熟
  
  impala和spark sql适合中小规模数据访问
  presto 并行性能更好
Airbnb 采用 Presto 来查询 Hive 表
  
  hive支持视图
  
  酷狗 离线计算 ( 批处理 )：通过 spark，spark SQL 实现，整体性能比 hive 提高 5―10 倍，hive 脚本都在转换为 Spark/Spark SQL
  ；部分复杂的作业还是通过 Hive/Spark 的方式实现  storm处理的数据如果写入HDFS有问题，可以再次写入kafka，然后落入hdfs
  
  kafka大流量优化
  a)num.network.threads( 网络处理线程数 ) 值应该比 cpu 数略大。
b)num.io.threads( 接收网络线程请求并处理线程数 ) 值提高为 cpu 数两倍

  
  Impala as "SQL on HDFS" (mpp), while Hive is more "SQL on Hadoop".
  impala不提供容错，如果失败，就得重来，但是查询速度快，可以用来做ad-hoc查询 还不是太成熟，数据量大不能fit到内存容易crash
  if you need real time, ad-hoc queries over a subset of your data go for Impala. And if you have batch processing kinda needs over your Big Data go for Hive.
   
  

Single huge table aggregations:
Querying over  data stored as text format in HDFS : Impala is faster(3x faster)
Querying over data stored in Parquet : Impala is faster(2x faster)
Querying over data stored in ORC : Presto is faster(Impala has no support for ORC)

Zeppelin 是一个提供交互数据分析且基于Web的笔记本。方便你做出可数据驱动的、可交互且可协作的精美文档，并且支持多种语言，包括 Scala(使用 Apache Spark)、Python(Apache Spark)、SparkSQL、 Hive、 Markdown、Shell等等。

Amazon Redshift 使用列式存储、数据压缩及区域映射，可降低执行查询所需的I/O 数量
Amazon Redshift 采用 MPP 体系结构，能够以并行的分布式处理方式来执行 SQL操作，从而利用所有可用资源



  
hbase数据先写到memstore和wal然到hfile    
支持 DDL(alter,create,describle,drop,enable,disable,exists,is_disabled,is_enabled,list) DML(count,delete,delete_all,get,get_counter,incr,put,scan,truncate)
create  'Blog' ,{NAME=>'Info'},{NAME=>'address'}   两个column family  Info和 address 
put 'Blog' 'John-0001','Info:title','Mouse' 
count 'Blog' ,INTERVAL=>10 ,每10行显示一条记录
 get 'Blog'   'John-0001'  {column=>['Info:title']} 
 scan 'Blog' ,{LIMIT=>1}  查第一行
  scan 'Blog' ,{STARTROW=>'startrow',STOPROW=>'Stoprow'}   range scan start is inclusive ,stop row is exclusive 
 scan 'Blog' ,{TIMERANGE=>[t1,t2]}  查时间范围
 put 如果rowid已经存在，就是修改，直接插入一个新version的记录
 需要先disable ，然后drop table 
  

  
 
 HiVE
 DDL(show tables,create,alter,drop) 
 create table foo(id INT,name STRING) delimited fields terminated by ',' lines terminated by '\n'
  create table foo(id INT,name STRING)  partitioned by (id INT)
   select *from tab_name where freq>100 sort by freq asc limit 10 ;
   
   Spark SQL 
   sqlCtx.table("people").groupBy("name").agg("name",avg("age")).collect 
      sqlCtx.table("select name,avg(age) from people group by name ") 

   =select name,avg(age) from people group by name ;
 
从数据上看，Kylin能够在比Hive/SparkSQL在更弱的硬件配置下获得更好的查询性能。  目前，有越来越多的国内外公司将Kylin作为大数据生产环境中的重要组件，如ebay、银联、百度、中国移动等
Apache Kylin是一个开源的分布式分析引擎，提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区，并于2015年11月正式毕业成为Apache顶级项目。
我们在Apache Kylin集群上跑了多个Cube测试，结果表明它能够有效解决大数据计算分析的3大痛点问题。
痛点一：百亿级海量数据多维指标动态计算耗时问题，Apache Kylin通过预计算生成Cube结果数据集并存储到HBase的方式解决。
痛点二：复杂条件筛选问题，用户查询时，Apache Kylin利用router查找算法及优化的HBase Coprocessor解决；
痛点三：跨月、季度、年等大时间区间查询问题，对于预计算结果的存储，Apache Kylin利用Cube的Data Segment分区存储管理解决。

从第三部分的各个场景对比中可以看出，SequoiaDB数据库在数据插入场景中表现最为突出，甚至超过本身以插入性能著称的Cassandra，混合读写场景下性能也可圈可点。
而业界普及率最高的MongoDB则在单纯读取性能上最为抢眼，远超其他。
HBase与Cassandra虽然在写入性能上远高于MongoDB，但是和SequoiaDB相比仍然逊色一筹；而在主键随机读操作方面，
Cassandra的新版本和之前的版本比起来性能大幅度上升，基本做到和MongoDB处于同一水平线，而HBase则远不能和其他产品相比。

不严谨地讲，Redis定位在"快"，HBase定位于"大",mongodb定位在"灵活"。
MongoDB是文档型数据库，使用bson结构，可以更加灵活的处理嵌套结构的数据。是这三个里最接近关系型数据库的。
Redis是k-v型数据库，目标是做高效的分布式缓存。数据一般不实时落地。也不适合做存储和分析。
HBase是列式数据库，BigTable的一种实现，目标是高效存储大量数据，支持列压缩，行事务。适合Schema-less的数据。

 Spark +Hbase + Apache Phoenix + Kafka +ElasticSearch
  Phoenix is a JDBC driver for Hbase 
  Mongodb用于缓存，可以忍受丢失数据的场景

SQL编辑器，支持Hive, Impala, MySQL, Oracle, PostgreSQL, SparkSQL, Solr SQL, Phoenix…
搜索引擎Solr的各种图表
Spark和Hadoop的友好界面支持
支持调度系统Apache Oozie，可进行workflow的编辑、查看


 在企业中，由于有些流水表每日有几千万条记录，数据仓库保存5年数据的话很容易不堪重负，因此可以使用拉链表的算法来节省存储空间。
1.采集当日全量数据存储到 ND（当日） 表中。 
2.可从历史表中取出昨日全量数据存储到 OD（上日数据）表中。
3.用ND－OD（minus差集）为当日新增和变化的数据（即日增量数据）。

两个表进行全字段比较，将结果记录到tabel_I表中
4.用OD－ND为状态到此结束需要封链的数据。 (需要修改END_DATE)
两个表进行全字段比较，将结果记录到tabel_U表中 
5.历史表（HIS）比ND表和OD表多两个字段（START_DATE，END_DATE） 
6.将tabel_I表的内容全部insert插入到HIS表中。START_DATE='当日',END_DATE可设为'9999-12-31' 
7.更新封链记录的END_DATE
历史表（HIS）和tabel_U表比较，START_DATE，END_DATE除外，以tabel_U表为准，两者交集（INTERSECT）将其END_DATE改成当日，说明该记录失效。 
8。取数据时对日期进行条件选择即可,如：取20100101日的数据为 
(where START_DATE<='20100101' and END_DATE>='20100101' )



spark

安装 
  ./sbt/sbt assembly
  
  storm(分布式容错实时流式处理框架) spark(分布式流式处理框架)
  storm trident(事物)能够保证严格的 exactly once 逻辑，spark就是exactly once
  storm和 kafka集成的更好，spark和hdfs集成更好
  storm 单机能处理约10,000 messasge ,spark stream能处理400,000message/s
  storm换成了netty(0.9原来是zeromq)
  storm重度使用ZK,可能会成为一个瓶颈 ，ZK每次都会发生物理IO，所以最好使用SSD
  storm 和kafka一起使用的时候，spout 并行度取决于kafka
  storm支持按照fields分组到特定的task处理

spark速度比hadoopy快10-100倍，使用hdfs作为存储
RDD=Resilient Distributed Dataset  可以认为是数据库的表 支持transformation(返回一个新的rdd)和 Action 返回一个计算的值 支持partion
SPARK SQL　DataFrame是一个分布式的，按照命名列的形式组织的数据集合。DataFrame基于R语言中的data frame概念，与关系型数据库中的数据库表类似。
以RDD为基础，带有schema信息。Spark SQL提供SQLContext封装Spark中的所有关系型功能。可以用之前的示例中的现有SparkContext创建SQLContext。下述代码片段展示了如何创建一个SQLContext对象。
  流工作的方式是将数据流按照预先定义的间隔(N秒)划分为批(称微批次)然后将每批数据视为一个弹性分布式数据集(Resilient Distributed Datasets，RDDs)。随后我们就可以使用诸如map、reduce、reduceByKey、join和window这样的操作来处理这些RDDs。这些RDD操作的结果会以批的形式返回。通常我们会将这些结果保存到数据存储中以供未来分析并生成报表与面板，或是发送基于事件的预警。Dstream(离散流，Discretized Stream，的缩写)是Spark流中最基本的抽象，它描述了一个持续的数据流。DStream既可以从诸如Kafka、Flume与Kinesis这样的数据源中创建，也可以对其他DStream实施操作。在内部，一个DStream被描述为一个RDD对象的序列。与Spark中的Spark上下文(SparkContext)相似，流上下文(StreamingContext)是所有流功能的主入口。
流上下文拥有内置方法可以将流数据接收到Spark流程序中。
使用该上下文，我们可以创建一个描述基于TCP数据源的流数据的DStream，可以用主机名与端口号指定TCP数据源
推荐引擎一般有两种算法实现：基于内容过滤和协同过滤。
协调过滤的解决方案比其他算法要好，Spark MLlib实现了ALS协同过滤算法。Spark MLlib的协同过滤有两种形式：显式反馈和隐试反馈。显式反馈是基于用户购买的商品（比如，电影），显式反馈虽好，但很多情况下会出现数据倾斜；隐试反馈是基于用户的行为数据，比如，浏览、点击、喜欢等行为。隐试反馈现在大规模应用在工业上进行数据预测分析，因为其很容易收集各类数据。
另外有基于模型的方法实现推荐引擎，这里暂且略过。神经网络技术被用来进行销售点的异常监测。比如像PayPal等公司使用不同的机器学习算法（比如，线性回归，神经网络和深度学习）来进行风险管理。

  2015年6月，Spark 1.4发布引入R语言作为Spark的接口。R语言接口在问世一个多月之后的调查中就有18%的用户使用。
  Spark目前支持四种语言的接口，除了上面提到的R语言的使用率以外，Python的使用率也有很大提升，从2014年的38%提升到2015年的58%；而Scala接口的使用率有所下降，从84%下降到71%。同时Spark的部署环境也有所变化，51%的部署在公有云上，48% 使用standalone方式部署，而在YARN上的只有40%了。
  腾讯的Spark规模到了8000+节点，日处理数据1PB+。阿里巴巴运行着目前最长时间的Spark Job：1PB+数据规模的Spark Job长达1周的时间。百度的硅谷研究院也在探索Spark+Tachyon的应用场景。

Spark MLlib的ALS算法已经在很多互联网公司用于其推荐系统中。基本上主流的互联网公司都已经部署了Spark平台并运行了自己的业务。上面说的更多的互联网的应用，实际上Spark的应用场景有很多。在Databricks公司的调查中显示主要应用依次是：商务智能、数据仓库、推荐系统、日志处理、欺诈检测等。
Apache Kylin是一个开源的分布式分析引擎，提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区
在eBay，已经上线两个生产环境平台，有着诸多的应用，包括用户行为分析、点击分析、商户分析、交易分析等应用

应用案例
prada 每件衣服有RFID，可以精确跟踪每个用户试衣时间
塔基特百货通过分析用户购买确定是否怀孕

  
  Apache Hive is a data warehouse infrastructure built on top of Hadoop. It allows for querying data stored on HDFS for analysis via HQL, an SQL-like language that gets translated to MapReduce jobs. Despite providing SQL functionality, Hive does not provide interactive querying yet - it only runs batch processes on Hadoop.